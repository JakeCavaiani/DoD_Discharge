vaul.final.discharge.2020)
write.csv(all.discharge.2020,"~/Documents/DoD_Discharge/Predicted_Discharge/2020/all.discharge.2020.csv", row.names = FALSE)
Q_2020 <- all.discharge.2020
Q_2020$day = format(as.POSIXct(Q_2020$DateTime,format="%Y-%m-%d %H:%M:%S"),format="%Y-%m-%d")
Q_2020$day = as.POSIXct(Q_2020$day, "%Y-%m-%d", tz="America/Anchorage")
Q_2020$DateTime = NULL
Q.daily.2020 = with(Q_2020, tapply(MeanDischarge, list(day, Site), mean))
Q.daily.2020 = as.data.frame(Q.daily.2020)
write.csv(Q_2020,"~/Documents/DoD_Discharge/Predicted_Discharge/2020/Q_2020.csv", row.names = FALSE)
write.csv(Q.daily.2020,"~/Documents/DoD_Discharge/Predicted_Discharge/2020/Q.daily.2020.csv", row.names = FALSE)
head(Q_2020)
Q_2020 <- all.discharge.2020
Q_2020$day = format(as.POSIXct(Q_2020$DateTime,format="%Y-%m-%d %H:%M:%S"),format="%Y-%m-%d")
Q_2020$day = as.POSIXct(Q_2020$day, "%Y-%m-%d", tz="America/Anchorage")
Q.daily.2020 = with(Q_2020, tapply(MeanDischarge, list(day, Site), mean))
Q.daily.2020 = as.data.frame(Q.daily.2020)
write.csv(Q_2020,"~/Documents/DoD_Discharge/Predicted_Discharge/2020/Q_2020.csv", row.names = FALSE)
write.csv(Q.daily.2020,"~/Documents/DoD_Discharge/Predicted_Discharge/2020/Q.daily.2020.csv", row.names = FALSE)
head(Q_2020)
rm(Q.daily.2020)
rm(Q_2020)
head(Q.daily.2019)
Q_2020 <- all.discharge.2020
Q_2020$day = format(as.POSIXct(Q_2020$DateTime,format="%Y-%m-%d %H:%M:%S"),format="%Y-%m-%d")
Q_2020$day = as.POSIXct(Q_2020$day, "%Y-%m-%d", tz="America/Anchorage")
str(Q_2020)
Q.daily.2020 = with(Q_2020, tapply(MeanDischarge, list(day, Site), mean))
str(Q.daily.2020)
Q.daily.2020 = as.data.frame(Q.daily.2020)
str(Q.daily.2020)
str(Q.daily.2019)
write.csv(Q.daily.2020,"~/Documents/DoD_Discharge/Predicted_Discharge/2020/Q.daily.2020.csv", row.names = FALSE)
head(Q.daily.2020)
head(Q.daily.2019)
View
View(Q.daily.2020)
rm(Q.daily.2020)
Q.daily.2020 = with(Q_2020, tapply(MeanDischarge, list(day, Site), mean))
View(Q_2020)
head(frch.final.discharge.2020)
library(tidyverse)
library(lubridate)
library(ggplot2)
library(scales)
library(plyr)
library(imputeTS)
library(TSA)
library(bbmle)
library(zoo)
library(xts)
library(forecast)
library(stats)
library(lattice)
library(nlme)
library(geosphere)
library(car)
library(EcoHydRology)
#### Load from google drive ####
#suna.2020.url <- "https://drive.google.com/drive/u/1/folders/1QGwlgWHBQI_AeLuMGNzD4qWB90UqlykK"
#SUNA_new <- drive_get(as_id(suna.2020.url))
#EXO_new <- drive_get(as_id(exo.2020.url))
#SUNA_glist <- drive_ls(SUNA_new, type = "csv")
#EXO_glist <- drive_ls(EXO_new, type = "csv")
#SUNAfile_list <- list.files(path = "")
#SUNA.ALL <- lapply(SUNA_glist)
#read.csv(SUNA_glist)
### Load from local machine ###
EXO_ALL <- read_csv("~/Documents/DoD_2020/EXO_data/from_internal_harddrive/processed/EXO.ALL.csv")
EXO_ALL$Site <- EXO_ALL$site.ID
EXO_ALL$DateTime <- as.POSIXct(EXO_ALL$DateTime)
ALL <- full_join(EXO_ALL, final_discharge_2020)
SUNA_ALL <- read_csv("~/Documents/DoD_2020/SUNA_data/from_internal_harddrive/processed/SUNA.processed.csv")
SUNA_ALL <- SUNA_ALL[, -(14:269)] # Remove channels
SUNA_ALL$Site <- SUNA_ALL$site.ID
SUNA_ALL$DateTime <- SUNA_ALL$datetimeAK
ALL <- full_join(ALL, SUNA_ALL)
#### subset data by site ####
FRCH <-  subset(ALL, Site == "FRCH")
head(FRCH$DateTime)
STRT = subset(ALL, Site == "STRT")
head(STRT$DateTime)
POKE = subset(ALL, Site == "POKE")
head(POKE$DateTime)
VAUL = subset(ALL, Site == "VAUL")
head(VAUL$DateTime)
MOOS = subset(ALL, Site == "MOOS")
head(MOOS$DateTime)
FRCH_Q = as.data.frame(Q.daily$FRCH)
FRCH_Q$day = as.Date(rownames(Q.daily))
names(FRCH_Q) = c("Discharge_Lsec", "day")
write.csv(FRCH_Q, "Predicted_Discharge/processed/FRCH_Q_2020.csv", row.names = FALSE)
STRT_Q = as.data.frame(Q.daily$STRT)
STRT_Q$day = as.Date(rownames(Q.daily))
names(STRT_Q) = c("Discharge_Lsec", "day")
POKE_Q = as.data.frame(Q.daily$POKE)
POKE_Q$day = as.Date(rownames(Q.daily))
names(POKE_Q) = c("Discharge_Lsec", "day")
VAUL_Q = as.data.frame(Q.daily$VAUL)
VAUL_Q$day = as.Date(rownames(Q.daily))
names(VAUL_Q) = c("Discharge_Lsec", "day")
MOOS_Q = as.data.frame(Q.daily$MOOS)
MOOS_Q$day = as.Date(rownames(Q.daily))
names(MOOS_Q) = c("Discharge_Lsec", "day")
#### data wrangling - fill gaps ####
# fxn #
fillgaps15 = function(df, dat, datquotes, largegap.num){
## Document gaps >= largegap.num (1 largegap.num = 15 min) ##
# (note - the criteria of what constitutes a "large" gap should be reevaluated depending on the trend being characterized)
is.na.rle <- rle(is.na(dat))
is.na.rle$values <- is.na.rle$values & is.na.rle$lengths >= (largegap.num)
biggaps = df[inverse.rle(is.na.rle), ]
tz(biggaps$DateTime) = "America/Anchorage"
biggaps = subset(biggaps, select = "DateTime")
# Make univariate time series, covert to zoo, then to ts #
ts.xts = subset(df, select = c("DateTime",datquotes))
ts.xts<-read.zoo(ts.xts, index.column=1, format="%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
ts.xts<-as.xts(ts.xts)
# remove leading and trailing NAs #
ts.xts = na.trim(ts.xts, is.na="any")
# Apply auto.arima and kalman filter to impute missing values #
fit2 = auto.arima(ts.xts)
kal = KalmanSmooth(ts.xts, fit2$model)
id.na<-which(is.na(ts.xts))
for(i in id.na)
ts.xts[i]<-fit2$model$Z %*% kal$smooth[i,]
# revert to dataframe #
ts.df = as.data.frame((ts.xts))
ts.df$date_timeAK = as.POSIXct(row.names(ts.df), tz="America/Anchorage")
names(ts.df) = c("dat_filled", "DateTime")
# remove large gaps #
ts.df$dat_filled[ts.df$date_timeAK %in% as.POSIXct(biggaps$DateTime)] = NA
# Replace large gaps with linear interpolation #
ts.df$dat_filled = na.interpolation(ts.df$dat_filled)
ts.df = subset(ts.df, select = c("dat_filled", "DateTime"))
return(ts.df)
}
# FRCH #
FRCH$Date <- mdy(FRCH$Date)
FRCH$DateTime <- as.POSIXct(paste(FRCH$Date, FRCH$Time), format="%Y-%m-%d %H:%M:%S") # make datetime column
head(FRCH$DateTime)
#FRCH.no3 <- subset(FRCH, select = c("DateTime","nitrateuM"))
#FRCH.no3 <-  fillgaps15(FRCH.no3, FRCH.no3$nitrateuM, "nitrateuM", 16)
#FRCH.fDOM = fillgaps15(FRCH.fDOM, FRCH.fDOM$fDOM.RFU, "fDOM.RFU", 16)
FRCH.fDOM = subset(FRCH, select = c("DateTime","fDOM.QSU"))
frch.fdom.final = aggregate(fDOM.QSU ~ DateTime, FUN=mean, data = FRCH.fDOM) # Averaging 15 minute intervals
frch.fdom.1 <- cut(FRCH.fDOM$DateTime, breaks = "15 min")
frch.fdom.final <- as.data.frame(aggregate(fDOM.QSU ~ frch.fdom.1, data = FRCH.fDOM, FUN = mean)) # Averaging 15 minute intervals
frch.fdom.final$DateTime <-as.POSIXct(frch.fdom.final$frch.fdom.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
FRCH_SUNA_processed <- read_csv("~/Documents/DoD_2020/SUNA_data/from_internal_harddrive/processed/FRCH_SUNA_processed.csv") # import FRCH SUNA data
FRCH_SUNA_processed <- FRCH_SUNA_processed[, -(14:287)]  #Removing channels
FRCH.no3 <- subset(FRCH_SUNA_processed, select = c("nitrateuM", "datetimeAK"))
FRCH.no3$DateTime <-mdy_hm(FRCH_SUNA_processed$datetimeAK, tz = "GMT")
attributes(FRCH.no3$DateTime)$tzone <- 'America/Anchorage'
frch.no3.final <- as.data.frame(aggregate(nitrateuM ~ DateTime, data = FRCH.no3, FUN = mean)) # Averaging 15 minute intervals
FRCH.SpCond = subset(FRCH, select = c("DateTime","SpCond.uScm"))
frch.spcond.final = aggregate(SpCond.uScm ~ DateTime, FUN=mean, data = FRCH.SpCond) # Averaging 15 minute intervals
frch.spcond.1 <- cut(FRCH.SpCond$DateTime, breaks = "15 min")
frch.spcond.final <- as.data.frame(aggregate(SpCond.uScm ~ frch.spcond.1, data = FRCH.SpCond, FUN = mean)) # Averaging 15 minute intervals
frch.spcond.final$DateTime <-as.POSIXct(frch.spcond.final$frch.spcond.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
FRCH.turb = subset(FRCH, select = c("DateTime","Turbidity.FNU"))
frch.turb.final = aggregate(Turbidity.FNU ~ DateTime, FUN=mean, data = FRCH.turb) # Averaging 15 minute intervals
frch.turb.1 <- cut(FRCH.turb$DateTime, breaks = "15 min")
frch.turb.final <- as.data.frame(aggregate(Turbidity.FNU ~ frch.turb.1, data = FRCH.turb, FUN = mean)) # Averaging 15 minute intervals
frch.turb.final$DateTime <-as.POSIXct(frch.turb.final$frch.turb.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
FRCH = left_join(frch.final.discharge, frch.fdom.final, by="DateTime")
FRCH = left_join(FRCH, frch.no3.final, by="DateTime")
FRCH = left_join(FRCH, frch.spcond.final, by="DateTime")
FRCH = left_join(FRCH, frch.turb.final, by="DateTime")
FRCH <- FRCH[, -c(4,7,9)]
write.csv(FRCH, "Output for analysis/FRCH_final_chem_2020.csv")
plot(FRCH$MeanDischarge ~ FRCH$DateTime, type="l", xlab="", ylab="Q (L/sec)",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"))
abline(h=FRCH_bfQ_mn*2, col="red", lty=2)
abline(h=FRCH_bfQ_mn, col="red")
lines(FRCH$nitrateuM * 20 ~ FRCH$DateTime, type="l", xlab="", ylab="", col="purple",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"))
lines(FRCH$fDOM.QSU * 10 ~ FRCH$DateTime, type="l", xlab="", ylab="", col="purple",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"))
### STRT ###
STRT.no3 <- subset(STRT, select = c("DateTime", "nitrateuM"))
plot(STRT.no3$dat_filled, type="l")
names(STRT.no3) = c("DateTime", "nitrateuM")
STRT.fDOM = subset(STRT, select = c("DateTime","fDOM.QSU"))
#STRT.fDOM.1 = fillgaps15(strt.fdom.final, strt.fdom.final$fDOM.QSU, "fDOM.QSU", 16)
plot(STRT$dat_filled, type="l")
names(STRT.fDOM) = c("DateTime", "fDOM.QSU")
str(STRT.fDOM)
#strt.fdom.1 <- STRT.fDOM[, list]
#data[,list(avg=mean(temperature)),by=hour]
strt.fdom.final = aggregate(fDOM.QSU ~ DateTime, FUN=mean, data = STRT.fDOM) # Averaging 15 minute intervals
strt.no3.1 <- cut(STRT.no3$DateTime, breaks="15 min")
strt.no3.final <- as.data.frame(aggregate(nitrateuM ~ strt.no3.1, data = STRT.no3, FUN = mean)) # Averaging 15 minute intervals
strt.no3.final$DateTime <-as.POSIXct(strt.no3.final$strt.no3.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
strt.spcond = subset(STRT, select = c("DateTime","SpCond.uScm"))
strt.spcond.final = aggregate(SpCond.uScm ~ DateTime, FUN=mean, data = strt.spcond) # Averaging 15 minute intervals
strt.spcond.1 <- cut(strt.spcond$DateTime, breaks = "15 min")
strt.spcond.final <- as.data.frame(aggregate(SpCond.uScm ~ strt.spcond.1, data = strt.spcond, FUN = mean)) # Averaging 15 minute intervals
strt.spcond.final$DateTime <-as.POSIXct(strt.spcond.final$strt.spcond.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
strt.turb = subset(STRT, select = c("DateTime","Turbidity.FNU"))
strt.turb.final = aggregate(Turbidity.FNU ~ DateTime, FUN=mean, data = strt.turb) # Averaging 15 minute intervals
strt.turb.1 <- cut(strt.turb$DateTime, breaks = "15 min")
strt.turb.final <- as.data.frame(aggregate(Turbidity.FNU ~ strt.turb.1, data = strt.turb, FUN = mean)) # Averaging 15 minute intervals
strt.turb.final$DateTime <-as.POSIXct(strt.turb.final$strt.turb.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
STRT = left_join(strt.final.discharge, strt.fdom.final, by="DateTime")
STRT = left_join(STRT, strt.no3.final, by="DateTime")
STRT = left_join(STRT, strt.spcond.final, by="DateTime")
STRT = left_join(STRT, strt.turb.final, by="DateTime")
STRT <- STRT[, -c(5,7,9)]
write.csv(STRT, "Output for analysis/STRT_final_chem_2020.csv")
plot(STRT$MeanDischarge ~ STRT$DateTime, type="l", xlab="", ylab="Q (L/sec)",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"))
abline(h=STRT_bfQ_mn*2, col="red", lty=2)
abline(h=STRT_bfQ_mn, col="red")
lines(STRT$nitrateuM * 50 ~ STRT$DateTime, type="l", xlab="", ylab="", col="purple",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"))
lines(STRT$fDOM.QSU * 20 ~ STRT$DateTime, type="l", xlab="", ylab="", col="purple",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"))
head(STRT$nitrateuM)
### POKE ###
POKE.no3 <- subset(POKE, select = c("DateTime", "nitrateuM"))
POKE.no3 <- POKE.no3[!is.na(POKE.no3$DateTime), ]
#POKE.no3.fill.gaps <-  fillgaps15(poke.no3.final, poke.no3.final$nitrateuM, "nitrateuM", 16)
#plot(POKE.no3$dat_filled, type="l")
#names(POKE.no3) = c("nitrate_uM_filled", "DateTime")
POKE.fDOM = subset(POKE, select = c("DateTime","fDOM.RFU"))
#POKE.fDOM = fillgaps15(POKE.fDOM, POKE.fDOM$fDOM.RFU, "fDOM.RFU", 16)
plot(POKE$dat_filled, type="l")
names(POKE.fDOM) = c("DateTime", "fDOM.RFU")
poke.fdom.1 <- cut(POKE.fDOM$DateTime, breaks = "15 min")
poke.fdom.final <- as.data.frame(aggregate(fDOM.RFU ~ poke.fdom.1, data = POKE.fDOM, FUN = mean)) # Averaging 15 minute intervals
poke.fdom.final$DateTime <-as.POSIXct(poke.fdom.final$poke.fdom.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
poke.no3.1 <- cut(POKE.no3$DateTime, breaks="15 min")
poke.no3.final <- as.data.frame(aggregate(nitrateuM ~ poke.no3.1, data = POKE.no3, FUN = mean)) # Averaging 15 minute intervals
poke.no3.final$DateTime <-as.POSIXct(poke.no3.final$poke.no3.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
poke.spcond = subset(POKE, select = c("DateTime","SpCond.uScm"))
poke.spcond.final = aggregate(SpCond.uScm ~ DateTime, FUN=mean, data = poke.spcond) # Averaging 15 minute intervals
poke.spcond.1 <- cut(poke.spcond$DateTime, breaks = "15 min")
poke.spcond.final <- as.data.frame(aggregate(SpCond.uScm ~ poke.spcond.1, data = poke.spcond, FUN = mean)) # Averaging 15 minute intervals
poke.spcond.final$DateTime <-as.POSIXct(poke.spcond.final$poke.spcond.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
poke.turb = subset(STRT, select = c("DateTime","Turbidity.FNU"))
poke.turb.final = aggregate(Turbidity.FNU ~ DateTime, FUN=mean, data = poke.turb) # Averaging 15 minute intervals
poke.turb.1 <- cut(poke.turb$DateTime, breaks = "15 min")
poke.turb.final <- as.data.frame(aggregate(Turbidity.FNU ~ poke.turb.1, data = poke.turb, FUN = mean)) # Averaging 15 minute intervals
poke.turb.final$DateTime <-as.POSIXct(poke.turb.final$poke.turb.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
POKE = left_join(poke.final.discharge, poke.fdom.final, by="DateTime")
POKE = left_join(POKE, poke.no3.final, by="DateTime")
POKE = left_join(POKE, poke.spcond.final, by="DateTime")
POKE = left_join(POKE, poke.turb.final, by="DateTime")
POKE <- POKE[, -c(4,6,8,10)]
write.csv(POKE, "Output for analysis/POKE_final_chem_2020.csv")
plot(POKE$MeanDischarge ~ POKE$DateTime, type="l", xlab="", ylab="Q (L/sec)",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"))
abline(h=POKE_bfQ_mn*2, col="red", lty=2)
abline(h=POKE_bfQ_mn, col="red")
lines(POKE$nitrateuM * 30 ~ POKE$DateTime, type="l", xlab="", ylab="", col="purple",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"))
lines(POKE$fDOM.RFU * 30 ~ POKE$DateTime, type="l", xlab="", ylab="", col="purple",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"))
### VAUL ###
VAUL.no3 <- subset(VAUL, select = c("DateTime", "nitrateuM"))
#plot(VAUL.no3$dat_filled, type="l")
#names(VAUL.no3) = c("nitrate_uM_filled", "DateTime")
VAUL.fDOM = subset(VAUL, select = c("DateTime","fDOM.QSU"))
#VAUL.fDOM = fillgaps15(VAUL.fDOM, VAUL.fDOM$fDOM.RFU, "fDOM.RFU", 16)
#plot(VAUL$dat_filled, type="l")
#names(VAUL.fDOM) = c("DateTime", "fDOM.QSU")
vaul.fdom.final = aggregate(fDOM.QSU ~ DateTime, FUN=mean, data = VAUL.fDOM) # Averaging 15 minute intervals
vaul.no3.1 <- cut(VAUL.no3$DateTime, breaks="15 min")
vaul.no3.final <- as.data.frame(aggregate(nitrateuM ~ vaul.no3.1, data = VAUL.no3, FUN = mean)) # Averaging 15 minute intervals
vaul.no3.final$DateTime <-as.POSIXct(vaul.no3.final$vaul.no3.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
vaul.spcond = subset(VAUL, select = c("DateTime","SpCond.uScm"))
vaul.spcond.final = aggregate(SpCond.uScm ~ DateTime, FUN=mean, data = vaul.spcond) # Averaging 15 minute intervals
vaul.spcond.1 <- cut(vaul.spcond$DateTime, breaks = "15 min")
vaul.spcond.final <- as.data.frame(aggregate(SpCond.uScm ~ vaul.spcond.1, data = vaul.spcond, FUN = mean)) # Averaging 15 minute intervals
vaul.spcond.final$DateTime <-as.POSIXct(vaul.spcond.final$vaul.spcond.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
vaul.turb = subset(STRT, select = c("DateTime","Turbidity.FNU"))
vaul.turb.final = aggregate(Turbidity.FNU ~ DateTime, FUN=mean, data = vaul.turb) # Averaging 15 minute intervals
vaul.turb.1 <- cut(vaul.turb$DateTime, breaks = "15 min")
vaul.turb.final <- as.data.frame(aggregate(Turbidity.FNU ~ vaul.turb.1, data = vaul.turb, FUN = mean)) # Averaging 15 minute intervals
vaul.turb.final$DateTime <-as.POSIXct(vaul.turb.final$vaul.turb.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
#VAUL.no3.2 <-  fillgaps15(vaul.no3.final, vaul.no3.final$nitrateuM, "nitrateuM", 16)
VAUL = left_join(vaul.final.discharge, vaul.fdom.final, by="DateTime")
VAUL = left_join(VAUL, vaul.no3.final, by="DateTime")
VAUL = left_join(VAUL, vaul.spcond.final, by="DateTime")
VAUL = left_join(VAUL, vaul.turb.final, by="DateTime")
VAUL <- VAUL[, -c(5,7,9)]
write.csv(VAUL, "Output for analysis/VAUL_final_chem_2020.csv")
plot(VAUL$MeanDischarge ~ VAUL$DateTime, type="l", xlab="", ylab="Q (L/sec)",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"))
abline(h=FRCH_bfQ_mn*2, col="red", lty=2)
abline(h=FRCH_bfQ_mn, col="red")
lines(VAUL$nitrateuM * 20 ~ VAUL$DateTime, type="l", xlab="", ylab="", col="purple",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"))
lines(VAUL$fDOM.QSU * 1 ~ VAUL$DateTime, type="l", xlab="", ylab="", col="purple",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"))
### MOOS ###
MOOS.no3 <- subset(MOOS, select = c("DateTime", "nitrateuM"))
#MOOS.no3 <-  fillgaps15(MOOS.no3, MOOS.no3$nitrateuM, "nitrateuM", 16)
plot(MOOS.no3$dat_filled, type="l")
MOOS.fDOM = subset(MOOS, select = c("DateTime","fDOM.QSU"))
names(MOOS.fDOM) = c("DateTime", "fDOM.QSU")
#MOOS.fDOM = fillgaps15(MOOS.fDOM, MOOS.fDOM$fDOM.QSU, "fDOM.QSU", 16)
plot(MOOS$dat_filled, type="l")
moos.fdom.final = aggregate(fDOM.QSU ~ DateTime, FUN = mean, data = MOOS.fDOM) # averaging every burst at 15 min intervals
moos.no3.1 <- cut(MOOS.no3$DateTime, breaks="15 min")
moos.no3.final <- as.data.frame(aggregate(nitrateuM ~ moos.no3.1, data = MOOS.no3, FUN = mean)) # Averaging 15 minute intervals
moos.no3.final$DateTime <-as.POSIXct(moos.no3.final$moos.no3.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
moos.spcond = subset(MOOS, select = c("DateTime","SpCond.uScm"))
moos.spcond.final = aggregate(SpCond.uScm ~ DateTime, FUN=mean, data = moos.spcond) # Averaging 15 minute intervals
moos.spcond.1 <- cut(moos.spcond$DateTime, breaks = "15 min")
moos.spcond.final <- as.data.frame(aggregate(SpCond.uScm ~ moos.spcond.1, data = moos.spcond, FUN = mean)) # Averaging 15 minute intervals
moos.spcond.final$DateTime <-as.POSIXct(moos.spcond.final$moos.spcond.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
moos.turb = subset(STRT, select = c("DateTime","Turbidity.FNU"))
moos.turb.final = aggregate(Turbidity.FNU ~ DateTime, FUN=mean, data = moos.turb) # Averaging 15 minute intervals
moos.turb.1 <- cut(moos.turb$DateTime, breaks = "15 min")
moos.turb.final <- as.data.frame(aggregate(Turbidity.FNU ~ moos.turb.1, data = moos.turb, FUN = mean)) # Averaging 15 minute intervals
moos.turb.final$DateTime <-as.POSIXct(moos.turb.final$moos.turb.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
MOOS = left_join(moos.final.discharge, moos.fdom.final, by="DateTime")
MOOS = left_join(MOOS, moos.no3.final, by="DateTime")
MOOS = left_join(MOOS, moos.spcond.final, by="DateTime")
MOOS = left_join(MOOS, moos.turb.final, by="DateTime")
MOOS <- MOOS[, -c(5,7,9)]
write.csv(MOOS, "Output for analysis/MOOS_final_chem_2020.csv")
plot(MOOS$MeanDischarge ~ MOOS$DateTime, type="l", xlab="", ylab="Q (L/sec)",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"))
abline(h=MOOS_bfQ_mn*2, col="red", lty=2)
abline(h=MOOS_bfQ_mn, col="red")
lines(MOOS$nitrateuM * 60 ~ MOOS$DateTime, type="l", xlab="", ylab="", col="purple",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"))
lines(MOOS$fDOM.QSU * 10 ~ MOOS$DateTime, type="l", xlab="", ylab="", col="purple",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"))
#### Baseflow Separation ####
any(is.na(FRCH_Q$day))
any(is.na(FRCH_Q$Discharge_Lsec))
FRCH_Q <- na.omit(FRCH_Q) # Remove 7 NaNs  # 132 rows to 125 rows
any(is.na(STRT_Q$day))
any(is.na(STRT_Q$Discharge_Lsec))
STRT_Q <- na.omit(STRT_Q) # Remove 19 NaNs
any(is.na(POKE_Q$day))
any(is.na(POKE_Q$Discharge_Lsec))
POKE_Q <- na.omit(POKE_Q) # Remove 4 NaNs
any(is.na(VAUL_Q$day))
any(is.na(VAUL_Q$Discharge_Lsec))
VAUL_Q <- na.omit(VAUL_Q) # Remove 21 NaNs
any(is.na(MOOS_Q$day))
any(is.na(MOOS_Q$Discharge_Lsec))
MOOS_Q <- na.omit(MOOS_Q) # Remove 11 NaNs
### examine the recursive digital filter at .9, .925, .95 levels ###
plot(FRCH$MeanDischarge ~ FRCH$DateTime, type = "l", xlab = "", ylab = "Q (L/sec)",
xlim =  as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"),
ylim = c(0, 3000), col="blue")
#
plot(poke.final.discharge$MeanDischarge ~ poke.final.discharge$DateTime, type="l", xlab="", ylab="Q (L/sec)",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"),
ylim = c(0,3000), col="blue")
plot(vaul.final.discharge$MeanDischarge ~ vaul.final.discharge$DateTime, type="l", xlab="", ylab="Q (L/sec)",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"),
ylim = c(0,3000), col="blue")
plot(strt.final.discharge$MeanDischarge ~ strt.final.discharge$DateTime, type="l", xlab="", ylab="Q (L/sec)",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"),
ylim = c(0,3000), col="blue")
plot(moos.final.discharge$MeanDischarge ~ moos.final.discharge$DateTime, type="l", xlab="", ylab="Q (L/sec)",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"),
ylim = c(0,3000), col="blue")
### Hydrograph Separation ###
#
FRCH_Q_bf = BaseflowSeparation(frch.final.discharge$MeanDischarge, filter_parameter = 0.90, passes = 3)
hydrograph(input=subset(FRCH_Q, select = c(day, Discharge_Lsec)), streamflow2=FRCH_Q_bf$bt)
#
strt.final.discharge <- strt.final.discharge[-c(10815:10817), ] # clean Nas.
STRT_Q_bf = BaseflowSeparation(strt.final.discharge$MeanDischarge, filter_parameter = 0.90, passes = 3)
hydrograph(input=subset(STRT_Q, select = c(day, Discharge_Lsec)), streamflow2=STRT_Q_bf$bt)
#
POKE_Q_bf = BaseflowSeparation(poke.final.discharge$MeanDischarge, filter_parameter = 0.90, passes = 3)
hydrograph(input=subset(POKE_Q, select = c(day, Discharge_Lsec)), streamflow2=POKE_Q_bf$bt)
#
VAUL_Q_bf = BaseflowSeparation(vaul.final.discharge$MeanDischarge, filter_parameter = 0.90, passes = 3)
hydrograph(input=subset(VAUL_Q, select = c(day, Discharge_Lsec)), streamflow2=VAUL_Q_bf$bt)
MOOS_Q_bf = BaseflowSeparation(moos.final.discharge$MeanDischarge, filter_parameter = 0.90, passes = 3)
hydrograph(input=subset(MOOS_Q, select = c(day, Discharge_Lsec)), streamflow2=MOOS_Q_bf$bt)
###.925 ###
FRCH_Q_bf = BaseflowSeparation(frch.final.discharge$MeanDischarge, filter_parameter = 0.925, passes = 3)
hydrograph(input=subset(FRCH_Q, select = c(day, Discharge_Lsec)), streamflow2=FRCH_Q_bf$bt)
#
STRT_Q_bf = BaseflowSeparation(strt.final.discharge$MeanDischarge, filter_parameter = 0.925, passes = 3)
hydrograph(input=subset(STRT_Q, select = c(day, Discharge_Lsec)), streamflow2=STRT_Q_bf$bt)
#
POKE_Q_bf = BaseflowSeparation(poke.final.discharge$MeanDischarge, filter_parameter = 0.925, passes = 3)
hydrograph(input=subset(POKE_Q, select = c(day, Discharge_Lsec)), streamflow2=POKE_Q_bf$bt)
#
VAUL_Q_bf = BaseflowSeparation(vaul.final.discharge$MeanDischarge, filter_parameter = 0.925, passes = 3)
hydrograph(input=subset(VAUL_Q, select = c(day, Discharge_Lsec)), streamflow2=VAUL_Q_bf$bt)
MOOS_Q_bf = BaseflowSeparation(moos.final.discharge$MeanDischarge, filter_parameter = 0.925, passes = 3)
hydrograph(input=subset(MOOS_Q, select = c(day, Discharge_Lsec)), streamflow2=MOOS_Q_bf$bt)
### .95 ###
FRCH_Q_bf = BaseflowSeparation(frch.final.discharge$MeanDischarge, filter_parameter = 0.95, passes = 3)
hydrograph(input=subset(FRCH_Q, select = c(day, Discharge_Lsec)), streamflow2=FRCH_Q_bf$bt)
#
STRT_Q_bf = BaseflowSeparation(strt.final.discharge$MeanDischarge, filter_parameter = 0.95, passes = 3)
hydrograph(input=subset(STRT_Q, select = c(day, Discharge_Lsec)), streamflow2=STRT_Q_bf$bt)
#
POKE_Q_bf = BaseflowSeparation(poke.final.discharge$MeanDischarge, filter_parameter = 0.95, passes = 3)
hydrograph(input=subset(POKE_Q, select = c(day, Discharge_Lsec)), streamflow2=POKE_Q_bf$bt)
#
VAUL_Q_bf = BaseflowSeparation(vaul.final.discharge$MeanDischarge, filter_parameter = 0.95, passes = 3)
hydrograph(input=subset(VAUL_Q, select = c(day, Discharge_Lsec)), streamflow2=VAUL_Q_bf$bt)
MOOS_Q_bf = BaseflowSeparation(moos.final.discharge$MeanDischarge, filter_parameter = 0.95, passes = 3)
hydrograph(input=subset(MOOS_Q, select = c(day, Discharge_Lsec)), streamflow2=MOOS_Q_bf$bt)
#### Deliniate storms in FRCH ####
# ID storms: Any events where Q reached 2X mean base flow
# Pick starting points: manually select inflection pt when Q began to rise
# Pick ending points: manually select pt when Q reached pre-storm baseflow OR when another event occurred
FRCH_bfQ_mn = mean(FRCH_Q_bf$bt)
FRCH_bfQ_mn
FRCH_bfQ_mn*2
STRT_bfQ_mn = mean(STRT_Q_bf$bt)
STRT_bfQ_mn
STRT_bfQ_mn*2
VAUL_bfQ_mn = mean(VAUL_Q_bf$bt)
VAUL_bfQ_mn
VAUL_bfQ_mn*2
POKE_bfQ_mn = mean(POKE_Q_bf$bt)
POKE_bfQ_mn
POKE_bfQ_mn*2
MOOS_bfQ_mn = mean(MOOS_Q_bf$bt)
MOOS_bfQ_mn
MOOS_bfQ_mn*2
### Merge Discharge and Precip ###
frch.precip.discharge <- full_join(frch.final.discharge, FRCH.st) # merging precip data and discharge
strt.precip.discharge <- full_join(strt.final.discharge, STRT.st.final) # merging precip data and discharge
vaul.precip.discharge <- full_join(vaul.final.discharge, VAUL.st.final) # merging precip data and discharge
poke.precip.discharge <- full_join(poke.final.discharge, poke.gauge) # merging precip data and discharge
### Sum daily discharge ###
frch.precip.discharge <- frch.precip.discharge[-c(1:3),] # Remove out of water discharge
frch.precip.discharge$twentyfour <- rollapplyr(frch.precip.discharge$inst_rainfall_mm, 96, sum, na.rm = TRUE, fill = NA, partial = TRUE)
frch.precip.discharge$fourtyeight <- rollapplyr(frch.precip.discharge$inst_rainfall_mm, 192, sum, na.rm = TRUE, fill = NA, partial = TRUE)
strt.precip.discharge$twentyfour <- rollapplyr(strt.precip.discharge$Precip, 96, sum, na.rm = TRUE, fill = NA, partial = TRUE)
strt.precip.discharge$fourtyeight <- rollapplyr(strt.precip.discharge$Precip, 192, sum, na.rm = TRUE, fill = NA, partial = TRUE)
vaul.precip.discharge$twentyfour <- rollapplyr(vaul.precip.discharge$inst_rainfall_mm, 96, sum, na.rm = TRUE, fill = NA, partial = TRUE)
vaul.precip.discharge$fourtyeight <- rollapplyr(vaul.precip.discharge$inst_rainfall_mm, 192, sum, na.rm = TRUE, fill = NA, partial = TRUE)
poke.precip.discharge$twentyfour <- rollapplyr(poke.precip.discharge$Precip, 96, sum, na.rm = TRUE, fill = NA, partial = TRUE)
poke.precip.discharge$fourtyeight <- rollapplyr(poke.precip.discharge$Precip, 192, sum, na.rm = TRUE, fill = NA, partial = TRUE)
# Greater than 5 #
frch.five.twenty.four <- frch.precip.discharge[which(frch.precip.discharge$twentyfour >= 5),] # twenty four hour period where the precip is 5
frch.five.fourty.eight <- frch.precip.discharge[which(frch.precip.discharge$fourtyeight >= 5),] # fourty eight hour period where the precip is greater than 10
strt.five.twenty.four <- strt.precip.discharge[which(strt.precip.discharge$twentyfour >= 5),] # twenty four hour period where the precip is 5
strt.five.fourty.eight <- strt.precip.discharge[which(strt.precip.discharge$fourtyeight >= 5),] # fourty eight hour period where the precip is greater than 10
vaul.five.twenty.four <- vaul.precip.discharge[which(vaul.precip.discharge$twentyfour >= 5),] # twenty four hour period where the precip is 5
vaul.five.fourty.eight <- vaul.precip.discharge[which(vaul.precip.discharge$fourtyeight >= 5),] # fourty eight hour period where the precip is greater than 10
poke.five.twenty.four <- poke.precip.discharge[which(poke.precip.discharge$twentyfour >= 5),] # twenty four hour period where the precip is 5
poke.five.fourty.eight <- poke.precip.discharge[which(poke.precip.discharge$fourtyeight >= 5),] # fourty eight hour period where the precip is greater than 10
# Greater than 10 #
frch.ten.twenty.four <- frch.precip.discharge[which(frch.precip.discharge$twentyfour >= 10),] # twenty four hour period where the precip is 10
frch.ten.fourty.eight <- frch.precip.discharge[which(frch.precip.discharge$fourtyeight >= 10),] # fourty eight hour period where the precip is greater than 10
strt.ten.twenty.four <- strt.precip.discharge[which(strt.precip.discharge$twentyfour >= 10),] # twenty four hour period where the precip is 10
strt.ten.fourty.eight <- strt.precip.discharge[which(strt.precip.discharge$fourtyeight >= 10),] # fourty eight hour period where the precip is greater than 10
vaul.ten.twenty.four <- vaul.precip.discharge[which(vaul.precip.discharge$twentyfour >= 10),] # twenty four hour period where the precip is 10
vaul.ten.fourty.eight <- vaul.precip.discharge[which(vaul.precip.discharge$fourtyeight >= 10),] # fourty eight hour period where the precip is greater than 10
poke.ten.twenty.four <- poke.precip.discharge[which(poke.precip.discharge$twentyfour >= 10),] # twenty four hour period where the precip is 10
poke.ten.fourty.eight <- poke.precip.discharge[which(poke.precip.discharge$fourtyeight >= 10),] # fourty eight hour period where the precip is greater than 10
write.csv(frch.precip.discharge, "frch.precip.discharge.csv", row.names = FALSE)
write.csv(strt.precip.discharge, "strt.precip.discharge.csv", row.names = FALSE)
write.csv(vaul.precip.discharge, "vaul.precip.discharge.csv", row.names = FALSE)
write.csv(poke.precip.discharge, "poke.precip.discharge.csv", row.names = FALSE)
#
#frch.gauge$date <- as.Date(frch.gauge$DateTime)# breaking into days
#daily.sum <- aggregate(frch.gauge["inst_rainfall_mm"], by = frch.gauge["date"], sum) # summing days
#frch.ten <- daily.sum[which(daily.sum$inst_rainfall_mm >= 10),] # anything greater than 10 is filtered
#strt.gauge$date <- as.Date(strt.gauge$DateTime)
#strt.daily.sum <- aggregate(strt.gauge["inst_rainfall_mm"], by = strt.gauge["date"], sum)
#strt.ten <- strt.daily.sum[which(strt.daily.sum$inst_rainfall_mm >= 10),]
#vaul.gauge$date <- as.Date(vaul.gauge$DateTime)
#vaul.daily.sum <- aggregate(vaul.gauge["inst_rainfall_mm"], by = vaul.gauge["date"], sum)
#vaul.ten <- vaul.daily.sum[which(vaul.daily.sum$inst_rainfall_mm >= 10),]
#par(mfrow=c(1,1))
#precip.cariboupeak$date <- as.Date(precip.cariboupeak$DateTime)
#poke.daily.sum <- aggregate(precip.cariboupeak["Precip"], by = precip.cariboupeak["date"], sum)
#poke.ten <- poke.daily.sum[which(poke.daily.sum$Precip >= 10),]
#plot(FRCH_Q$Discharge_Lsec ~ FRCH_Q$day, type="l", xlab="", ylab="Q (L/sec)",ylim = c(0,3000), col="blue", main="FRCH")
#lines(FRCH_Q_bf$bt ~ FRCH_Q$day, col="red")
#lines(FRCH_Q_bf$bt*1.3 ~ FRCH_Q$day, col="red", lty = 2)
#lines((FRCH_Q_bf$bt*5) ~ FRCH_Q$day, col="red", lty=2)
#abline(h = FRCH_bfQ_mn*2, col="red", lty=2)
### Discharge/Chem/Precip ###
# FRCH #
### Import precipitation data into the *ALL document ###
# FRCH rain gauge installed on the 11th of June.
plot(FRCH.st$inst_rainfall_mm ~ FRCH.st$DateTime, type="h",
xlim = as.POSIXct(c("2020-06-01 0:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"),
ylim = c(20,0),
axes=F, xlab="", ylab="")
axis(side = 4)
par(mfrow=c(1,1))
abline(v = as.POSIXct(frch.five.fourty.eight$DateTime), col = "yellow", lwd = 0.1)
abline(v = as.POSIXct(frch.five.twenty.four$DateTime), col="green", lwd = 0.1)
par(new = T)
plot(FRCH.st$inst_rainfall_mm ~ FRCH.st$DateTime, type="h",
xlim = as.POSIXct(c("2020-06-01 0:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"),
ylim = c(25,0),
axes=F, xlab="", ylab="")
par(new = T)
plot(FRCH$MeanDischarge ~ FRCH$DateTime, type="l", xlab="", ylab="Q (L/sec)",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"))
abline(h=FRCH_bfQ_mn*2, col="red", lty=2)
abline(h=FRCH_bfQ_mn, col="red")
lines(FRCH$nitrateuM * 20 ~ FRCH$DateTime, type="l", xlab="", ylab="", col="purple",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"))
lines(FRCH$fDOM.QSU * 10 ~ FRCH$DateTime, type="l", xlab="", ylab="", col="purple",
xlim = as.POSIXct(c("2020-06-01 00:00:00","2020-10-15 00:00:00"), tz="America/Anchorage"))
VAUL_storm14_09_06_SPC <- read_csv("~/Documents/Storms/Storm_Events/2020/VAUL/VAUL_storm14_09_06_SPC.csv")
head
head(VAUL_storm14_09_06_SPC$valuedatetime)
