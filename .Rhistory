STRT.fDOM.1 = fillgaps15(strt.fdom.final, strt.fdom.final$fDOM.QSU, "fDOM.QSU", 16)
plot(STRT$dat_filled, type="l")
names(STRT.fDOM) = c("DateTime", "fDOM.QSU")
str(STRT.fDOM)
#
### STRT ###
STRT.no3 <- subset(STRT, select = c("DateTime", "nitrateuM"))
names(STRT.no3) = c("DateTime", "nitrateuM")
STRT.fDOM = subset(STRT, select = c("DateTime","fDOM.QSU"))
STRT.fDOM.1 = fillgaps15(strt.fdom.final, strt.fdom.final$fDOM.QSU, "fDOM.QSU", 16)
names(STRT.fDOM) = c("DateTime", "fDOM.QSU")
strt.fdom.final = aggregate(fDOM.QSU ~ DateTime, FUN=mean, data = STRT.fDOM) # Averaging 15 minute intervals
strt.no3.1 <- cut(STRT.no3$DateTime, breaks="15 min")
strt.no3.final <- as.data.frame(aggregate(nitrateuM ~ strt.no3.1, data = STRT.no3, FUN = mean)) # Averaging 15 minute intervals
strt.no3.final$DateTime <-as.POSIXct(strt.no3.final$strt.no3.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
STRT.no3.1 = fillgaps15(strt.no3.final, strt.no3.final$nitrateuM, "nitrateuM", 16)
STRT = left_join(strt.final.discharge, strt.fdom.final, by="DateTime")
STRT = left_join(STRT, strt.no3.final, by="DateTime")
### VAUL ###
VAUL.no3 <- subset(VAUL, select = c("DateTime", "nitrateuM"))
VAUL.no3.2 <-  fillgaps15(vaul.no3.final, vaul.no3.final$nitrateuM, "nitrateuM", 16)
VAUL.fDOM = subset(VAUL, select = c("DateTime","fDOM.QSU"))
vaul.fdom.final = aggregate(fDOM.QSU ~ DateTime, FUN=mean, data = VAUL.fDOM) # Averaging 15 minute intervals
### VAUL ###
VAUL.no3 <- subset(VAUL, select = c("DateTime", "nitrateuM"))
VAUL.fDOM = subset(VAUL, select = c("DateTime","fDOM.QSU"))
vaul.fdom.final = aggregate(fDOM.QSU ~ DateTime, FUN=mean, data = VAUL.fDOM) # Averaging 15 minute intervals
vaul.no3.1 <- cut(VAUL.no3$DateTime, breaks="15 min")
vaul.no3.final <- as.data.frame(aggregate(nitrateuM ~ vaul.no3.1, data = VAUL.no3, FUN = mean)) # Averaging 15 minute intervals
vaul.no3.final$DateTime <-as.POSIXct(vaul.no3.final$vaul.no3.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
VAUL = left_join(vaul.final.discharge, vaul.fdom.final, by="DateTime")
VAUL = left_join(VAUL, vaul.no3.final, by="DateTime")
### MOOS ###
MOOS.no3 <- subset(MOOS, select = c("DateTime", "nitrateuM"))
MOOS.fDOM = subset(MOOS, select = c("DateTime","fDOM.QSU"))
names(MOOS.fDOM) = c("DateTime", "fDOM.QSU")
MOOS.fDOM = fillgaps15(MOOS.fDOM, MOOS.fDOM$fDOM.QSU, "fDOM.QSU", 16)
moos.fdom.final = aggregate(fDOM.QSU ~ DateTime, FUN = mean, data = MOOS.fDOM) # averaging every burst at 15 min intervals
moos.no3.1 <- cut(MOOS.no3$DateTime, breaks="15 min")
moos.no3.final <- as.data.frame(aggregate(nitrateuM ~ moos.no3.1, data = MOOS.no3, FUN = mean)) # Averaging 15 minute intervals
moos.no3.final$DateTime <-as.POSIXct(moos.no3.final$moos.no3.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
MOOS = left_join(moos.final.discharge, moos.fdom.final, by="DateTime")
MOOS = left_join(MOOS, moos.no3.final, by="DateTime")
any(is.na(FRCH_Q$day))
any(is.na(FRCH_Q$Discharge_Lsec))
FRCH_Q <- na.omit(FRCH_Q) # Remove 7 NaNs  # 132 rows to 125 rows
any(is.na(STRT_Q$day))
any(is.na(STRT_Q$Discharge_Lsec))
STRT_Q <- na.omit(STRT_Q) # Remove 19 NaNs
any(is.na(POKE_Q$day))
any(is.na(POKE_Q$Discharge_Lsec))
POKE_Q <- na.omit(POKE_Q) # Remove 4 NaNs
any(is.na(VAUL_Q$day))
any(is.na(VAUL_Q$Discharge_Lsec))
VAUL_Q <- na.omit(VAUL_Q) # Remove 21 NaNs
any(is.na(MOOS_Q$day))
any(is.na(MOOS_Q$Discharge_Lsec))
MOOS_Q <- na.omit(MOOS_Q) # Remove 11 NaNs
### Hydrograph Separation ###
#
FRCH_Q_bf = BaseflowSeparation(frch.final.discharge$MeanDischarge, filter_parameter = 0.90, passes = 3)
hydrograph(input=subset(FRCH_Q, select = c(day, Discharge_Lsec)), streamflow2=FRCH_Q_bf$bt)
#
strt.final.discharge <- strt.final.discharge[-c(10815:10817), ] # clean Nas.
STRT_Q_bf = BaseflowSeparation(strt.final.discharge$MeanDischarge, filter_parameter = 0.90, passes = 3)
hydrograph(input=subset(STRT_Q, select = c(day, Discharge_Lsec)), streamflow2=STRT_Q_bf$bt)
#
POKE_Q_bf = BaseflowSeparation(poke.final.discharge$MeanDischarge, filter_parameter = 0.90, passes = 3)
hydrograph(input=subset(POKE_Q, select = c(day, Discharge_Lsec)), streamflow2=POKE_Q_bf$bt)
#
VAUL_Q_bf = BaseflowSeparation(vaul.final.discharge$MeanDischarge, filter_parameter = 0.90, passes = 3)
hydrograph(input=subset(VAUL_Q, select = c(day, Discharge_Lsec)), streamflow2=VAUL_Q_bf$bt)
MOOS_Q_bf = BaseflowSeparation(moos.final.discharge$MeanDischarge, filter_parameter = 0.90, passes = 3)
hydrograph(input=subset(MOOS_Q, select = c(day, Discharge_Lsec)), streamflow2=MOOS_Q_bf$bt)
###.925 ###
FRCH_Q_bf = BaseflowSeparation(frch.final.discharge$MeanDischarge, filter_parameter = 0.925, passes = 3)
hydrograph(input=subset(FRCH_Q, select = c(day, Discharge_Lsec)), streamflow2=FRCH_Q_bf$bt)
#
STRT_Q_bf = BaseflowSeparation(strt.final.discharge$MeanDischarge, filter_parameter = 0.925, passes = 3)
hydrograph(input=subset(STRT_Q, select = c(day, Discharge_Lsec)), streamflow2=STRT_Q_bf$bt)
#
POKE_Q_bf = BaseflowSeparation(poke.final.discharge$MeanDischarge, filter_parameter = 0.925, passes = 3)
hydrograph(input=subset(POKE_Q, select = c(day, Discharge_Lsec)), streamflow2=POKE_Q_bf$bt)
#
VAUL_Q_bf = BaseflowSeparation(vaul.final.discharge$MeanDischarge, filter_parameter = 0.925, passes = 3)
hydrograph(input=subset(VAUL_Q, select = c(day, Discharge_Lsec)), streamflow2=VAUL_Q_bf$bt)
MOOS_Q_bf = BaseflowSeparation(moos.final.discharge$MeanDischarge, filter_parameter = 0.925, passes = 3)
hydrograph(input=subset(MOOS_Q, select = c(day, Discharge_Lsec)), streamflow2=MOOS_Q_bf$bt)
### .95 ###
FRCH_Q_bf = BaseflowSeparation(frch.final.discharge$MeanDischarge, filter_parameter = 0.95, passes = 3)
hydrograph(input=subset(FRCH_Q, select = c(day, Discharge_Lsec)), streamflow2=FRCH_Q_bf$bt)
#
STRT_Q_bf = BaseflowSeparation(strt.final.discharge$MeanDischarge, filter_parameter = 0.95, passes = 3)
hydrograph(input=subset(STRT_Q, select = c(day, Discharge_Lsec)), streamflow2=STRT_Q_bf$bt)
#
POKE_Q_bf = BaseflowSeparation(poke.final.discharge$MeanDischarge, filter_parameter = 0.95, passes = 3)
hydrograph(input=subset(POKE_Q, select = c(day, Discharge_Lsec)), streamflow2=POKE_Q_bf$bt)
#
VAUL_Q_bf = BaseflowSeparation(vaul.final.discharge$MeanDischarge, filter_parameter = 0.95, passes = 3)
hydrograph(input=subset(VAUL_Q, select = c(day, Discharge_Lsec)), streamflow2=VAUL_Q_bf$bt)
MOOS_Q_bf = BaseflowSeparation(moos.final.discharge$MeanDischarge, filter_parameter = 0.95, passes = 3)
hydrograph(input=subset(MOOS_Q, select = c(day, Discharge_Lsec)), streamflow2=MOOS_Q_bf$bt)
### Hydrograph Separation ###
#
FRCH_Q_bf = BaseflowSeparation(frch.final.discharge$MeanDischarge, filter_parameter = 0.90, passes = 3)
hydrograph(input=subset(FRCH_Q, select = c(day, Discharge_Lsec)), streamflow2=FRCH_Q_bf$bt)
#
strt.final.discharge <- strt.final.discharge[-c(10815:10817), ] # clean Nas.
STRT_Q_bf = BaseflowSeparation(strt.final.discharge$MeanDischarge, filter_parameter = 0.90, passes = 3)
hydrograph(input=subset(STRT_Q, select = c(day, Discharge_Lsec)), streamflow2=STRT_Q_bf$bt)
#
POKE_Q_bf = BaseflowSeparation(poke.final.discharge$MeanDischarge, filter_parameter = 0.90, passes = 3)
hydrograph(input=subset(POKE_Q, select = c(day, Discharge_Lsec)), streamflow2=POKE_Q_bf$bt)
#
VAUL_Q_bf = BaseflowSeparation(vaul.final.discharge$MeanDischarge, filter_parameter = 0.90, passes = 3)
hydrograph(input=subset(VAUL_Q, select = c(day, Discharge_Lsec)), streamflow2=VAUL_Q_bf$bt)
MOOS_Q_bf = BaseflowSeparation(moos.final.discharge$MeanDischarge, filter_parameter = 0.90, passes = 3)
hydrograph(input=subset(MOOS_Q, select = c(day, Discharge_Lsec)), streamflow2=MOOS_Q_bf$bt)
###.925 ###
FRCH_Q_bf = BaseflowSeparation(frch.final.discharge$MeanDischarge, filter_parameter = 0.925, passes = 3)
hydrograph(input=subset(FRCH_Q, select = c(day, Discharge_Lsec)), streamflow2=FRCH_Q_bf$bt)
#
STRT_Q_bf = BaseflowSeparation(strt.final.discharge$MeanDischarge, filter_parameter = 0.925, passes = 3)
hydrograph(input=subset(STRT_Q, select = c(day, Discharge_Lsec)), streamflow2=STRT_Q_bf$bt)
#
POKE_Q_bf = BaseflowSeparation(poke.final.discharge$MeanDischarge, filter_parameter = 0.925, passes = 3)
hydrograph(input=subset(POKE_Q, select = c(day, Discharge_Lsec)), streamflow2=POKE_Q_bf$bt)
#
VAUL_Q_bf = BaseflowSeparation(vaul.final.discharge$MeanDischarge, filter_parameter = 0.925, passes = 3)
hydrograph(input=subset(VAUL_Q, select = c(day, Discharge_Lsec)), streamflow2=VAUL_Q_bf$bt)
MOOS_Q_bf = BaseflowSeparation(moos.final.discharge$MeanDischarge, filter_parameter = 0.925, passes = 3)
hydrograph(input=subset(MOOS_Q, select = c(day, Discharge_Lsec)), streamflow2=MOOS_Q_bf$bt)
### .95 ###
FRCH_Q_bf = BaseflowSeparation(frch.final.discharge$MeanDischarge, filter_parameter = 0.95, passes = 3)
hydrograph(input=subset(FRCH_Q, select = c(day, Discharge_Lsec)), streamflow2=FRCH_Q_bf$bt)
#
STRT_Q_bf = BaseflowSeparation(strt.final.discharge$MeanDischarge, filter_parameter = 0.95, passes = 3)
hydrograph(input=subset(STRT_Q, select = c(day, Discharge_Lsec)), streamflow2=STRT_Q_bf$bt)
#
POKE_Q_bf = BaseflowSeparation(poke.final.discharge$MeanDischarge, filter_parameter = 0.95, passes = 3)
hydrograph(input=subset(POKE_Q, select = c(day, Discharge_Lsec)), streamflow2=POKE_Q_bf$bt)
#
VAUL_Q_bf = BaseflowSeparation(vaul.final.discharge$MeanDischarge, filter_parameter = 0.95, passes = 3)
hydrograph(input=subset(VAUL_Q, select = c(day, Discharge_Lsec)), streamflow2=VAUL_Q_bf$bt)
MOOS_Q_bf = BaseflowSeparation(moos.final.discharge$MeanDischarge, filter_parameter = 0.95, passes = 3)
hydrograph(input=subset(MOOS_Q, select = c(day, Discharge_Lsec)), streamflow2=MOOS_Q_bf$bt)
head(FRCH)
# FRCH #
FRCH$Date <- mdy(FRCH$Date)
FRCH$DateTime <- as.POSIXct(paste(FRCH$Date, FRCH$Time), format="%Y-%m-%d %H:%M:%S") # make datetime column
FRCH.fDOM = subset(FRCH, select = c("DateTime","fDOM.QSU"))
frch.fdom.final = aggregate(fDOM.QSU ~ DateTime, FUN=mean, data = FRCH.fDOM) # Averaging 15 minute intervals
frch.fdom.1 <- cut(FRCH.fDOM$DateTime, breaks = "15 min")
frch.fdom.final <- as.data.frame(aggregate(fDOM.QSU ~ frch.fdom.1, data = FRCH.fDOM, FUN = mean)) # Averaging 15 minute intervals
frch.fdom.final$DateTime <-as.POSIXct(frch.fdom.final$frch.fdom.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
FRCH_SUNA_processed <- read_csv("~/Documents/DoD_2020/SUNA_data/from_internal_harddrive/processed/FRCH_SUNA_processed.csv") # import FRCH SUNA data
FRCH_SUNA_processed <- FRCH_SUNA_processed[, -(14:287)]  #Removing channels
FRCH.no3 <- subset(FRCH_SUNA_processed, select = c("nitrateuM", "datetimeAK"))
FRCH.no3$DateTime <-mdy_hm(FRCH_SUNA_processed$datetimeAK, tz = "GMT")
attributes(FRCH.no3$DateTime)$tzone <- 'America/Anchorage'
frch.no3.final <- as.data.frame(aggregate(nitrateuM ~ DateTime, data = FRCH.no3, FUN = mean)) # Averaging 15 minute intervals
FRCH = left_join(frch.final.discharge, frch.fdom.final, by="DateTime")
FRCH = left_join(FRCH, frch.no3.final, by="DateTime")
head(FRCH)
head(MOOS)
#
### STRT ###
STRT.no3 <- subset(STRT, select = c("DateTime", "nitrateuM"))
names(STRT.no3) = c("DateTime", "nitrateuM")
STRT.fDOM = subset(STRT, select = c("DateTime","fDOM.QSU"))
STRT.fDOM.1 = fillgaps15(strt.fdom.final, strt.fdom.final$fDOM.QSU, "fDOM.QSU", 16)
names(STRT.fDOM) = c("DateTime", "fDOM.QSU")
strt.fdom.final = aggregate(fDOM.QSU ~ DateTime, FUN=mean, data = STRT.fDOM) # Averaging 15 minute intervals
strt.no3.1 <- cut(STRT.no3$DateTime, breaks="15 min")
strt.no3.final <- as.data.frame(aggregate(nitrateuM ~ strt.no3.1, data = STRT.no3, FUN = mean)) # Averaging 15 minute intervals
strt.no3.final$DateTime <-as.POSIXct(strt.no3.final$strt.no3.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
STRT = left_join(strt.final.discharge, strt.fdom.final, by="DateTime")
STRT = left_join(STRT, strt.no3.final, by="DateTime")
### POKE ###
POKE.no3 <- subset(POKE, select = c("DateTime", "nitrateuM"))
POKE.no3 <- POKE.no3[!is.na(POKE.no3$DateTime), ]
POKE.fDOM = subset(POKE, select = c("DateTime","fDOM.RFU"))
names(POKE.fDOM) = c("DateTime", "fDOM.RFU")
poke.fdom.1 <- cut(POKE.fDOM$DateTime, breaks = "15 min")
poke.fdom.final <- as.data.frame(aggregate(fDOM.RFU ~ poke.fdom.1, data = POKE.fDOM, FUN = mean)) # Averaging 15 minute intervals
poke.fdom.final$DateTime <-as.POSIXct(poke.fdom.final$poke.fdom.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
poke.no3.1 <- cut(POKE.no3$DateTime, breaks="15 min")
poke.no3.final <- as.data.frame(aggregate(nitrateuM ~ poke.no3.1, data = POKE.no3, FUN = mean)) # Averaging 15 minute intervals
poke.no3.final$DateTime <-as.POSIXct(poke.no3.final$poke.no3.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
POKE = left_join(poke.final.discharge, poke.fdom.final, by="DateTime")
POKE = left_join(POKE, poke.no3.final, by="DateTime")
### VAUL ###
VAUL.no3 <- subset(VAUL, select = c("DateTime", "nitrateuM"))
strt.fdom.final = aggregate(fDOM.QSU ~ DateTime, FUN=mean, data = STRT.fDOM) # Averaging 15 minute intervals
VAUL.fDOM = subset(VAUL, select = c("DateTime","fDOM.QSU"))
vaul.fdom.final = aggregate(fDOM.QSU ~ DateTime, FUN=mean, data = VAUL.fDOM) # Averaging 15 minute intervals
vaul.no3.1 <- cut(VAUL.no3$DateTime, breaks="15 min")
vaul.no3.final <- as.data.frame(aggregate(nitrateuM ~ vaul.no3.1, data = VAUL.no3, FUN = mean)) # Averaging 15 minute intervals
vaul.no3.final$DateTime <-as.POSIXct(vaul.no3.final$vaul.no3.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
VAUL = left_join(vaul.final.discharge, vaul.fdom.final, by="DateTime")
VAUL = left_join(VAUL, vaul.no3.final, by="DateTime")
### MOOS ###
MOOS.no3 <- subset(MOOS, select = c("DateTime", "nitrateuM"))
MOOS.fDOM = subset(MOOS, select = c("DateTime","fDOM.QSU"))
moos.fdom.final = aggregate(fDOM.QSU ~ DateTime, FUN = mean, data = MOOS.fDOM) # averaging every burst at 15 min intervals
moos.no3.1 <- cut(MOOS.no3$DateTime, breaks="15 min")
moos.no3.final <- as.data.frame(aggregate(nitrateuM ~ moos.no3.1, data = MOOS.no3, FUN = mean)) # Averaging 15 minute intervals
moos.no3.final$DateTime <-as.POSIXct(moos.no3.final$moos.no3.1, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
MOOS = left_join(moos.final.discharge, moos.fdom.final, by="DateTime")
MOOS = left_join(MOOS, moos.no3.final, by="DateTime")
head(MOOS)
head(FRCH)
no3.yield = rbind(FRCH, MOOS)
FRCH <- FRCH[-c(4,)]
FRCH <- FRCH[,-4]
head(FRCH)
MOOS <- MOOS[,-5]
head(MOOS)
no3.yield = rbind(FRCH, MOOS)
no3.yield$day = date(no3.yield$DateTime)
head(no3.yield)
no3.daily.means =
no3.yield %>%
group_by(day, Site) %>%
summarize_all(funs(mean), na.rm = TRUE)
## fxn to fill gaps in data ##
fillgaps = function(df, dat, datquotes, largegap.num){
## Document gaps >= largegap.num (1 largegap.num = 15 min) ##
# (note - the criteria of what constitutes a "large" gap should be reevaluated depending on the trend being characterized)
is.na.rle <- rle(is.na(dat))
is.na.rle$values <- is.na.rle$values & is.na.rle$lengths >= (largegap.num)
biggaps = df[inverse.rle(is.na.rle), ]
tz(biggaps$date_timeAK) = "America/Anchorage"
biggaps = subset(biggaps, select = "date_timeAK")
# Make univariate time series, covert to zoo, then to ts #
ts.xts = subset(df, select = c("date_timeAK",datquotes))
ts.xts<-read.zoo(ts.xts, index.column=1, format="%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
ts.xts<-as.xts(ts.xts)
# remove leading and trailing NAs #
ts.xts = na.trim(ts.xts, is.na="any")
# Apply auto.arima and kalman filter to impute missing values #
fit2 = auto.arima(ts.xts)
kal = KalmanSmooth(ts.xts, fit2$model)
id.na<-which(is.na(ts.xts))
for(i in id.na)
ts.xts[i]<-fit2$model$Z %*% kal$smooth[i,]
# revert to dataframe #
ts.df = as.data.frame((ts.xts))
ts.df$date_timeAK = as.POSIXct(row.names(ts.df), tz="America/Anchorage")
names(ts.df) = c("dat_filled", "date_timeAK")
# remove large gaps #
ts.df$dat_filled[ts.df$date_timeAK %in% as.POSIXct(biggaps$date_timeAK)] = NA
# # Replace large gaps with linear interpolation #
# ts.df$dat_filled = na.interpolation(ts.df$dat_filled)
# ### Make daily ###
# ### add a column for day ###
# ts.df$day = format(as.POSIXct(ts.df$date_timeAK,format="%Y-%m-%d %H:%M:%S"),format="%Y-%m-%d")
# ts.df$day = as.POSIXct(ts.df$day, "%Y-%m-%d", tz="America/Anchorage")
# ts.df$date_timeAK = NULL
# daily.df =
#   ts.df %>%
#   group_by(day) %>%
#   summarize_all(funs(mean), na.rm = TRUE)
# #daily.df = paste(df, dat, "daily", sep="_")
return(ts.df)
}
no3.daily.means =
no3.yield %>%
group_by(day, Site) %>%
summarize_all(funs(mean), na.rm = TRUE)
## fxn to fill gaps in data ##
fillgaps = function(df, dat, datquotes, largegap.num){
## Document gaps >= largegap.num (1 largegap.num = 15 min) ##
# (note - the criteria of what constitutes a "large" gap should be reevaluated depending on the trend being characterized)
is.na.rle <- rle(is.na(dat))
is.na.rle$values <- is.na.rle$values & is.na.rle$lengths >= (largegap.num)
biggaps = df[inverse.rle(is.na.rle), ]
tz(biggaps$DateTime) = "America/Anchorage"
biggaps = subset(biggaps, select = "DateTime")
# Make univariate time series, covert to zoo, then to ts #
ts.xts = subset(df, select = c("DateTime",datquotes))
ts.xts<-read.zoo(ts.xts, index.column=1, format="%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
ts.xts<-as.xts(ts.xts)
# remove leading and trailing NAs #
ts.xts = na.trim(ts.xts, is.na="any")
# Apply auto.arima and kalman filter to impute missing values #
fit2 = auto.arima(ts.xts)
kal = KalmanSmooth(ts.xts, fit2$model)
id.na<-which(is.na(ts.xts))
for(i in id.na)
ts.xts[i]<-fit2$model$Z %*% kal$smooth[i,]
# revert to dataframe #
ts.df = as.data.frame((ts.xts))
ts.df$DateTime = as.POSIXct(row.names(ts.df), tz="America/Anchorage")
names(ts.df) = c("dat_filled", "DateTime")
# remove large gaps #
ts.df$dat_filled[ts.df$DateTime %in% as.POSIXct(biggaps$DateTime)] = NA
# # Replace large gaps with linear interpolation #
# ts.df$dat_filled = na.interpolation(ts.df$dat_filled)
# ### Make daily ###
# ### add a column for day ###
# ts.df$day = format(as.POSIXct(ts.df$date_timeAK,format="%Y-%m-%d %H:%M:%S"),format="%Y-%m-%d")
# ts.df$day = as.POSIXct(ts.df$day, "%Y-%m-%d", tz="America/Anchorage")
# ts.df$date_timeAK = NULL
# daily.df =
#   ts.df %>%
#   group_by(day) %>%
#   summarize_all(funs(mean), na.rm = TRUE)
# #daily.df = paste(df, dat, "daily", sep="_")
return(ts.df)
}
no3.daily.means =
no3.yield %>%
group_by(day, Site) %>%
summarize_all(funs(mean), na.rm = TRUE)
class(no3.yield)
View(no3.yield)
no3.yield <- no3.yield[,-(3:4) ]
no3.daily.means =
no3.yield %>%
group_by(day, Site) %>%
summarize_all(funs(mean), na.rm = TRUE)
no3.daily.means =
no3.yield %>%
mutate(DateTime = day(DateTime)) %>%
group_by(day, Site) %>%
summarize(mean_x1 = mean(X1) na.rm = TRUE)
no3.daily.means =
no3.yield %>%
mutate(DateTime = day(DateTime)) %>%
group_by(day, Site) %>%
summarize(mean_x1 = mean(X1), na.rm = TRUE)
no3.daily.means =
no3.yield %>%
mutate(DateTime = day(DateTime)) %>%
group_by(day, Site) %>%
summarize(mean_x1 = mean(X1), na.rm = TRUE)
no3.daily.means <- tapply(no3.yield[,3],day,mean)
no3.daily.means <- aggregate(nitrateuM ~ day, no3.yield, mean)
view(no3.daily.means)
no3.yield.FRCH  <- FRCH
View(no3.yield.FRCH)
no3.yield.FRCH  <- FRCH[,-(3:4)]
no3.yield.FRCH$day <- date(no3.yield.FRCH$DateTime)
no3.daily.means.FRCH <- aggregate(nitrateuM ~ day, no3.yield.FRCH, mean)
View(no3.daily.means.FRCH)
no3.yield
View(no3.yield)
#FRCH/MOOS#
no3.daily.means <- aggregate(x=no3.yield$nitrateuM,
by=list(no3.yield$Site,no3.yield$day),
FUN=mean)
View(no3.daily.means)
#FRCH/MOOS#
no3.daily.means <- aggregate(x=no3.yield$nitrateuM,
by=list(no3.yield$Site,no3.yield$day),
FUN=mean, na.rm = TRUE)
#FRCH/MOOS#
MOOS$NO3_yield_km2 <- MOOS$nitrateuM/113 #MOOS is 113km^2
FRCH$NO3_yield_km2 <- FRCH$nitrateuM/44
no3.yield <- rbind(FRCH, MOOS, na.rm = TRUE)
View(FRCH)
head(FRCH)
head(MOOS)
no3.yield <- rbind(FRCH, MOOS)
head(no3.yield)
nrow(no3.yield)
no3.yield$day <- date(no3.yield$DateTime)
head(no3.yield)
no3.daily.means <- aggregate(x=no3.yield$nitrateuM,
by=list(no3.yield$Site,no3.yield$day),
FUN=mean, na.rm = TRUE)
head(no3.daily.means)
no3.daily.means <- aggregate(x=no3.yield$NO3_yield_km2,
by=list(no3.yield$Site,no3.yield$day),
FUN=mean, na.rm = TRUE)
names(no3.daily.means) <- c("Site", "DateTime", "NO3_yield_km2")
head(no3.daily.means)
ggplot(no3.daily.means, aes(Site, NO3_yield_km2)) + geom_boxplot(aes(fill=Site))+
scale_fill_manual(values=c("#0571B0","#CA0020"), "Catchment") +
theme_bw() + ylab("NO3- daily mean yield (mg N/km2/day)") + xlab("") +
theme(panel.border = element_blank(), panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size = 20), legend.position = "none")
POKE$NO3_yield_km2 <- POKE$nitrateuM/60 # Poke is 60km^2
VAUL$NO3_yield_km2 <- VAUL$nitrateuM/32 # VAUL is 32km^2
STRT$NO3_yield_km2 <- STRT$nitrateuM/125 # STRT is 125 km^2
no3.yield <- rbind(FRCH, MOOS, POKE, VAUL, STRT)
head(POKE)
head(FRCH)
no3.yield <- rbind(FRCH, MOOS, VAUL, STRT)
POKE <- POKE[,-(4,6)]
POKE <- POKE[,-(4)]
head(POKE)
POKE <- POKE[,-(5)]
no3.yield <- rbind(FRCH, MOOS, POKE)
names(POKE) <- c("Site", "DateTime", "MeanDischarge", "fDOM.QSU", "nitrateuM", "NO3_yield_km2")
no3.yield <- rbind(FRCH, MOOS, POKE)
head(VAUL)
VAUL <- VAUL[,(-5)]
no3.yield <- rbind(FRCH, MOOS, POKE, VAUL)
head(STRT)
STRT <- STRT[,(-5)]
no3.yield <- rbind(FRCH, MOOS, POKE, VAUL, STRT)
no3.yield$day <- date(no3.yield$DateTime) # make a day column
no3.daily.means <- aggregate(x=no3.yield$NO3_yield_km2,
by=list(no3.yield$Site,no3.yield$day),
FUN=mean, na.rm = TRUE)
names(no3.daily.means) <- c("Site", "DateTime", "NO3_yield_km2")
ggplot(no3.daily.means, aes(Site, NO3_yield_km2)) + geom_boxplot(aes(fill=Site))+
scale_fill_manual(values=c("#0571B0","#CA0020"), "Catchment") +
theme_bw() + ylab("NO3- daily mean yield (mg N/km2/day)") + xlab("") +
theme(panel.border = element_blank(), panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size = 20), legend.position = "none")
ggplot(no3.daily.means, aes(Site, NO3_yield_km2)) + geom_boxplot(aes(fill=Site))+
scale_fill_manual(values=c("#0571B0","#CA0020", "yellow", "green", "red"), "Catchment") +
theme_bw() + ylab("NO3- daily mean yield (mg N/km2/day)") + xlab("") +
theme(panel.border = element_blank(), panel.grid.major = element_blank(),panel.grid.minor = element_blank(), axis.line = element_line(colour = "black"), text = element_text(size = 20), legend.position = "none")
# calc daily yield #
no3.yield.daily = no3.yield
no3.yield.daily$day = format(as.POSIXct(no3.yield.daily$DateTime,format="%Y-%m-%d %H:%M:%S"),format="%Y-%m-%d")
no3.yield.daily$day = as.POSIXct(no3.yield.daily$day, "%Y-%m-%d", tz="America/Anchorage")
no3.yield.daily$DateTime = NULL
no3.yield.daily =
no3.yield.daily %>%
group_by(day, Site) %>%
summarize_all(funs(sum), na.rm = F)
no3.daily.means <- aggregate(x=no3.yield$NO3_yield_km2,
by=list(no3.yield$Site,no3.yield$day),
FUN=sum, na.rm = TRUE)
no3.yield.daily$NO3_yield_km2.day = no3.yield.daily$NO3_yield_km2
no3.yield.daily$NO3_yield_km2 = NULL
median(no3.yield.daily$NO3_yield_km2.day[no3.yield.daily$Site=="FRCH" &
!is.na(no3.yield.daily$NO3_yield_km2.day)]) /
median(no3.yield.daily$NO3_yield_km2.day[no3.yield.daily$Site=="MOOS"&
!is.na(no3.yield.daily$NO3_yield_km2.day)])
sum(no3.yield.daily$NO3_yield_km2.day[no3.yield.daily$Site=="FRCH"])
sum(no3.yield.daily$NO3_yield_km2.day[no3.yield.daily$Site=="MOOS"])
no3.daily.means <- aggregate(x=no3.yield$NO3_yield_km2,
by=list(no3.yield$Site,no3.yield$day),
FUN=sum, na.rm = FALSE)
no3.yield.daily$NO3_yield_km2.day = no3.yield.daily$NO3_yield_km2
no3.yield.daily$NO3_yield_km2 = NULL
median(no3.yield.daily$NO3_yield_km2.day[no3.yield.daily$Site=="FRCH" &
!is.na(no3.yield.daily$NO3_yield_km2.day)]) /
median(no3.yield.daily$NO3_yield_km2.day[no3.yield.daily$Site=="MOOS"&
!is.na(no3.yield.daily$NO3_yield_km2.day)])
sum(no3.yield.daily$NO3_yield_km2.day[no3.yield.daily$Site=="FRCH"])
sum(no3.yield.daily$NO3_yield_km2.day[no3.yield.daily$Site=="MOOS"])
sum(no3.yield.daily$NO3_yield_km2.day[no3.yield.daily$Site=="FRCH"], na.rm = TRUE)
sum(no3.yield.daily$NO3_yield_km2.day[no3.yield.daily$Site=="MOOS"], na.rm = TRUE)
par(mfrow=c(2,1))
plot(density(no3.yield.daily$NO3_yield_km2.day[no3.yield.daily$Site=="FRCH"]))
plot(density(no3.yield.daily$NO3_yield_km2.day[no3.yield.daily$Site=="FRCH"]), na.rm = TRUE)
MOOS_storm1_06_21_Q <- pd.read_csv("Storms/MOOS_storm1_06_21_Q.csv", usecols = (1,2))
library(reticulate)
library(tidyverse)
library(ggplot2)
library(gridExtra)
library(boot)
installed.packages("reticulate")
installed.package("reticulate")
install.packages("reticulate")
library(reticulate)
#import pickle
#import pandas as pd
#from hysteresis_metrics import hysteresisMetrics
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 1000)
Sys.which("python")
use_python("/usr/bin/python")
library(tidyverse)
options(tz="America/Anchorage")
library(ggplot2)
library(gridExtra)
library(boot)
# Python setup
{python}
#import pickle
#import pandas as pd
#from hysteresis_metrics import hysteresisMetrics
pd.set_option('display.max_columns', 500)
pd.set_option('display.width', 1000)
quit()
library(reticulate)
Sys.which("python")
use_python("/usr/bin/python")
library(tidyverse)
options(tz="America/Anchorage")
library(ggplot2)
library(gridExtra)
library(boot)
# Python setup
{python}
### Poker1 (light blue) and Poker2 (dark blue) with observed Q.
poke.final <- ggplot(aes(x = DateTime, y = pred.poke1.Q), data = Poke1comb) +
geom_line(aes(x = DateTime, y = pred.poke1.Q), data = Poke1comb, color="#A6CEE3", size=1.25) +
geom_line(aes(x = DateTime, y = pred.poke2.Q), data = Poke2comb,color="#1F78B4", size=1.25, alpha = 0.75) +
geom_line(aes(x = Poke1comb.DateTime, y = MeanDischarge), data = poke.final.discharge, color = "red", size = 1.25, alpha = 0.25) +
geom_point(aes(x = DateTime, y = MeasuredQ_Ls), size=2) +
theme_classic() +
ylim(0, 3000) +
ggtitle("Poker1(light) & Poker2(dark) predicted all measured Q") +
ylab("Predicted discharge L/s") +
xlab("Time")
```{r setup, include=FALSE}
library(reticulate)
Sys.which("python")
use_python("/usr/bin/python")
library(tidyverse)
options(tz="America/Anchorage")
library(ggplot2)
library(gridExtra)
library(boot)
reticulate::repl_python()
