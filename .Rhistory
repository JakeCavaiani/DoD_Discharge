filter(Site == "Moose")
Qsummary.MO.2 <- Qsummary.MO[-c(1,9:10), ] # removing points
moosecomb <- full_join(Moose1.pre.middle.post, Qsummary.MO.1)
ggplot(aes(x=WaterLevelmeters, y=MeasuredQ_Ls), data=moose3comb) +
geom_point(aes( color=Method), size=3) +
geom_smooth(method = "lm", se=FALSE) +
stat_poly_eq(formula = y ~ x,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
scale_x_continuous(limits = c(166.2,167)) +
theme_classic() +
ggtitle("Moose measured Q")
moose3comb <- full_join(Moose1.pre.middle.post, Qsummary.MO.1)
ggplot(aes(x=WaterLevelmeters, y=MeasuredQ_Ls), data=moose3comb) +
geom_point(aes( color=Method), size=3) +
geom_smooth(method = "lm", se=FALSE) +
stat_poly_eq(formula = y ~ x,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
scale_x_continuous(limits = c(166.2,167)) +
theme_classic() +
ggtitle("Moose measured Q")
moose3comb <- full_join(Moose1.pre.middle.post, Qsummary.MO.2)
ggplot(aes(x=WaterLevelmeters, y=MeasuredQ_Ls), data=moose3comb) +
geom_point(aes( color=Method), size=3) +
geom_smooth(method = "lm", se=FALSE) +
stat_poly_eq(formula = y ~ x,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
scale_x_continuous(limits = c(166.2,167)) +
theme_classic() +
ggtitle("Moose measured Q")
Moose3.lm <- lm(moose3comb$MeasuredQ_Ls ~ moose3comb$WaterLevelmeters)
summary(Moose3.lm)
moose3comb$pred.moose1.Q <- coef(Moose3.lm)[2] * moose3comb$WaterLevelmeters + coef(Moose3.lm)[1]
ggplot(aes(x=DateTime, y=pred.moose1.Q), data=moose3comb) +
geom_line(color="#A6CEE3", size=1.25) +
geom_point(aes(x=DateTime, y=MeasuredQ_Ls, shape=Method), size=2) +
theme_classic() +
ggtitle("Moose1 predicted all measured Q") +
scale_y_continuous(name = "Predicted Discharge L/s") +
scale_x_datetime(name = "Time")
Moose2.lm <- lm(moose2comb$MeasuredQ_Ls ~ moose2comb$WaterLevelmeters)
summary(Moose2.lm)
moose2comb$pred.moose1.Q <- coef(Moose2.lm)[2] * moose2comb$WaterLevelmeters + coef(Moose2.lm)[1]
ggplot(aes(x=DateTime, y=pred.moose1.Q), data=moose2comb) +
geom_line(color="#A6CEE3", size=1.25) +
geom_point(aes(x=DateTime, y=MeasuredQ_Ls, shape=Method), size=2) +
theme_classic() +
ggtitle("Moose1 predicted all measured Q") +
scale_y_continuous(name = "Predicted Discharge L/s") +
scale_x_datetime(name = "Time")
Qsummary.MO.2 <- Qsummary.MO[-c(1), ] # removing points
moose3comb <- full_join(Moose1.pre.middle.post, Qsummary.MO.2)
ggplot(aes(x=WaterLevelmeters, y=MeasuredQ_Ls), data=moose3comb) +
geom_point(aes( color=Method), size=3) +
geom_smooth(method = "lm", se=FALSE) +
stat_poly_eq(formula = y ~ x,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
scale_x_continuous(limits = c(166.2,167)) +
theme_classic() +
ggtitle("Moose measured Q")
Moose3.lm <- lm(moose3comb$MeasuredQ_Ls ~ moose3comb$WaterLevelmeters)
summary(Moose3.lm)
moose3comb$pred.moose1.Q <- coef(Moose3.lm)[2] * moose3comb$WaterLevelmeters + coef(Moose3.lm)[1]
ggplot(aes(x=DateTime, y=pred.moose1.Q), data=moose3comb) +
geom_line(color="#A6CEE3", size=1.25) +
geom_point(aes(x=DateTime, y=MeasuredQ_Ls, shape=Method), size=2) +
theme_classic() +
ggtitle("Moose1 predicted all measured Q") +
scale_y_continuous(name = "Predicted Discharge L/s") +
scale_x_datetime(name = "Time")
ggplot(aes(x=WaterLevelmeters, y=MeasuredQ_Ls), data=moose3comb) +
geom_point(aes( color=Method), size=3) +
geom_smooth(method = "lm", se=FALSE) +
stat_poly_eq(formula = y ~ poly(x,2, raw = TRUE),
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
scale_x_continuous(limits = c(166.2,167)) +
theme_classic() +
ggtitle("Moose measured Q")
ggplot(aes(x=WaterLevelmeters, y=MeasuredQ_Ls), data=moose3comb) +
geom_point(aes( color=Method), size=3) +
geom_smooth(method = "lm", se=FALSE) +
stat_poly_eq(formula = y ~ x,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
scale_x_continuous(limits = c(166.2,167)) +
theme_classic() +
ggtitle("Moose measured Q")
Qsummary.MO.2 <- Qsummary.MO[-c(1, 9:10), ] # removing points
Qsummary.MO <- Qsummary  %>%
filter(Site == "Moose")
Qsummary.MO.2 <- Qsummary.MO[-c(1, 9:10), ] # removing points
moose3comb <- full_join(Moose1.pre.middle.post, Qsummary.MO.2)
ggplot(aes(x=WaterLevelmeters, y=MeasuredQ_Ls), data=moose3comb) +
geom_point(aes( color=Method), size=3) +
geom_smooth(method = "lm", se=FALSE) +
stat_poly_eq(formula = y ~ x,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
scale_x_continuous(limits = c(166.2,167)) +
theme_classic() +
ggtitle("Moose measured Q")
Moose3.lm <- lm(moose3comb$MeasuredQ_Ls ~ moose3comb$WaterLevelmeters)
summary(Moose3.lm)
moose3comb$pred.moose1.Q <- coef(Moose3.lm)[2] * moose3comb$WaterLevelmeters + coef(Moose3.lm)[1]
ggplot(aes(x=DateTime, y=pred.moose1.Q), data=moose3comb) +
geom_line(color="#A6CEE3", size=1.25) +
geom_point(aes(x=DateTime, y=MeasuredQ_Ls, shape=Method), size=2) +
theme_classic() +
ggtitle("Moose1 predicted all measured Q") +
scale_y_continuous(name = "Predicted Discharge L/s") +
scale_x_datetime(name = "Time")
Moose2.lm <- lm(moose2comb$MeasuredQ_Ls ~ moose2comb$WaterLevelmeters)
summary(Moose2.lm)
moose2comb$pred.moose1.Q <- coef(Moose2.lm)[2] * moose2comb$WaterLevelmeters + coef(Moose2.lm)[1]
ggplot(aes(x=DateTime, y=pred.moose1.Q), data=moose2comb) +
geom_line(color="#A6CEE3", size=1.25) +
geom_point(aes(x=DateTime, y=MeasuredQ_Ls, shape=Method), size=2) +
theme_classic() +
ggtitle("Moose1 predicted all measured Q") +
scale_y_continuous(name = "Predicted Discharge L/s") +
scale_x_datetime(name = "Time")
moose3comb_final <- moose3comb[,-c(1:3,5,7:13)]
names(moose3comb_final) <- c("DateTime", "Site", "Q")
moose3comb_final$Site <- "MOOS"
write.csv(moose3comb_final, "DoD_Discharge/Predicted_Discharge/2018/MOOS/MOOS.Q.csv", row.names = FALSE)
write.csv(moose3comb_final, "Predicted_Discharge/2018/MOOS/MOOS.Q.csv", row.names = FALSE)
setwd("C:/Users/Karen Jorgenson/Documents/Github/DoD_Discharge")
moose3comb_final <- moose3comb[,-c(1:3,5,7:13)]
names(moose3comb_final) <- c("DateTime", "Site", "Q")
moose3comb_final$Site <- "MOOS"
write.csv(moose3comb_final, "Predicted_Discharge/2018/MOOS/MOOS.Q.csv", row.names = FALSE)
getwd()
Qsummary.FR <- Qsummary  %>% #filter out measured Q at just french
filter(Site == "French")
French1comb <- full_join(French1, Qsummary.FR)
ggplot(aes(x=WaterLevelmeters, y=MeasuredQ_Ls), data=French1comb) +
geom_point(aes( color=Method), size=3) +
geom_smooth(method = "lm", se=FALSE) +
stat_poly_eq(formula = y ~ x,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
scale_x_continuous(limits = c(184.2,184.9)) +
theme_classic() +
ggtitle("French1 all measured Q")
French1.lm <- lm(French1comb$MeasuredQ_Ls ~ French1comb$WaterLevelmeters)
summary(French1.lm)
Qsummary.FR.1 <- Qsummary.FR[-c(8:9), ] # removing the HOBOWare points
French2comb <- full_join(French1, Qsummary.FR.1)
ggplot(aes(x=WaterLevelmeters, y=MeasuredQ_Ls), data=French2comb) +
geom_point(aes( color=Method), size=3) +
geom_smooth(method = "lm", se=FALSE) +
stat_poly_eq(formula = y ~ x,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
scale_x_continuous(limits = c(184.2,184.9)) +
theme_classic() +
ggtitle("French1 all measured Q")
French2.lm <- lm(French2comb$MeasuredQ_Ls ~ French2comb$WaterLevelmeters)
summary(French1.lm)
French2comb$pred.french1.Q <- coef(French2.lm)[2] * French2comb$WaterLevelmeters + coef(French2.lm)[1]
ggplot(aes(x=DateTime, y=pred.french1.Q), data=French2comb) +
geom_line(color="#A6CEE3", size=1.25) +
geom_point(aes(x=DateTime, y=MeasuredQ_Ls, shape=Method), size=3) +
theme_classic() +
ggtitle("French1 predicted all measured Q") +
scale_y_continuous(name = "Discharge L/s") +
scale_x_datetime(name = "Time")
write.csv(moose3comb_final, "~Predicted_Discharge/2018/MOOS/MOOS.Q.csv", row.names = FALSE)
# Fill in any missing data
French2comb <- na_kalman(French2comb)
ggplot(aes(x=DateTime, y=pred.french1.Q), data=French2comb) +
geom_line(color="#A6CEE3", size=1.25) +
geom_point(aes(x=DateTime, y=MeasuredQ_Ls, shape=Method), size=3) +
theme_classic() +
ggtitle("French1 predicted all measured Q") +
scale_y_continuous(name = "Discharge L/s") +
scale_x_datetime(name = "Time")
moose3comb <- na_kalman(moose3comb)
ggplot(aes(x=DateTime, y=pred.moose1.Q), data=moose3comb) +
geom_line(color="#A6CEE3", size=1.25) +
geom_point(aes(x=DateTime, y=MeasuredQ_Ls, shape=Method), size=2) +
theme_classic() +
ggtitle("Moose1 predicted all measured Q") +
scale_y_continuous(name = "Predicted Discharge L/s") +
scale_x_datetime(name = "Time")
final_discharge_2018 <- rbind(moose3comb, French2comb)
final_discharge_2018 <- full_join(moose3comb, French2comb)
Q_2018 <- final_discharge_2018
Q_2018$day = format(as.POSIXct(Q_2018$DateTime,format="%Y-%m-%d %H:%M:%S"),format="%Y-%m-%d")
Q_2018$day = as.POSIXct(Q_2018$day, "%Y-%m-%d", tz="America/Anchorage")
# Import processed Q data
### Import Data ###
frch.stream.2019.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vStPTLYv7j4tC3hGRHQ3rW8oCTx9_I0bekcLBjCl4jKQT8GLImI_hXp9qq6UsmdVAaPd7vr4r3BsLZJ/pub?output=csv"
frch.stream.2019.url.two <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vQmHJ-1aQ_8UWAPq-v_us3gz-JTv7vsdVVKNnnMUloJwJNK7TTgvU8kLeUOCbIYU_mHz8v1k1CFz2Vl/pub?output=csv"
vaul.stream.2019.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vSo7CfzMCKXdPmdVZ2c8tJQ-_NzKkje0QWYIseiLxH82hJeJZZ1wtiuL6ZleDoEaPPJMzuWdqB3NaAQ/pub?output=csv"
poke.stream.2019.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vR5CEMDu-NFH49FcPmbf_QglRqVaEV-0xgcGJWz3kWuuGP8pwI-OhXtSZCwN4uwBlOq0CuuQ9tMYLXX/pub?output=csv"
poke.stream.2019.url.two <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vTInrTbsXhYZ0Hcn0YZIBF7LWimNdO0V1e_06hKNaIriwxszvphODlUDfRnT_5_Xgi63k2WFW4q8EKm/pub?output=csv"
strt.stream.2019.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vTgVqJmbVgtXVDGQL_SiQqHphyUBuXG-w0bCk8mLn-IksFrqg3PMvRveGizqHM9lhq_rhqozKseAD_7/pub?output=csv"
strt.stream.2019.url.two <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vRNwL17hN8tMuyzDCDKCTeXGjQ1eN7j881D0-pyi46PhTK7LwoqQ_jrwZWQrSypd3icId9KFpqsuatj/pub?output=csv"
moos.stream.2019.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vQMF0fbfNRwgU-9DfsCJ7LpPd_LoAL01gcSdHzNIFXJ5sSnXwH8Vvsqyj_nZAeWVcXGDWhyJP2TbjZq/pub?output=csv"
FRCH_RainGauge_2019 <- read.csv("~/Documents/DoD_2019/RainGauge/FRCH.RainGauge.2019.csv")
# Import processed Q data
### Import Data ###
frch.stream.2019.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vStPTLYv7j4tC3hGRHQ3rW8oCTx9_I0bekcLBjCl4jKQT8GLImI_hXp9qq6UsmdVAaPd7vr4r3BsLZJ/pub?output=csv"
frch.stream.2019.url.two <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vQmHJ-1aQ_8UWAPq-v_us3gz-JTv7vsdVVKNnnMUloJwJNK7TTgvU8kLeUOCbIYU_mHz8v1k1CFz2Vl/pub?output=csv"
vaul.stream.2019.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vSo7CfzMCKXdPmdVZ2c8tJQ-_NzKkje0QWYIseiLxH82hJeJZZ1wtiuL6ZleDoEaPPJMzuWdqB3NaAQ/pub?output=csv"
poke.stream.2019.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vR5CEMDu-NFH49FcPmbf_QglRqVaEV-0xgcGJWz3kWuuGP8pwI-OhXtSZCwN4uwBlOq0CuuQ9tMYLXX/pub?output=csv"
poke.stream.2019.url.two <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vTInrTbsXhYZ0Hcn0YZIBF7LWimNdO0V1e_06hKNaIriwxszvphODlUDfRnT_5_Xgi63k2WFW4q8EKm/pub?output=csv"
strt.stream.2019.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vTgVqJmbVgtXVDGQL_SiQqHphyUBuXG-w0bCk8mLn-IksFrqg3PMvRveGizqHM9lhq_rhqozKseAD_7/pub?output=csv"
strt.stream.2019.url.two <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vRNwL17hN8tMuyzDCDKCTeXGjQ1eN7j881D0-pyi46PhTK7LwoqQ_jrwZWQrSypd3icId9KFpqsuatj/pub?output=csv"
moos.stream.2019.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vQMF0fbfNRwgU-9DfsCJ7LpPd_LoAL01gcSdHzNIFXJ5sSnXwH8Vvsqyj_nZAeWVcXGDWhyJP2TbjZq/pub?output=csv"
#FRCH_RainGauge_2019 <- read.csv("~/Documents/DoD_2019/RainGauge/FRCH.RainGauge.2019.csv")
#FRCH_RainGauge_2019$Datetime <-  ymd_hms(FRCH_RainGauge_2019$Datetime)
#attributes(FRCH_RainGauge_2019$Datetime)$tzone <-'America/Anchorage'
#POKE_RainGauge_2019 <- read.csv("~/Documents/DoD_2019/RainGauge/POKE.RainGauge.2019.csv")
#POKE_RainGauge_2019$DateTime <- ymd_hms(POKE_RainGauge_2019$DateTime)
#attributes(POKE_RainGauge_2019$DateTime)$tzone <- 'America/Anchorage'
#VAUL_RainGauge_2019 <- read.csv("~/Documents/DoD_2019/RainGauge/VAUL.RainGauge.2019.csv")
#VAUL_RainGauge_2019$DateTime <- ymd_hms(VAUL_RainGauge_2019$DateTime)
#attributes(VAUL_RainGauge_2019$DateTime)$tzone <- 'America/Anchorage'
### read in data ###
frch.stream.one.2019 <- read.csv(url(frch.stream.2019.url))
frch.stream.two.2019 <- read.csv(url(frch.stream.2019.url.two))
vaul.stream.one.2019 <- read.csv(url(vaul.stream.2019.url))
poke.stream.one.2019 <- read.csv(url(poke.stream.2019.url))
poke.stream.two.2019 <- read.csv(url(poke.stream.2019.url.two))
strt.stream.one.2019 <- read.csv(url(strt.stream.2019.url)) # only goes to august
strt.stream.two.2019 <- read.csv(url(strt.stream.2019.url.two)) # goes all the way to october.
moos.stream.one.2019 <- read.csv(url(moos.stream.2019.url))
# Rename column headers #
names(frch.stream.one.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
names(frch.stream.two.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
names(vaul.stream.one.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
names(poke.stream.one.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
names(poke.stream.two.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
names(strt.stream.one.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
names(strt.stream.two.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
names(moos.stream.one.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
# Input NA for missing time #
frch.stream.one.2019$DateTimeGMT[frch.stream.one.2019$DateTimeGMT == ""] <- NA
frch.stream.two.2019$DateTimeGMT[frch.stream.two.2019$DateTimeGMT == ""] <- NA
vaul.stream.one.2019$DateTimeGMT[vaul.stream.one.2019$DateTimeGMT == ""] <- NA
poke.stream.one.2019$DateTimeGMT[poke.stream.one.2019$DateTimeGMT == ""] <- NA
poke.stream.two.2019$DateTimeGMT[poke.stream.two.2019$DateTimeGMT == ""] <- NA
strt.stream.one.2019$DateTimeGMT[strt.stream.one.2019$DateTimeGMT == ""] <- NA
strt.stream.two.2019$DateTimeGMT[strt.stream.two.2019$DateTimeGMT == ""] <- NA
moos.stream.one.2019$DateTimeGMT[moos.stream.one.2019$DateTimeGMT == ""] <- NA
# Convert time and put in AK time #
frch.stream.one.2019$DateTime <- as.POSIXct(paste(frch.stream.one.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
frch.stream.one.2019$DateTime <- lubridate::round_date(frch.stream.one.2019$DateTime, "15 minutes")
frch.stream.two.2019$DateTime <- as.POSIXct(paste(frch.stream.two.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
vaul.stream.one.2019$DateTime <- as.POSIXct(paste(vaul.stream.one.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
poke.stream.one.2019$DateTime <- as.POSIXct(paste(poke.stream.one.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
poke.stream.one.2019$DateTime <- lubridate::round_date(poke.stream.one.2019$DateTime, "15 minutes")
poke.stream.two.2019$DateTime <- as.POSIXct(paste(poke.stream.two.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
strt.stream.one.2019$DateTime <- as.POSIXct(paste(strt.stream.one.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
strt.stream.two.2019$DateTime <- as.POSIXct(paste(strt.stream.two.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
moos.stream.one.2019$DateTime <- as.POSIXct(paste(moos.stream.one.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
# Observed discharge
myurl <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vRUMy2yDlF5WQRDGgbuNHeVNp7diusfPJuKgikGY2ZQ8ewbG4Tyxm5TeN0shtDkxMmeL9M0AzhaL8l7/pub?output=csv"
QSummary.2019 <- read.csv(url(myurl))
QSummary.2019$Time[QSummary.2019$Time == ""] <- NA
QSummary.2019$Q_Ls[QSummary.2019$Q_Ls == ""] <- NA
### Format Time ###
QSummary.2019$Date <- mdy(QSummary.2019$Date)
QSummary.2019$DateTime <- as.POSIXct(paste(QSummary.2019$Date, QSummary.2019$Time), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
QSummary.2019$DateTime <- lubridate::round_date(QSummary.2019$DateTime, "15 minutes")
library(here)
write.csv(frch.pt.2019.final, here("DoD_Discharge/PT_data/2019/FRCH/frch.pt.2019.csv"), row.names = FALSE)
# Import processed Q data
### Import Data ###
frch.stream.2019.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vStPTLYv7j4tC3hGRHQ3rW8oCTx9_I0bekcLBjCl4jKQT8GLImI_hXp9qq6UsmdVAaPd7vr4r3BsLZJ/pub?output=csv"
frch.stream.2019.url.two <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vQmHJ-1aQ_8UWAPq-v_us3gz-JTv7vsdVVKNnnMUloJwJNK7TTgvU8kLeUOCbIYU_mHz8v1k1CFz2Vl/pub?output=csv"
vaul.stream.2019.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vSo7CfzMCKXdPmdVZ2c8tJQ-_NzKkje0QWYIseiLxH82hJeJZZ1wtiuL6ZleDoEaPPJMzuWdqB3NaAQ/pub?output=csv"
poke.stream.2019.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vR5CEMDu-NFH49FcPmbf_QglRqVaEV-0xgcGJWz3kWuuGP8pwI-OhXtSZCwN4uwBlOq0CuuQ9tMYLXX/pub?output=csv"
poke.stream.2019.url.two <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vTInrTbsXhYZ0Hcn0YZIBF7LWimNdO0V1e_06hKNaIriwxszvphODlUDfRnT_5_Xgi63k2WFW4q8EKm/pub?output=csv"
strt.stream.2019.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vTgVqJmbVgtXVDGQL_SiQqHphyUBuXG-w0bCk8mLn-IksFrqg3PMvRveGizqHM9lhq_rhqozKseAD_7/pub?output=csv"
strt.stream.2019.url.two <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vRNwL17hN8tMuyzDCDKCTeXGjQ1eN7j881D0-pyi46PhTK7LwoqQ_jrwZWQrSypd3icId9KFpqsuatj/pub?output=csv"
moos.stream.2019.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vQMF0fbfNRwgU-9DfsCJ7LpPd_LoAL01gcSdHzNIFXJ5sSnXwH8Vvsqyj_nZAeWVcXGDWhyJP2TbjZq/pub?output=csv"
#FRCH_RainGauge_2019 <- read.csv("~/Documents/DoD_2019/RainGauge/FRCH.RainGauge.2019.csv")
#FRCH_RainGauge_2019$Datetime <-  ymd_hms(FRCH_RainGauge_2019$Datetime)
#attributes(FRCH_RainGauge_2019$Datetime)$tzone <-'America/Anchorage'
#POKE_RainGauge_2019 <- read.csv("~/Documents/DoD_2019/RainGauge/POKE.RainGauge.2019.csv")
#POKE_RainGauge_2019$DateTime <- ymd_hms(POKE_RainGauge_2019$DateTime)
#attributes(POKE_RainGauge_2019$DateTime)$tzone <- 'America/Anchorage'
#VAUL_RainGauge_2019 <- read.csv("~/Documents/DoD_2019/RainGauge/VAUL.RainGauge.2019.csv")
#VAUL_RainGauge_2019$DateTime <- ymd_hms(VAUL_RainGauge_2019$DateTime)
#attributes(VAUL_RainGauge_2019$DateTime)$tzone <- 'America/Anchorage'
### read in data ###
frch.stream.one.2019 <- read.csv(url(frch.stream.2019.url))
frch.stream.two.2019 <- read.csv(url(frch.stream.2019.url.two))
vaul.stream.one.2019 <- read.csv(url(vaul.stream.2019.url))
poke.stream.one.2019 <- read.csv(url(poke.stream.2019.url))
poke.stream.two.2019 <- read.csv(url(poke.stream.2019.url.two))
strt.stream.one.2019 <- read.csv(url(strt.stream.2019.url)) # only goes to august
strt.stream.two.2019 <- read.csv(url(strt.stream.2019.url.two)) # goes all the way to october.
moos.stream.one.2019 <- read.csv(url(moos.stream.2019.url))
# Rename column headers #
names(frch.stream.one.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
names(frch.stream.two.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
names(vaul.stream.one.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
names(poke.stream.one.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
names(poke.stream.two.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
names(strt.stream.one.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
names(strt.stream.two.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
names(moos.stream.one.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
# Input NA for missing time #
frch.stream.one.2019$DateTimeGMT[frch.stream.one.2019$DateTimeGMT == ""] <- NA
frch.stream.two.2019$DateTimeGMT[frch.stream.two.2019$DateTimeGMT == ""] <- NA
vaul.stream.one.2019$DateTimeGMT[vaul.stream.one.2019$DateTimeGMT == ""] <- NA
poke.stream.one.2019$DateTimeGMT[poke.stream.one.2019$DateTimeGMT == ""] <- NA
poke.stream.two.2019$DateTimeGMT[poke.stream.two.2019$DateTimeGMT == ""] <- NA
strt.stream.one.2019$DateTimeGMT[strt.stream.one.2019$DateTimeGMT == ""] <- NA
strt.stream.two.2019$DateTimeGMT[strt.stream.two.2019$DateTimeGMT == ""] <- NA
moos.stream.one.2019$DateTimeGMT[moos.stream.one.2019$DateTimeGMT == ""] <- NA
# Convert time and put in AK time #
frch.stream.one.2019$DateTime <- as.POSIXct(paste(frch.stream.one.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
frch.stream.one.2019$DateTime <- lubridate::round_date(frch.stream.one.2019$DateTime, "15 minutes")
frch.stream.two.2019$DateTime <- as.POSIXct(paste(frch.stream.two.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
vaul.stream.one.2019$DateTime <- as.POSIXct(paste(vaul.stream.one.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
poke.stream.one.2019$DateTime <- as.POSIXct(paste(poke.stream.one.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
poke.stream.one.2019$DateTime <- lubridate::round_date(poke.stream.one.2019$DateTime, "15 minutes")
poke.stream.two.2019$DateTime <- as.POSIXct(paste(poke.stream.two.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
strt.stream.one.2019$DateTime <- as.POSIXct(paste(strt.stream.one.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
strt.stream.two.2019$DateTime <- as.POSIXct(paste(strt.stream.two.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
moos.stream.one.2019$DateTime <- as.POSIXct(paste(moos.stream.one.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
# Observed discharge
myurl <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vRUMy2yDlF5WQRDGgbuNHeVNp7diusfPJuKgikGY2ZQ8ewbG4Tyxm5TeN0shtDkxMmeL9M0AzhaL8l7/pub?output=csv"
QSummary.2019 <- read.csv(url(myurl))
QSummary.2019$Time[QSummary.2019$Time == ""] <- NA
QSummary.2019$Q_Ls[QSummary.2019$Q_Ls == ""] <- NA
### Format Time ###
QSummary.2019$Date <- mdy(QSummary.2019$Date)
QSummary.2019$DateTime <- as.POSIXct(paste(QSummary.2019$Date, QSummary.2019$Time), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
QSummary.2019$DateTime <- lubridate::round_date(QSummary.2019$DateTime, "15 minutes")
frch.stream.two.2019 <- frch.stream.two.2019[1:nrow(frch.stream.one.2019),]
frch.stream.one.2019$Site <- "FRCH1" #add column identifier
frch.stream.two.2019$Site <- "FRCH2"
frch.pt.2019 <- bind_rows(frch.stream.one.2019, frch.stream.two.2019)
vaul.pt.2019 <- vaul.stream.one.2019
vaul.pt.2019$Site <- "VAUL1"
poke.stream.two.2019 <- poke.stream.two.2019[1:nrow(poke.stream.one.2019),]
poke.stream.one.2019$Site <- "POKE1" #add column identifier
poke.stream.two.2019$Site <- "POKE2"
poke.pt.2019 <- bind_rows(poke.stream.one.2019, poke.stream.two.2019)
moos.pt.2019 <- moos.stream.one.2019
moos.pt.2019$Site <- "MOOS1"
# Checking closeness between two PT #
plot(x = frch.stream.one.2019$AbsPTDepth, y = frch.stream.two.2019$AbsPTDepth, main = "French PT comparison",
xlab = "French1 PT",
ylab = "French2 PT")
abline(1,1)
FRCH_RainGauge_2019 <- read.csv(here("DoD_2019/RainGauge/FRCH.RainGauge.2019.csv"))
library(here)
frch.stream.two.2019 <- frch.stream.two.2019[1:nrow(frch.stream.one.2019),]
frch.stream.one.2019$Site <- "FRCH1" #add column identifier
frch.stream.two.2019$Site <- "FRCH2"
frch.pt.2019 <- bind_rows(frch.stream.one.2019, frch.stream.two.2019)
vaul.pt.2019 <- vaul.stream.one.2019
vaul.pt.2019$Site <- "VAUL1"
poke.stream.two.2019 <- poke.stream.two.2019[1:nrow(poke.stream.one.2019),]
poke.stream.one.2019$Site <- "POKE1" #add column identifier
poke.stream.two.2019$Site <- "POKE2"
poke.pt.2019 <- bind_rows(poke.stream.one.2019, poke.stream.two.2019)
moos.pt.2019 <- moos.stream.one.2019
moos.pt.2019$Site <- "MOOS1"
# Checking closeness between two PT #
plot(x = frch.stream.one.2019$AbsPTDepth, y = frch.stream.two.2019$AbsPTDepth, main = "French PT comparison",
xlab = "French1 PT",
ylab = "French2 PT")
abline(1,1)
plot(FRCH_RainGauge_2019$inst_rainfall_mm ~ FRCH_RainGauge_2019$Datetime, type="h",
xlim = as.POSIXct(c("2019-05-31 15:45:00","2019-10-22 09:15:00"), tz="America/Anchorage"),
ylim = c(20,0),
axes=F, xlab="", ylab="")
plot(moos.stream.one.2019$DateTime, moos.stream.one.2019$AbsPTDepth, type = 'l')
moos.stream.one.2019 <- moos.stream.one.2019[-c(3715, 5179,5342), ]
plot(moos.stream.one.2019$DateTime, moos.stream.one.2019$AbsPTDepth, type = 'l')
moos.stream.one.2019 %>% ggplot(aes(DateTime, AbsPTDepth)) + geom_point()
moos.stream.one.2019 %>% filter(DateTime > "2019-06-01" & DateTime < "2019-07-01) %>% ggplot(aes(DateTime, AbsPTDepth)) + geom_point()
moos.stream.one.2019 %>% filter(DateTime > "2019-06-01" & DateTime < "2019-07-01") %>%
moos.stream.one.2019 %>% filter(DateTime > "2019-06-01" & DateTime < "2019-07-01")
moos.stream.one.2019 %>% filter(DateTime > "2019-06-01" & DateTime < "2019-07-01") %>%
ggplot(aes(DateTime, AbsPTDepth)) + geom_point()
moos.stream.one.2019 %>% filter(DateTime > "2019-07-01" & DateTime < "2019-08-01") %>%
ggplot(aes(DateTime, AbsPTDepth)) + geom_point()
moos.stream.one.2019 %>% filter(DateTime > "2019-08-01" & DateTime < "2019-09-01") %>%
ggplot(aes(DateTime, AbsPTDepth)) + geom_point()
moos.stream.one.2019 %>% filter(DateTime > "2019-09-01" & DateTime < "2019-10-01") %>%
ggplot(aes(DateTime, AbsPTDepth)) + geom_point()
moos.stream.one.2019 %>% #filter(DateTime > "2019-09-01" & DateTime < "2019-10-01") %>%
ggplot(aes(DateTime, AbsPTDepth)) + geom_point()
moos.stream.one.2019$Site <- "MOOS"
moos.stream.one.2019 <- moos.stream.one.2019[,-2]
write.csv(moos.stream.one.2019, here("DoD_Discharge/PT_data/2019/MOOS/moos.pt.2019.csv"), row.names = FALSE)
# ALL Sites #
all <- ggplot(QSummary.2019) +
geom_point(aes(x=DateTime, y=Q_Ls, color=Site), size=3) +
theme_classic() +
scale_color_brewer(palette = "Set1") +
ggtitle("ALL SITES")
all
a <- QSummary.2019 %>% filter(Site == "Moose") %>%
ggplot() +
geom_point(aes(x=DateTime, y = Q_Ls, color = Method), size=3) +
theme_classic() +
ggtitle("Moose")
a
b <- QSummary.2019 %>% filter(Site == "French") %>%
ggplot() +
geom_point(aes(x=DateTime, y = Q_Ls, color = Method), size=3) +
theme_classic() +
ggtitle("French")
b
c <- QSummary.2019 %>% filter(Site == "Poker") %>%
ggplot() +
geom_point(aes(x=DateTime, y = Q_Ls, color = Method), size=3) +
theme_classic() +
ggtitle("Poker")
c
d <- QSummary.2019 %>% filter(Site == "Vault") %>%
ggplot() +
geom_point(aes(x=DateTime, y = Q_Ls, color = Method), size=3) +
theme_classic() +
ggtitle("Vault")
d
e <- QSummary.2019 %>% filter(Site == "Stuart") %>%
ggplot() +
geom_point(aes(x=DateTime, y = Q_Ls, color = Method), size=3) +
theme_classic() +
ggtitle("Stuart")
e
plot_grid(all, NA,
a, b,
c,d,
e,
nrow = 4, ncol = 2)
all
QSummary.MO.2019 <- QSummary.2019 %>% filter(Site =="Moose")
QSummary.MO.2019$Site <- "MOOS"
moos.stream.one.2019$Site <- "MOOS"
Moose1comb.2019 <- full_join(moos.stream.one.2019, QSummary.MO.2019)
Moose1.lm.2019 <- lm(Moose1comb.2019$Q_Ls ~ Moose1comb.2019$AbsPTDepth)
summary(Moose1.lm.2019) # I think this worked
moos.formula <- y ~ x
ggplot(aes(x = AbsPTDepth, y = Q_Ls), data = Moose1comb.2019) +
geom_point(aes(color = Method), size = 3) +
geom_smooth(method = "lm", se=FALSE) +
stat_poly_eq(formula = moos.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
xlim(0.9, 1.8) +
theme_classic() +
ggtitle("Moose1 all measured Q")  # I think this worked
QSummary.MO.2019.1 <- QSummary.MO.2019[-16, ]
Moose2comb.2019 <- full_join(moos.stream.one.2019, QSummary.MO.2019.1)
Moose2.lm.2019 <- lm(Moose2comb.2019$Q_Ls ~ Moose2comb.2019$AbsPTDepth)
summary(Moose2.lm.2019) # I think this worked
moos.formula <- y ~ x
ggplot(aes(x = AbsPTDepth, y = Q_Ls), data = Moose2comb.2019) +
geom_point(aes(color = Method), size = 3) +
geom_smooth(method = "lm", se=FALSE) +
stat_poly_eq(formula = moos.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
xlim(0.9, 1.8) +
theme_classic() +
ggtitle("Moose1 all measured Q")  # I think this worked
Moose2comb.2019$pred.moos1.Q <- coef(Moose2.lm.2019)[2] * Moose2comb.2019$AbsPTDepth+ coef(Moose2.lm.2019)[1]
ggplot(aes(x = DateTime, y = pred.moos1.Q), data = Moose2comb.2019) +
geom_line(color="#A6CEE3", size=1.25) +
geom_point(aes(x = DateTime, y = Q_Ls), size=3) +
theme_classic() +
ggtitle("Moose1 predicted all measured Q") +
xlab("Date") +
ylab("Predicted Discharge")
plot(FRCH_RainGauge_2019$inst_rainfall_mm ~ FRCH_RainGauge_2019$Datetime, type="h",
xlim = as.POSIXct(c("2019-04-29 14:15:00","2019-10-10 09:15:00"), tz="America/Anchorage"),
ylim = c(20,0),
axes=F, xlab="", ylab="")
#plot(FRCH_RainGauge_2019$inst_rainfall_mm ~ FRCH_RainGauge_2019$Datetime, type="h",
#     xlim = as.POSIXct(c("2019-04-29 14:15:00","2019-10-10 09:15:00"), tz="America/Anchorage"),
#     ylim = c(20,0),
#     axes=F, xlab="", ylab="")
#par(new = T)
plot(frch.stream.one.2019$DateTime, frch.stream.one.2019$AbsPTDepth, type = 'l')
which(frch.stream.one.2019$AbsPTDepth > 2.40)
frch.stream.one.2019.1 <- frch.stream.one.2019 %>% subset(frch.stream.one.2019$DateTime < "2019-08-24 00:00:00" & frch.stream.one.2019$DateTime > "2019-08-17 00:00:00")
frch.stream.one.2019.before <- frch.stream.one.2019[-c(10549:15724), ]  # clipping off to have beginning of dataframe
frch.stream.two.middle <- frch.stream.two.2019[-c(1:10549, 11162:15724), ]
frch.stream.one.2019.after <- frch.stream.one.2019[-c(1:11162), ]  # clipping off to have beginning of dataframe
frch.stream.one.all <- rbind(frch.stream.one.2019.before, frch.stream.two.middle, frch.stream.one.2019.after)
plot(frch.stream.one.all$DateTime, frch.stream.one.all$AbsPTDepth, type = "l")
frch.stream.one.2019 <- frch.stream.one.all
plot(frch.stream.one.2019$DateTime, frch.stream.one.2019$AbsPTDepth, type = 'l')
#plot(FRCH_RainGauge_2019$inst_rainfall_mm ~ FRCH_RainGauge_2019$Datetime, type="h",
#     xlim = as.POSIXct(c("2019-04-29 14:15:00","2019-10-10 09:15:00"), tz="America/Anchorage"),
#     ylim = c(20,0),
#     axes=F, xlab="", ylab="")
#par(new = T)
plot(frch.stream.two.2019$DateTime, frch.stream.two.2019$AbsPTDepth, type = 'l')
frch.stream.two.2019 <- frch.stream.two.2019[-c(107,108,389,610,964),]
#plot(FRCH_RainGauge_2019$inst_rainfall_mm ~ FRCH_RainGauge_2019$Datetime, type="h",
#     xlim = as.POSIXct(c("2019-04-29 14:15:00","2019-10-10 09:15:00"), tz="America/Anchorage"),
#     ylim = c(20,0),
#     axes=F, xlab="", ylab="")
#ar(new = T)
plot(frch.stream.two.2019$DateTime, frch.stream.two.2019$AbsPTDepth, type = 'l')
