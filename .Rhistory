### Rename columns ###
names(strt.gauge) <- c("Site", "DateTimeGMT", "Precip")
names(frch.gauge) <- c("Site", "DateTimeGMT", "Precip")
names(vaul.gauge) <- c("Site", "DateTimeGMT", "Precip")
strt.gauge$Site <- "STRT"
frch.gauge$Site <- "FRCH"
vaul.gauge$Site <- "VAUL"
# Input NA for missing time #
strt.gauge$DateTimeGMT[strt.gauge$DateTimeGMT == ""] <- NA
frch.gauge$DateTimeGMT[frch.gauge$DateTimeGMT == ""] <- NA
vaul.gauge$DateTimeGMT[vaul.gauge$DateTimeGMT == ""] <- NA
# Convert time and put in AK time #
strt.gauge$DateTime <- mdy_hms(strt.gauge$DateTimeGMT, tz = "GMT")
attributes(strt.gauge$DateTime)$tzone <- 'America/Anchorage'
frch.gauge$DateTime <- mdy_hms(frch.gauge$DateTimeGMT, tz = "GMT")
attributes(frch.gauge$DateTime)$tzone <- 'America/Anchorage'
vaul.gauge$DateTime <- mdy_hms(vaul.gauge$DateTimeGMT, tz = "GMT")
attributes(vaul.gauge$DateTime)$tzone <- 'America/Anchorage'
# Plot data #
STRT <- ggplot(strt.gauge) +
geom_line(aes(x = DateTime, y = Precip)) +
xlab("Date") +
ylab("Cumulative Precipitation in mm") +
ggtitle("Stuart Rain Gauge")
STRT
FRCH <- ggplot(frch.gauge) +
geom_line(aes(x = DateTime, y = Precip)) +
xlab("Date") +
ylab("Cumulative Precipitation in mm") +
ggtitle("French Rain Gauge")
FRCH
VAUL <- ggplot(vaul.gauge) +
geom_line(aes(x = DateTime, y = Precip)) +
xlab("Date") +
ylab("Cumulative Precipitation in mm") +
ggtitle("Vault Rain Gauge")
VAUL
## VAUL ##
vaul.gauge$inst_rainfall_mm = 0.2
## FRCH ##
frch.gauge$inst_rainfall_mm = 0.2
## STRT ##
strt.gauge$inst_rainfall_mm = 0.2
head(vaul.gauge$DateTime)
## STRT ##
min<-cut(strt.gauge$DateTime, breaks="15 min")
STRT.st <- as.data.frame(aggregate(inst_rainfall_mm ~ min, data = strt.gauge, FUN=function(x)
sum=sum(x)))
STRT.st$datetimeAK<-as.POSIXct(STRT.st$min, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
## FRCH ##
min<-cut(strt.gauge$DateTime, breaks="15 min")
FRCH.st <- as.data.frame(aggregate(inst_rainfall_mm ~ min, data = frch.gauge, FUN=function(x)
sum=sum(x)))
## FRCH ##
min<-cut(frch.gauge$DateTime, breaks="15 min")
FRCH.st <- as.data.frame(aggregate(inst_rainfall_mm ~ min, data = frch.gauge, FUN=function(x)
sum=sum(x)))
FRCH.st$datetimeAK<-as.POSIXct(FRCH.st$min, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
## STRT ##
min<-cut(strt.gauge$DateTime, breaks="15 min")
STRT.st <- as.data.frame(aggregate(inst_rainfall_mm ~ min, data = strt.gauge, FUN=function(x)
sum=sum(x)))
STRT.st$datetimeAK<-as.POSIXct(STRT.st$min, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
## VAUL ##
min<-cut(vaul.gauge$DateTime, breaks="15 min")
VAUL.st <- as.data.frame(aggregate(inst_rainfall_mm ~ min, data=vaul.gauge, FUN=function(x)
sum=sum(x)))
VAUL.st$datetimeAK<-as.POSIXct(VAUL.st$min, "%Y-%m-%d %H:%M:%S", tz="America/Anchorage")
#### round time to nearest 15 min ####
STRT.st$datetimeAK = lubridate::round_date(STRT.st$datetimeAK, "15 minutes")
FRCH.st$datetimeAK = lubridate::round_date(FRCH.st$datetimeAK, "15 minutes")
VAUL.st$datetimeAK = lubridate::round_date(VAUL.st$datetimeAK, "15 minutes")
plot(STRT.st$inst_rainfall_mm ~ STRT.st$datetimeAK, type="h",
xlim=c(as.POSIXct("2020-07-25 00:00:00"), as.POSIXct("2020-10-21 00:00:00")),
ylim=c(0,13))
plot(FRCH.st$inst_rainfall_mm ~ FRCH.st$datetimeAK, type="h",
xlim=c(as.POSIXct("2020-06-05 00:00:00"), as.POSIXct("2020-10-21 00:00:00")),
ylim=c(0,13))
plot(VAUL.st$inst_rainfall_mm ~ VAUL.st$datetimeAK, type="h",
xlim=c(as.POSIXct("2020-06-05 00:00:00"), as.POSIXct("2020-10-21 00:00:00")),
ylim=c(0,13))
par(mfrow=c(3,1))
plot(STRT.st$inst_rainfall_mm ~ STRT.st$datetimeAK, type="h",
xlim=c(as.POSIXct("2020-07-25 00:00:00"), as.POSIXct("2020-10-21 00:00:00")),
ylim=c(0,13))
plot(FRCH.st$inst_rainfall_mm ~ FRCH.st$datetimeAK, type="h",
xlim=c(as.POSIXct("2020-06-05 00:00:00"), as.POSIXct("2020-10-21 00:00:00")),
ylim=c(0,13))
plot(VAUL.st$inst_rainfall_mm ~ VAUL.st$datetimeAK, type="h",
xlim=c(as.POSIXct("2020-06-05 00:00:00"), as.POSIXct("2020-10-21 00:00:00")),
ylim=c(0,13))
par(mfrow=c(1,1))
plot(STRT.st$inst_rainfall_mm ~ STRT.st$datetimeAK, type="h",
xlim=c(as.POSIXct("2020-07-25 00:00:00"), as.POSIXct("2020-10-21 00:00:00")),
ylim=c(0,13))
plot(FRCH_Q$Discharge_Lsec ~ FRCH_Q$day, type="l", xlab="", ylab="Q (L/sec)",ylim = c(0,3000), col="blue", main="FRCH")
library(tidyverse)
library(lubridate)
library(ggplot2)
library(scales)
library(plyr)
library(imputeTS)
library(TSA)
library(bbmle)
library(zoo)
library(xts)
library(forecast)
library(stats)
library(lattice)
library(nlme)
library(geosphere)
library(car)
library(EcoHydRology)
### Load from local machine ###
EXO_ALL <- read_csv("~/Documents/DoD_2020/EXO_data/from_internal_harddrive/processed/EXO.ALL.csv")
EXO_ALL$Site <- EXO_ALL$site.ID
EXO_ALL$DateTime <- as.POSIXct(EXO_ALL$DateTime)
ALL <- full_join(EXO_ALL, final_discharge_2020)
library(tidyverse)
library(lubridate)
library(data.table)
library(rio)
library(ggplot2)
library(scales)
library(psych)
library(here)
library(googledrive)
library(readxl)
library(cowplot)
library(zoo)
library(readr)
library(dplyr)
library(RColorBrewer)
library(gridExtra)
library(ggpmisc)
library(here)
dir.create(here("PT_data"))
dir.create(here("PT_data", "clean"))
setwd(here("PT_data", "clean"))
### Import Raw Data ###
# VAUL only has one because data for PT1 was very erroneous
moos.stream.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vSqPvEKpJI6Kq5O6_oRRj0t9IDXvUwGeHD3t_mYiQvGRL_ZFsCU_4Hw1FMBadCipWjzk-Tg2D2xBK9b/pub?output=csv"
moos.stream.url.two <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vRLiymnxf0Kh0V9RC-aYvoOuVR1mdUR4h4Eyd2QM8eE-C0WnSGiHU30G7hNmBrla7q78ApCi8TIQX4y/pub?output=csv"
frch.stream.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vTEniUzPMlYhqf_XyFnCG5j97f9uZxBCafA8qs4L6KybqvF0eve9Ic4-IkvkeEoYDzAstr40ftBBSnc/pub?output=csv"
frch.stream.url.two <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vSBuhkfYzLPVefrA5bLqybCkJmQtT1zLo5OFavWhjVCYX82QqhYo712IWgxKlpDbk3zMBkJ-QiN_RpZ/pub?output=csv"
strt.stream.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vTv0x_cYRqBh5Aw1shmc630pIXbjVbV8Vet_gZun7AhngwvQWVLkGL7t8gbBuaMnP4tcUQsSN_Zl_f5/pub?output=csv"
strt.stream.url.two <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vQfQQybzS-N-iEQBLalffAhOzLvWOZYTjo84q9rGx_5q1oxm9Kv3WjFePB15m0hSQQLc5DYrPXlwEcS/pub?output=csv"
vaul.stream.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vRVA4AxNNaYJY6hJCD7c7Y4jloR68x1Zols2Grg7xiKx-gVQlqh5yb3e3L5XkFUXyRn0GnD1nRi_XXJ/pub?output=csv"
poke.stream.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vTVII1zFxhCY1VCg6D_NH9dZkE0lsv15W3_hDnvuj0lvnOV3yOhqwiGjs0lSR-ELXnfjc_bLb8mC6M6/pub?output=csv"
poke.stream.url.two <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vTx06zsh-FYmaIix2GBP-GW7E-EYH78bINSLusSbSpD_FP6P7H28JD0M8p8KKXxCFGeiXKEHKitEZW_/pub?output=csv"
# Load Data#
moos.stream.one <- read.csv(url(moos.stream.url), skip = 491)
moos.stream.two <- read.csv(url(moos.stream.url.two), skip = 1)
frch.stream.one <- read.csv(url(frch.stream.url), skip = 1)
frch.stream.two <- read.csv(url(frch.stream.url.two), skip = 4)
strt.stream.one <- read.csv(url(strt.stream.url), skip = 1)
strt.stream.two <- read.csv(url(strt.stream.url.two), skip = 1)
vaul.stream <- read.csv(url(vaul.stream.url), skip = 1)
poke.stream.one <- read.csv(url(poke.stream.url), skip = 1)
poke.stream.two <- read.csv(url(poke.stream.url.two), skip = 1)
# Rename columns #
names(moos.stream.one) <- c("Site", "DateTimeGMT", "AbsolutePressure", "WaterLevel")
names(moos.stream.two) <- c("Site", "DateTimeGMT", "AbsolutePressure", "WaterLevel")
names(frch.stream.one) <- c("Site", "DateTimeGMT", "Absolute Pressure", "WaterLevel")
names(frch.stream.two) <- c("Site", "DateTimeGMT", "Absolute Pressure", "WaterLevel")
names(strt.stream.one) <- c("Site", "DateTimeGMT", "Absolute Pressure", "WaterLevel")
names(strt.stream.two) <- c("Site", "DateTimeGMT", "Absolute Pressure", "WaterLevel")
names(vaul.stream) <- c("Site", "DateTimeGMT", "Absolute Pressure", "WaterLevel")
names(poke.stream.one) <- c("Site", "DateTimeGMT", "AbsolutePressure", "WaterLevel")
names(poke.stream.two) <- c("Site", "DateTimeGMT", "AbsolutePressure", "WaterLevel")
# Input NA for missing time #
moos.stream.one$DateTimeGMT[moos.stream.one$DateTimeGMT == ""] <- NA
moos.stream.two$DateTimeGMT[moos.stream.one$DateTimeGMT == ""] <- NA
frch.stream.one$DateTimeGMT[frch.stream.one$DateTimeGMT == ""] <- NA
frch.stream.two$DateTimeGMT[frch.stream.two$DateTimeGMT == ""] <- NA
strt.stream.one$DateTimeGMT[strt.stream.one$DateTimeGMT == ""] <- NA
strt.stream.two$DateTimeGMT[strt.stream.one$DateTimeGMT == ""] <- NA
vaul.stream$DateTimeGMT[vaul.stream$DateTimeGMT == ""] <- NA
poke.stream.one$DateTimeGMT[poke.stream.one$DateTimeGMT == ""] <- NA
poke.stream.two$DateTimeGMT[poke.stream.one$DateTimeGMT == ""] <- NA
# Convert time and put in AK time #
moos.stream.one$DateTime <- mdy_hms(moos.stream.one$DateTimeGMT, tz = "GMT")
attributes(moos.stream.one$DateTime)$tzone <- 'America/Anchorage'
moos.stream.two$DateTime <- mdy_hms(moos.stream.two$DateTimeGMT, tz = "GMT")
attributes(moos.stream.two$DateTime)$tzone <- 'America/Anchorage'
frch.stream.one$DateTime <- mdy_hms(frch.stream.one$DateTimeGMT, tz = "GMT")
attributes(frch.stream.one$DateTime)$tzone <- 'America/Anchorage'
frch.stream.two$DateTime <- mdy_hms(frch.stream.two$DateTimeGMT, tz = "GMT")
attributes(frch.stream.two$DateTime)$tzone <- 'America/Anchorage'
strt.stream.one$DateTime <- mdy_hms(strt.stream.one$DateTimeGMT, tz = "GMT")
attributes(strt.stream.one$DateTime)$tzone <- 'America/Anchorage'
strt.stream.two$DateTime <- mdy_hms(strt.stream.two$DateTimeGMT, tz = "GMT")
attributes(strt.stream.two$DateTime)$tzone <- 'America/Anchorage'
vaul.stream$DateTime <- mdy_hms(vaul.stream$DateTimeGMT, tz = "GMT")
attributes(vaul.stream$DateTime)$tzone <- 'America/Anchorage'
poke.stream.one$DateTime <- mdy_hms(poke.stream.one$DateTimeGMT, tz = "GMT")
attributes(poke.stream.one$DateTime)$tzone <- 'America/Anchorage'
poke.stream.two$DateTime <- mdy_hms(poke.stream.two$DateTimeGMT, tz = "GMT")
attributes(poke.stream.two$DateTime)$tzone <- 'America/Anchorage'
### Filtering out data ###
### MOOS ###
moos.stream.one <- moos.stream.one %>% filter(moos.stream.one$WaterLevel > 165.5) %>% subset(moos.stream.one$DateTime < "2020-10-14") # cleaning data that is below 165.5 because those are errant and then before 10/14 because thats when we took the PTs out
plot(x = moos.stream.one$DateTime, y = moos.stream.one$WaterLevel) # Plot check
moos.stream.two <- moos.stream.two %>% subset(moos.stream.two$DateTime < "2020-10-14")
plot(x = moos.stream.two$DateTime, y = moos.stream.two$WaterLevel) #plot check
### FRCH ###
frch.stream.one <- frch.stream.one %>% filter(frch.stream.one$WaterLevel > 184) %>%  subset(frch.stream.one$DateTime < "2020-10-14") #cleaning data that is before the 14th (Site was taken down the 15th)
frch.stream.one$DateTime[frch.stream.one$DateTime == "2020-06-28 21:15"] <- NA
frch.stream.one$DateTime[frch.stream.one$DateTime == "2020-06-29 14:45"] <- NA
plot(x = frch.stream.one$DateTime, y = frch.stream.one$WaterLevel) # plot check
frch.stream.two <- frch.stream.two %>%  subset(frch.stream.two$DateTime < "2020-10-14") #cleaning data that is before the 14th (Site was taken down the 15th)
plot(x = frch.stream.two$DateTime, y = frch.stream.two$WaterLevel) # plot check
### STRT ###
strt.stream.one <- strt.stream.one %>% subset(strt.stream.one$DateTime < "2020-10-8") # cleaning data that is before October 8th due to ice in channel (Site was taken down Oct 13th)
plot(x = strt.stream.one$DateTime, y = strt.stream.one$WaterLevel) # plot check
strt.stream.two <- strt.stream.two %>% subset(strt.stream.two$DateTime < "2020-10-08") # cleaning data that is before October 8th due to ice in channel (Site was taken down Oct 13th)
strt.stream.two$DateTime[strt.stream.two$DateTime == "2020-06-24 8:45"] <- NA
plot(x = strt.stream.two$DateTime, y = strt.stream.two$WaterLevel) # plot check
### VAUL ###
vaul.stream <- vaul.stream %>% subset(vaul.stream$DateTime < "2020-10-05") # Cleaning data that is before October 5th due to ice in channel (Site was taken down Oct 14th)
plot(x = vaul.stream$DateTime, y = vaul.stream$WaterLevel) # plot check
### POKE ###
poke.stream.one <- poke.stream.one %>% subset(poke.stream.one$DateTime < "2020-10-10") # Cleaning data that is before October 10th due to ice (Site was taken down Oct 14th)
plot(x = poke.stream.one$DateTime, y = poke.stream.one$WaterLevel) # plot check
poke.stream.two <- poke.stream.two %>% subset(poke.stream.two$DateTime < "2020-10-10") # Cleaning data that is before October 10th due to ice (Site was taken down Oct 14th)
plot(x = poke.stream.two$DateTime, y = poke.stream.two$WaterLevel) # plot check
# Combine the two PT into one #
moos.stream.two <- moos.stream.two[1:nrow(moos.stream.one),]
moos.stream.one$Site <- "MOOS1" #add column identifier
moos.stream.two$Site <- "MOOS2"
allmoos <- bind_rows(moos.stream.one, moos.stream.two)
frch.stream.two <- frch.stream.two[1:nrow(frch.stream.one),]
frch.stream.one$Site <- "FRCH1" #add column identifier
frch.stream.two$Site <- "FRCH2"
allfrch <- bind_rows(frch.stream.one, frch.stream.two)
strt.stream.two <- strt.stream.two[1:nrow(strt.stream.one),]
strt.stream.one$Site <- "STRT1" #add column identifier
strt.stream.two$Site <- "STRT2"
allstrt <- bind_rows(strt.stream.one, strt.stream.two)
vaul.stream$Site <- "VAUL" #add column identifier
allvaul <- vaul.stream
poke.stream.two <- poke.stream.two[1:nrow(poke.stream.one),]
poke.stream.one$Site <- "POKE1" #add column identifier
poke.stream.two$Site <- "POKE2"
allpoke <- bind_rows(poke.stream.one, poke.stream.two)
# Checking closeness between two PT #
plot(x = moos.stream.one$WaterLevel, y = moos.stream.two$WaterLevel, main = "Moose PT comparison",
xlab = "Moose1PT",
ylab = "Moose2PT")
abline(1,1)
plot(x = frch.stream.one$WaterLevel, y = frch.stream.two$WaterLevel, main = "French PT comparison",
xlab = "French1 PT",
ylab = "French2 PT")
abline(1,1)
plot(x = strt.stream.one$WaterLevel, y = strt.stream.two$WaterLevel, main = "Stuart PT comparison",
xlab = "Stuart1 PT",
ylab = "Stuart2 PT")
abline(1,1)
plot(x = poke.stream.one$WaterLevel, y = poke.stream.two$WaterLevel, main = "Poker PT comparison",
xlab = "Poker1 PT",
ylab = "Poker2 PT")
abline(1,1)
Moos <- ggplot(allmoos) +
geom_line(aes(x = DateTime , y= WaterLevel, color = Site), size=1.25) +
xlab("Date") +
ylab("Water Level") +
theme_classic() +
ggtitle("Moose PT comparison") +
scale_color_brewer(palette = "Paired")
Moos
Frch <- ggplot(allfrch) +
geom_line(aes(x = DateTime , y= WaterLevel, color = Site), size=1.25) +
xlab("Date") +
ylab("Water Level") +
theme_classic() +
ggtitle("French Water Level") +
scale_color_brewer(palette = "Paired")
Frch
Strt <- ggplot(allstrt) +
geom_line(aes(x = DateTime , y= WaterLevel, color = Site), size=1.25) +
xlab("Date") +
ylab("Water Level") +
theme_classic() +
ggtitle("Stuart PT comparison") +
scale_color_brewer(palette = "Paired")
Strt
Vaul <- ggplot(vaul.stream) +
geom_line(aes(x = DateTime , y= WaterLevel, color = Site), size=1.25) +
xlab("Date") +
ylab("Water Level") +
theme_classic() +
ggtitle("Vault PT comparison") +
scale_color_brewer(palette = "Paired")
Vaul
Poke <- ggplot(allpoke) +
geom_line(aes(x = DateTime , y= WaterLevel, color = Site), size=1.25) +
xlab("Date") +
ylab("Water Level") +
theme_classic() +
ggtitle("Poker PT comparison") +
scale_color_brewer(palette = "Paired")
Poke
setwd(here())
# check: should be at DoD_Discharge
getwd()
### Write CSV ###
write.csv(allmoos,"PT_data/clean/allmoos.csv", row.names = FALSE)
write.csv(allfrch,"PT_data/clean/allfrch.csv", row.names = FALSE)
write.csv(allstrt,"PT_data/clean/allstrt.csv", row.names = FALSE)
write.csv(allvaul,"PT_data/clean/allvaul.csv", row.names = FALSE)
write.csv(allpoke,"PT_data/clean/allpoke.csv", row.names = FALSE)
library(tidyverse)
library(lubridate)
library(data.table)
library(rio)
library(ggplot2)
library(scales)
library(psych)
library(here)
library(googledrive)
library(readxl)
library(cowplot)
library(zoo)
library(readr)
library(dplyr)
library(RColorBrewer)
library(gridExtra)
library(ggpmisc)
library(here)
dir.create(here("Rating_curve"))
dir.create(here("Rating_curve", "Plots"))
getwd()
discharge.2020 <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vTPrFKu3yyEDEDkxPVJW2vIWznwmSUcwuNlHInDmrD4EjOQYAkHmtnWJXRT1toDa74ptmHj4O1My3xw/pub?output=csv"
QSummary <- read.csv(url(discharge.2020))
QSummary <-  subset(QSummary, select = -c(X2019, Notes, Average, X, Observations, X.1, X2020, average.as.of.8.29., X.2, observations.as.of.8.29.)) # Cleaning columns that are not important to the dataset
QSummary$date <- mdy(QSummary$Date)
QSummary$DateTime <- as.POSIXct(paste(QSummary$date, QSummary$Time), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
### ALL Sites ###
ggplot(QSummary) +
geom_point(aes(x=Date, y=MeasuredQ_Ls, color=Site, shape=Method), size=3) +
theme_classic() +
scale_color_brewer(palette = "Set1") +
ggtitle("ALL SITES")
# Filter French #
QSummary.FR <- QSummary %>% filter(Site =="FRCH")
# Clean date and time #
QSummary.FR$date <- mdy(QSummary.FR$Date)
QSummary.FR$DateTime <- as.POSIXct(paste(QSummary.FR$date, QSummary.FR$Time), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
### Rating curve for FRCH PT1 ###
frch.stream.one$Site <- "FRCH"
French1comb <- full_join(frch.stream.one, QSummary.FR) # Join PT data with Discharge
French1.lm <- lm(French1comb$MeasuredQ_Ls ~ French1comb$WaterLevel) # linear model with discharge and water level
frch.formula <- y ~ x
frc.1 <- ggplot(aes(x = WaterLevel, y = MeasuredQ_Ls), data = French1comb) +
geom_point(aes(color = Method), size = 3) +
geom_smooth(method = "lm", se=FALSE) +
stat_poly_eq(formula = frch.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
xlim(184,185.5) +
theme_classic() +
ggtitle("French1 all measured Q")
frc.1
### Rating curve for FRCH PT2 ###
frch.stream.two$Site <- "FRCH"
French2comb <- full_join(frch.stream.two, QSummary.FR)
French2.lm <- lm(French2comb$MeasuredQ_Ls ~ French2comb$WaterLevel)
frc.2 <- ggplot(aes(x= WaterLevel, y = MeasuredQ_Ls), data = French2comb) +
geom_point(aes(color = Method), size = 3) +
geom_smooth(method = "lm", se=FALSE) +
stat_poly_eq(formula = frch.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
xlim(184, 185.5) +
theme_classic() +
ggtitle("French2 all measured Q")
frc.2
### Filter Moose ###
QSummary.MO <- QSummary %>% filter(Site =="MOOS")
### Rating curve for MOOS PT1 ###
QSummary.MO$date <- mdy(QSummary.MO$Date)
QSummary.MO$DateTime <- as.POSIXct(paste(QSummary.MO$date, QSummary.MO$Time), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
moos.stream.one$Site <- "MOOS"
Moose1comb <- full_join(moos.stream.one, QSummary.MO)
MOOS1.lm <- lm(Moose1comb$MeasuredQ_Ls ~ Moose1comb$WaterLevel)
moos.formula <- y ~ x
mrc.1 <- ggplot(aes(x = WaterLevel, y = MeasuredQ_Ls), data = Moose1comb) +
geom_point(aes(color = Method), size = 3) +
geom_smooth(method = "lm", se=FALSE) +
stat_poly_eq(formula = moos.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
xlim(165.75,166.5) +
ylim(600, 1500) +
theme_classic() +
ggtitle("Moose1 all measured Q")
mrc.1
### Rating curve for MOOS PT2 ###
moos.stream.two$Site <- "MOOS"
Moose2comb <- full_join(moos.stream.two, QSummary.MO)
MOOS2.lm <- lm(Moose2comb$MeasuredQ_Ls ~ Moose2comb$WaterLevel)
mrc.2 <- ggplot(aes(x = WaterLevel, y = MeasuredQ_Ls), data = Moose2comb) +
geom_point(aes(color = Method), size = 3) +
geom_smooth(method = "lm", se=FALSE) +
stat_poly_eq(formula = moos.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
xlim(165.75,166.75) +
ylim(600, 1500) +
theme_classic() +
ggtitle("Moose2 all measured Q")
mrc.2
### Filter Poker ###
QSummary.PO <- QSummary %>% filter(Site =="POKE")
### Rating curve for POKE PT1 ###
poke.stream.one$Site <- "POKE"
Poke1comb <- full_join(poke.stream.one, QSummary.PO)
POKE1.lm <- lm(Poke1comb$MeasuredQ_Ls ~ Poke1comb$WaterLevel)
poke.formula <- y ~ x
prc.1 <- ggplot(aes(x = WaterLevel, y = MeasuredQ_Ls), data = Poke1comb) +
geom_point(aes(color = Method), size = 3) +
geom_smooth(method = "lm", se=FALSE, formula = poke.formula) +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
xlim(215.9, 216.5) +
ylim(200, 2000) +
theme_classic() +
ggtitle("Poke1 all measured Q")
prc.1
### Rating curve for POKE PT2 ###
poke.stream.two$Site <- "POKE"
Poke2comb <- full_join(poke.stream.two, QSummary.PO)
POKE2.lm <- lm(Poke2comb$MeasuredQ_Ls ~ Poke2comb$WaterLevel)
prc.2 <- ggplot(aes(x = WaterLevel, y = MeasuredQ_Ls), data = Poke2comb) +
geom_point(aes(color = Method), size = 3) +
geom_smooth(method = "lm", se=FALSE) +
stat_poly_eq(formula = poke.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
xlim(215.8, 216.5) +
ylim(200, 2000) +
theme_classic() +
ggtitle("Poker2 all measured Q")
### Filter Stuart ###
QSummary.ST <- QSummary %>% filter(Site =="STRT")
### Rating curve for STRT PT1 ###
strt.stream.one$Site <- "STRT"
Strt1comb <- full_join(strt.stream.one, QSummary.ST)
STRT1.lm <- lm(Strt1comb$MeasuredQ_Ls ~ Strt1comb$WaterLevel)
strt.formula <- y ~ x
src.1 <- ggplot(aes(x = WaterLevel, y = MeasuredQ_Ls), data = Strt1comb) +
geom_point(aes(color = Method), size = 3) +
geom_smooth(method = "lm", se=FALSE, formula = strt.formula) +
stat_poly_eq(formula = strt.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
xlim(248.4, 248.7) +
ylim(200, 3000) +
theme_classic() +
ggtitle("Strt1 all measured Q")  # I think this worked
src.1
### Rating curve for STRT PT2 ###
strt.stream.two$Site <- "STRT"
Strt2comb <- full_join(strt.stream.two, QSummary.ST)
STRT2.lm <- lm(Strt2comb$MeasuredQ_Ls ~ Strt2comb$WaterLevel)
strt.formula <- y ~ x
src.2 <- ggplot(aes(x = WaterLevel, y = MeasuredQ_Ls), data = Strt2comb) +
geom_point(aes(color = Method), size = 3) +
geom_smooth(method = "lm", se=FALSE, formula = strt.formula) +
stat_poly_eq(formula = strt.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
xlim(248.5, 248.7) +
ylim(200, 2000) +
theme_classic() +
ggtitle("Strt2 all measured Q")
src.2
### Filter Vault ###
QSummary.VA <- QSummary %>% filter(Site =="VAUL") %>% filter(MeasuredQ_Ls < 2000)
### Rating curve for VAUL PT2 ###
vaul.stream$Site <- "VAUL"
Vaul2comb <- full_join(vaul.stream, QSummary.VA)
VAUL2.lm <- lm(Vaul2comb$MeasuredQ_Ls ~ Vaul2comb$WaterLevel)
vaul.formula <- y ~ x
vrc.1 <- ggplot(aes(x = WaterLevel, y = MeasuredQ_Ls), data = Vaul2comb) +
geom_point(aes(color = Method), size = 3) +
geom_smooth(method = "lm", se=FALSE) +
stat_poly_eq(formula = vaul.formula,
aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
parse = TRUE) +
xlim(197.5, 198.5) +
ylim(0, 1500) +
theme_classic() +
ggtitle("Vault2 all measured Q")
vrc.1
# Import data from google drive #
discharge.2020 <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vTPrFKu3yyEDEDkxPVJW2vIWznwmSUcwuNlHInDmrD4EjOQYAkHmtnWJXRT1toDa74ptmHj4O1My3xw/pub?output=csv"
QSummary <- read.csv(url(discharge.2020))
QSummary <-  subset(QSummary, select = -c(X2019, Notes, Average, X, Observations, X.1, X2020, average.as.of.8.29., X.2, observations.as.of.8.29.)) # Cleaning columns that are not important to the dataset
QSummary$date <- mdy(QSummary$Date)
QSummary$DateTime <- as.POSIXct(paste(QSummary$date, QSummary$Time), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
### ALL Sites ###
ggplot(QSummary) +
geom_point(aes(x=Date, y=MeasuredQ_Ls, color=Site, shape=Method), size=3) +
theme_classic() +
scale_color_brewer(palette = "Set1") +
ggtitle("ALL SITES")
# Filter French #
QSummary.FR <- QSummary %>% filter(Site =="FRCH")
# Filter French #
QSummary.FR <- QSummary %>% filter(Site == "FRCH")
