---
title: "2019 Q"
author: "Jake Cavaiani"
date: "12/2/22"
output:
  html_document: default
  word_document: default
  pdf_document: default
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
Sys.setenv(TZ='America/Anchorage')
library(tidyverse)
library(dplyr)
library(ggplot2)
library(readr)
library(lubridate)
library(rio)
library(neonUtilities)
library(raster)
library(data.table)
library(scales)
library(psych)
library(here)
library(googledrive)
library(readxl)
library(cowplot)
library(zoo)
library(RColorBrewer)
library(gridExtra)
library(ggpmisc)
library(imputeTS)
library(itsmr)
library(here)

```

### 2019
2019 data is read from DoD->2019 AK sensors->2019 Sensor data ->PT->DoD 2019 PT depth corrected for atm  
Wading rods and slugs were used to measure discrete Q during site visit
Includes all sites (Moose, French, Poker, Vault, Stuart)

2019 data is read in from DoD->2019 ak sensors->2019 sensor data->Q -> Pressure Transducer Data->Depth->'site'

```{r, include=FALSE, warning=FALSE}
# Import processed Q data
### Import Data ###
frch.stream.2019.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vStPTLYv7j4tC3hGRHQ3rW8oCTx9_I0bekcLBjCl4jKQT8GLImI_hXp9qq6UsmdVAaPd7vr4r3BsLZJ/pub?output=csv"
frch.stream.2019.url.two <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vQmHJ-1aQ_8UWAPq-v_us3gz-JTv7vsdVVKNnnMUloJwJNK7TTgvU8kLeUOCbIYU_mHz8v1k1CFz2Vl/pub?output=csv"
vaul.stream.2019.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vSo7CfzMCKXdPmdVZ2c8tJQ-_NzKkje0QWYIseiLxH82hJeJZZ1wtiuL6ZleDoEaPPJMzuWdqB3NaAQ/pub?output=csv"
poke.stream.2019.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vR5CEMDu-NFH49FcPmbf_QglRqVaEV-0xgcGJWz3kWuuGP8pwI-OhXtSZCwN4uwBlOq0CuuQ9tMYLXX/pub?output=csv"
poke.stream.2019.url.two <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vTInrTbsXhYZ0Hcn0YZIBF7LWimNdO0V1e_06hKNaIriwxszvphODlUDfRnT_5_Xgi63k2WFW4q8EKm/pub?output=csv"
strt.stream.2019.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vTgVqJmbVgtXVDGQL_SiQqHphyUBuXG-w0bCk8mLn-IksFrqg3PMvRveGizqHM9lhq_rhqozKseAD_7/pub?output=csv"
strt.stream.2019.url.two <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vRNwL17hN8tMuyzDCDKCTeXGjQ1eN7j881D0-pyi46PhTK7LwoqQ_jrwZWQrSypd3icId9KFpqsuatj/pub?output=csv"
moos.stream.2019.url <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vQMF0fbfNRwgU-9DfsCJ7LpPd_LoAL01gcSdHzNIFXJ5sSnXwH8Vvsqyj_nZAeWVcXGDWhyJP2TbjZq/pub?output=csv"

#FRCH_RainGauge_2019 <- read.csv(here("DoD_2019/RainGauge/FRCH.RainGauge.2019.csv"))
#FRCH_RainGauge_2019$Datetime <-  ymd_hms(FRCH_RainGauge_2019$Datetime)
#attributes(FRCH_RainGauge_2019$Datetime)$tzone <-'America/Anchorage'

#POKE_RainGauge_2019 <- read.csv("~/Documents/DoD_2019/RainGauge/POKE.RainGauge.2019.csv")
#POKE_RainGauge_2019$DateTime <- ymd_hms(POKE_RainGauge_2019$DateTime)
#attributes(POKE_RainGauge_2019$DateTime)$tzone <- 'America/Anchorage'

#VAUL_RainGauge_2019 <- read.csv("~/Documents/DoD_2019/RainGauge/VAUL.RainGauge.2019.csv")
#VAUL_RainGauge_2019$DateTime <- ymd_hms(VAUL_RainGauge_2019$DateTime)
#attributes(VAUL_RainGauge_2019$DateTime)$tzone <- 'America/Anchorage'

### read in data ###
frch.stream.one.2019 <- read.csv(url(frch.stream.2019.url))
frch.stream.two.2019 <- read.csv(url(frch.stream.2019.url.two))
vaul.stream.one.2019 <- read.csv(url(vaul.stream.2019.url))
poke.stream.one.2019 <- read.csv(url(poke.stream.2019.url))
poke.stream.two.2019 <- read.csv(url(poke.stream.2019.url.two))
strt.stream.one.2019 <- read.csv(url(strt.stream.2019.url)) # only goes to august
strt.stream.two.2019 <- read.csv(url(strt.stream.2019.url.two)) # goes all the way to october.
moos.stream.one.2019 <- read.csv(url(moos.stream.2019.url))

# Rename column headers # 
names(frch.stream.one.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
names(frch.stream.two.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
names(vaul.stream.one.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
names(poke.stream.one.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
names(poke.stream.two.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
names(strt.stream.one.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
names(strt.stream.two.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")
names(moos.stream.one.2019) <- c("Site", "DateTimeGMT", "Temp", "AbsPTDepth")

# Input NA for missing time #
frch.stream.one.2019$DateTimeGMT[frch.stream.one.2019$DateTimeGMT == ""] <- NA
frch.stream.two.2019$DateTimeGMT[frch.stream.two.2019$DateTimeGMT == ""] <- NA

vaul.stream.one.2019$DateTimeGMT[vaul.stream.one.2019$DateTimeGMT == ""] <- NA

poke.stream.one.2019$DateTimeGMT[poke.stream.one.2019$DateTimeGMT == ""] <- NA
poke.stream.two.2019$DateTimeGMT[poke.stream.two.2019$DateTimeGMT == ""] <- NA

strt.stream.one.2019$DateTimeGMT[strt.stream.one.2019$DateTimeGMT == ""] <- NA
strt.stream.two.2019$DateTimeGMT[strt.stream.two.2019$DateTimeGMT == ""] <- NA

moos.stream.one.2019$DateTimeGMT[moos.stream.one.2019$DateTimeGMT == ""] <- NA

# Convert time and put in AK time #
frch.stream.one.2019$DateTime <- as.POSIXct(paste(frch.stream.one.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
frch.stream.one.2019$DateTime <- lubridate::round_date(frch.stream.one.2019$DateTime, "15 minutes")
frch.stream.two.2019$DateTime <- as.POSIXct(paste(frch.stream.two.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
vaul.stream.one.2019$DateTime <- as.POSIXct(paste(vaul.stream.one.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
poke.stream.one.2019$DateTime <- as.POSIXct(paste(poke.stream.one.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
poke.stream.one.2019$DateTime <- lubridate::round_date(poke.stream.one.2019$DateTime, "15 minutes")
poke.stream.two.2019$DateTime <- as.POSIXct(paste(poke.stream.two.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
strt.stream.one.2019$DateTime <- as.POSIXct(paste(strt.stream.one.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
strt.stream.two.2019$DateTime <- as.POSIXct(paste(strt.stream.two.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
moos.stream.one.2019$DateTime <- as.POSIXct(paste(moos.stream.one.2019$DateTimeGMT), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")

# Observed discharge
myurl <- "https://docs.google.com/spreadsheets/d/e/2PACX-1vRUMy2yDlF5WQRDGgbuNHeVNp7diusfPJuKgikGY2ZQ8ewbG4Tyxm5TeN0shtDkxMmeL9M0AzhaL8l7/pub?output=csv"
QSummary.2019 <- read.csv(url(myurl))

QSummary.2019$Time[QSummary.2019$Time == ""] <- NA
QSummary.2019$Q_Ls[QSummary.2019$Q_Ls == ""] <- NA

### Format Time
QSummary.2019$Date <- mdy(QSummary.2019$Date)
QSummary.2019$DateTime <- as.POSIXct(paste(QSummary.2019$Date, QSummary.2019$Time), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
QSummary.2019$DateTime <- lubridate::round_date(QSummary.2019$DateTime, "15 minutes")

# Site names
frch.stream.two.2019 <- frch.stream.two.2019[1:nrow(frch.stream.one.2019),]
frch.stream.one.2019$Site <- "FRCH1" #add column identifier
frch.stream.two.2019$Site <- "FRCH2"
frch.pt.2019 <- bind_rows(frch.stream.one.2019, frch.stream.two.2019)

vaul.pt.2019 <- vaul.stream.one.2019
vaul.pt.2019$Site <- "VAUL1"

poke.stream.two.2019 <- poke.stream.two.2019[1:nrow(poke.stream.one.2019),]
poke.stream.one.2019$Site <- "POKE1" #add column identifier
poke.stream.two.2019$Site <- "POKE2"
poke.pt.2019 <- bind_rows(poke.stream.one.2019, poke.stream.two.2019)

moos.pt.2019 <- moos.stream.one.2019
moos.pt.2019$Site <- "MOOS1"
```


Checking closeness between the two Pressure Transducers
```{r , echo=FALSE, warning=FALSE}

# Checking closeness between two PT #
plot(x = frch.stream.one.2019$AbsPTDepth, y = frch.stream.two.2019$AbsPTDepth, main = "French PT comparison",
     xlab = "French1 PT", 
     ylab = "French2 PT")
abline(1,1) 

```

Looks pretty good

Checking Raw PT data 

Raw Moose
```{r, echo=FALSE, warning=FALSE}

plot(moos.stream.one.2019$DateTime, moos.stream.one.2019$AbsPTDepth, type = 'l')
```

Let the cleaning commence!

## Moose 2.0 ##
```{r, echo=FALSE, warning=FALSE}
moos.stream.one.2019 <- moos.stream.one.2019[-c(3715, 5179,5342), ]


moos.stream.one.2019 %>% filter(DateTime > "2019-07-01" & DateTime < "2019-07-10") %>% 
  ggplot(aes(DateTime, AbsPTDepth)) + geom_point()
```
1)removed vertical bars in dataframe
? Spike in early Julyish does have rainfall close to it....is it real?
Middle of October? Ice on? Should I clip middle of October, French was removed on October 10th according to the field notebook 

Fill in data gaps
```{r}
moos.stream.one.2019 <- moos.stream.one.2019[,c(5,4)]

DateTimeFill <- data.frame(DateTime = seq(ymd_hm("	
2019-05-31 15:45", tz = "America/Anchorage"),ymd_hm("2019-10-22 09:15", tz = "America/Anchorage"), by = '15 mins'))
moos.stream.one.2019 <- full_join(moos.stream.one.2019, DateTimeFill)
moos.stream.one.2019 <- moos.stream.one.2019[order(moos.stream.one.2019$DateTime),]
moos.stream.one.2019 <- na_kalman(moos.stream.one.2019, maxgap = 10)

moos.stream.one.2019$Site <- rep("MOOS", length(moos.stream.one.2019$DateTime))

ggplot(moos.stream.one.2019, aes(x = DateTime, y = AbsPTDepth)) +
  geom_point()
```

# Observed Discharge at all sites 

Slugs and wading rods were used for 2019 observed Q

```{r, echo=FALSE, fig.width=6, fig.height=4, warning=FALSE}
# ALL Sites #
all <- ggplot(QSummary.2019) +
  geom_point(aes(x=DateTime, y=Q_Ls, color=Site), size=3) +
  theme_classic() +
  scale_color_brewer(palette = "Set1") +
  ggtitle("ALL SITES")
all
```

Raw Rating Curve with Moose 1 Pressure Transducer

```{r, echo=FALSE, warning=FALSE}
QSummary.MO.2019 <- QSummary.2019 %>% filter(Site =="Moose")

QSummary.MO.2019$Site <- "MOOS"
moos.stream.one.2019$Site <- "MOOS"

Moose1comb.2019 <- full_join(moos.stream.one.2019, QSummary.MO.2019) 

Moose1.lm.2019 <- lm(Moose1comb.2019$Q_Ls ~ Moose1comb.2019$AbsPTDepth)
summary(Moose1.lm.2019) # I think this worked

moos.formula <- y ~ x

ggplot(aes(x = AbsPTDepth, y = Q_Ls), data = Moose1comb.2019) +
  geom_point(aes(color = Method), size = 3) +
  geom_smooth(method = "lm", se=FALSE) +
  stat_poly_eq(formula = moos.formula, 
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
               parse = TRUE) +
  xlim(0.9, 1.8) + 
  theme_classic() +
  ggtitle("Moose1 all measured Q")  # I think this worked


```
Not too shabby, I'm going to remove the top YSI point.

```{r, echo=FALSE, warning=FALSE}
QSummary.MO.2019.1 <- QSummary.MO.2019[-16, ]


Moose2comb.2019 <- full_join(moos.stream.one.2019, QSummary.MO.2019.1) 

Moose2.lm.2019 <- lm(Moose2comb.2019$Q_Ls ~ Moose2comb.2019$AbsPTDepth)
summary(Moose2.lm.2019) # I think this worked

moos.formula <- y ~ x

ggplot(aes(x = AbsPTDepth, y = Q_Ls), data = Moose2comb.2019) +
  geom_point(aes(color = Method), size = 3) +
  geom_smooth(method = "lm", se=FALSE) +
  stat_poly_eq(formula = moos.formula, 
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
               parse = TRUE) +
  xlim(0.9, 1.8) + 
  theme_classic() +
  ggtitle("Moose1 all measured Q")  # I think this worked


```

That's better, I will use this for the predicted discharge 

# Predicted Q MOOS PT1
Black points are observed Q

```{r, echo=FALSE, warning=FALSE}
Moose2comb.2019$pred.moos1.Q <- coef(Moose2.lm.2019)[2] * Moose2comb.2019$AbsPTDepth+ coef(Moose2.lm.2019)[1]
ggplot(aes(x = DateTime, y = pred.moos1.Q), data = Moose2comb.2019) +
  geom_line(color="#A6CEE3", size=1.25) +
  geom_point(aes(x = DateTime, y = Q_Ls), size=3) +
  theme_classic() +
  ggtitle("Moose1 predicted all measured Q") +
  xlab("Date") +
  ylab("Predicted Discharge") 
```

Not too shabby

### export PT data to csv to DoD_Discharge->Predicted_Discharge->2019
```{r, echo=FALSE, warning=FALSE}
Moose2comb.2019_final <- Moose2comb.2019[,c(3,1,11)]
names(Moose2comb.2019_final) <- c("Site", "DateTime", "Q")
Moose2comb.2019_final$Site <- rep("MOOS", length(Moose2comb.2019_final$DateTime))

# Remove early measured Q rows
Moose2comb.2019_final <- Moose2comb.2019_final %>% filter(DateTime >= "2019-05-31 15:45")

Moose2comb.2019_final <- na_kalman(Moose2comb.2019_final, maxgap = 10)

write.csv(Moose2comb.2019_final, here("Predicted_Discharge/2019/MOOS/MOOS.Q.csv"), row.names = FALSE)
```

## Raw French PT1
```{r, echo=FALSE, warning=FALSE}
#plot(FRCH_RainGauge_2019$inst_rainfall_mm ~ FRCH_RainGauge_2019$Datetime, type="h",
#     xlim = as.POSIXct(c("2019-04-29 14:15:00","2019-10-10 09:15:00"), tz="America/Anchorage"),
#     ylim = c(20,0), 
#     axes=F, xlab="", ylab="")
#par(new = T)
plot(frch.stream.one.2019$DateTime, frch.stream.one.2019$AbsPTDepth, type = 'l')
```
Looks good. I am going to replace the noisy-ness of the receding limb in the big august storm with FRCH PT2 as it is less noisy let the cleaning commence!

# FRCH PT1 2.0
```{r, echo=FALSE, warning=FALSE}
which(frch.stream.one.2019$AbsPTDepth > 2.40) 
frch.stream.one.2019.1 <- frch.stream.one.2019 %>% subset(frch.stream.one.2019$DateTime < "2019-08-24 00:00:00" & frch.stream.one.2019$DateTime > "2019-08-17 00:00:00") 

frch.stream.one.2019.before <- frch.stream.one.2019[-c(10549:15724), ]  # clipping off to have beginning of dataframe

frch.stream.two.middle <- frch.stream.two.2019[-c(1:10549, 11162:15724), ]

frch.stream.one.2019.after <- frch.stream.one.2019[-c(1:11162), ]  # clipping off to have beginning of dataframe

frch.stream.one.all <- rbind(frch.stream.one.2019.before, frch.stream.two.middle, frch.stream.one.2019.after)
plot(frch.stream.one.all$DateTime, frch.stream.one.all$AbsPTDepth, type = "l")
frch.stream.one.2019 <- frch.stream.one.all
plot(frch.stream.one.2019$DateTime, frch.stream.one.2019$AbsPTDepth, type = "l")
```
1) replaced the noisy receding limb in the big end of August storm of PT1 with the more constant data of PT2

## Raw French PT2
```{r, echo=FALSE, warning=FALSE}
#plot(FRCH_RainGauge_2019$inst_rainfall_mm ~ FRCH_RainGauge_2019$Datetime, type="h",
#     xlim = as.POSIXct(c("2019-04-29 14:15:00","2019-10-10 09:15:00"), tz="America/Anchorage"),
#     ylim = c(20,0), 
#     axes=F, xlab="", ylab="")
#par(new = T)
plot(frch.stream.two.2019$DateTime, frch.stream.two.2019$AbsPTDepth, type = 'l')

```

Going to clean some of the vertical bars in may but other than that this looks pretty good!
let the cleaning commence 

FRCH PT2 2.0
```{r, echo=FALSE, warning=FALSE}
frch.stream.two.2019 <- frch.stream.two.2019[-c(107,108,389,610,964),] 
#plot(FRCH_RainGauge_2019$inst_rainfall_mm ~ FRCH_RainGauge_2019$Datetime, type="h",
#     xlim = as.POSIXct(c("2019-04-29 14:15:00","2019-10-10 09:15:00"), tz="America/Anchorage"),
#     ylim = c(20,0), 
#     axes=F, xlab="", ylab="")
#ar(new = T)
plot(frch.stream.two.2019$DateTime, frch.stream.two.2019$AbsPTDepth, type = 'l')

```
1) removed vertical bars early on in season 

Check closeness between French PT1 and PT2
```{r}
frch.pt.2019.wide <- full_join(frch.stream.one.2019[,4:5], frch.stream.two.2019[,4:5], by = "DateTime")
plot(frch.pt.2019.wide$AbsPTDepth.x, frch.pt.2019.wide$AbsPTDepth.y)
```

Export PT data to csv to DoD_Discharge->PT_data->2019
```{r, echo=FALSE, warning=FALSE}
frch.stream.one.2019 <- frch.stream.one.2019[,c(1,5,4)]
frch.stream.two.2019 <- frch.stream.two.2019[,c(1,5,4)]

frch.stream.2019 <- rbind(frch.stream.one.2019, frch.stream.two.2019)
write.csv(frch.stream.2019, here("PT_data/2019/FRCH/frch.pt.2019.csv"), row.names = FALSE)

ggplot(frch.stream.2019, aes(x = DateTime, y = AbsPTDepth, color = Site)) +
  geom_point()


```


# Raw Rating Curve with French 1 Pressure Transducer

```{r, echo=FALSE, warning=FALSE}
QSummary.FR.2019 <- QSummary.2019 %>% filter(Site =="French") %>% drop_na(Q_Ls)
QSummary.FR.2019$Site <- "FRCH"


French1comb.2019 <- full_join(frch.stream.one.2019, QSummary.FR.2019, by = "DateTime") 
French1.lm.2019 <- lm(French1comb.2019$Q_Ls ~ French1comb.2019$AbsPTDepth)
summary(French1.lm.2019)  # Worked

frch.formula <- y ~ x

ggplot(aes(x = AbsPTDepth, y = Q_Ls), data = French1comb.2019) +
  geom_point(aes(color = Method), size = 3) +
  geom_smooth(method = "lm", se=FALSE) +
  stat_poly_eq(formula = frch.formula, 
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
               parse = TRUE) +
  theme_classic() +
  ggtitle("French1 all measured Q")


```

Lots of points that are clustered at the bottom. I will remove the 3 large YSI points 

```{r, echo=FALSE, warning=FALSE}
QSummary.FR.2019.1 <- QSummary.FR.2019[-c(11:13), ]

French2comb.2019 <- full_join(frch.stream.one.2019, QSummary.FR.2019.1, by = "DateTime") 
French2.lm.2019 <- lm(French2comb.2019$Q_Ls ~ French2comb.2019$AbsPTDepth)
summary(French2.lm.2019)  # Worked

frch.formula <- y ~ x

ggplot(aes(x = AbsPTDepth, y = Q_Ls), data = French2comb.2019) +
  geom_point(aes(color = Method), size = 3) +
  geom_smooth(method = "lm", se=FALSE) +
  stat_poly_eq(formula = frch.formula, 
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
               parse = TRUE) +
  xlim(0.59, 0.67) +
  ylim(0, 300) +
  theme_classic() +
  ggtitle("French1 all measured Q")


```

Not as good of an R^2. 

Rating curve with two high Q points.
```{r, echo=FALSE, warning=FALSE}
QSummary.FR.2019 <- QSummary.2019 %>% filter(Site =="French") %>% drop_na(Q_Ls) %>% filter(Q_Ls < 1500)
QSummary.FR.2019$Site <- "FRCH"


French1comb.2019 <- full_join(frch.stream.one.2019, QSummary.FR.2019, by = "DateTime") 
French1.lm.2019 <- lm(French1comb.2019$Q_Ls ~ French1comb.2019$AbsPTDepth)
summary(French1.lm.2019)  # Worked

frch.formula <- y ~ x

ggplot(aes(x = AbsPTDepth, y = Q_Ls), data = French1comb.2019) +
  geom_point(aes(color = Method), size = 3) +
  geom_smooth(method = "lm", se=FALSE) +
  stat_poly_eq(formula = frch.formula, 
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
               parse = TRUE) +
  theme_classic() +
  ggtitle("French1 measured Q")


```

# Predict Q French1

```{r, echo=FALSE, warning=FALSE}
French1comb.2019 <- full_join(frch.stream.one.2019, QSummary.FR.2019, by = "DateTime") %>% filter(!AbsPTDepth %in% NA)
French1.lm.2019 <- lm(French1comb.2019$Q_Ls ~ French1comb.2019$AbsPTDepth)

French1comb.2019$pred.french1.Q <- coef(French1.lm.2019)[2] * French1comb.2019$AbsPTDepth+ coef(French1.lm.2019)[1]

ggplot(aes(x = DateTime, y = pred.french1.Q), data=French1comb.2019) +
  geom_point(color="#A6CEE3", size=1.25) +
  geom_point(data = French1comb.2019, aes(x = DateTime, y = Q_Ls, shape = Method), size = 3) +
  theme_classic() +
  ggtitle("French") +
  scale_shape_discrete(name = "Method", labels = c("Wading Rod", "Salt Dilution", "")) +
  xlab("") +
  ylab("Discharge (L/s)")



```

# Raw Rating Curve with French 2 Pressure Transducer

```{r, echo=FALSE, warning=FALSE}

French3comb.2019 <- full_join(frch.stream.two.2019, QSummary.FR.2019, by = "DateTime") 
French3.lm.2019 <- lm(French3comb.2019$Q_Ls ~ French3comb.2019$AbsPTDepth)
summary(French3.lm.2019) # worked


ggplot(aes(x = AbsPTDepth, y = Q_Ls), data = French3comb.2019) +
  geom_point(aes(color = Method), size = 3) +
  geom_smooth(method = "lm", se=FALSE) +
  stat_poly_eq(formula = frch.formula, 
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
               parse = TRUE) +
  theme_classic() +
  ggtitle("French2 all measured Q")


```
Same thing as FRCH 1. Next plot will be without the 3 high YSI points

```{r, echo=FALSE, warning=FALSE}

French4comb.2019 <- full_join(frch.stream.two.2019, QSummary.FR.2019.1, by = "DateTime") 
French4.lm.2019 <- lm(French4comb.2019$Q_Ls ~ French4comb.2019$AbsPTDepth)
summary(French2.lm.2019)  # Worked

frch.formula <- y ~ x

ggplot(aes(x = AbsPTDepth, y = Q_Ls), data = French4comb.2019) +
  geom_point(aes(color = Method), size = 3) +
  geom_smooth(method = "lm", se=FALSE) +
  stat_poly_eq(formula = frch.formula, 
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
               parse = TRUE) +
  xlim(0.4, 0.5) +
  theme_classic() +
  ggtitle("French2 all measured Q")


```
I will remove the low flowmeter point for the next plot

```{r, echo=FALSE, warning=FALSE}

QSummary.FR.2019.2 <- QSummary.FR.2019[-c(10,11:13), ]

French5comb.2019 <- full_join(frch.stream.two.2019, QSummary.FR.2019.2, by = "DateTime") 
French5.lm.2019 <- lm(French5comb.2019$Q_Ls ~ French5comb.2019$AbsPTDepth)
summary(French5.lm.2019)

frch.formula <- y ~ poly(x, 2, raw = TRUE)

ggplot(aes(x = AbsPTDepth, y = Q_Ls), data = French5comb.2019) +
  geom_point(aes(color = Method), size = 3) +
  geom_smooth(method = "lm", se=FALSE) +
  stat_poly_eq(formula = frch.formula, 
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
               parse = TRUE) +
  xlim(0.4, 0.5) +
  theme_classic() +
  ggtitle("French2 all measured Q")


```
Lets also remove that high depth, low Q YSI point. 

```{r, echo=FALSE, warning=FALSE}

QSummary.FR.2019.3 <- QSummary.FR.2019[-c(10,5,11:13), ]

French6comb.2019 <- full_join(frch.stream.two.2019, QSummary.FR.2019.3, by = "DateTime") 
French6.lm.2019 <- lm(French6comb.2019$Q_Ls ~ French6comb.2019$AbsPTDepth)
summary(French6.lm.2019)

frch.formula <- y ~ x

p1 <- ggplot(aes(x = AbsPTDepth, y = Q_Ls), data = French6comb.2019) +
  geom_point(aes(color = Method), size = 3) +
  geom_smooth(method = "lm", se=FALSE) +
  stat_poly_eq(formula = frch.formula, 
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
               parse = TRUE) +
  xlim(0.4, 0.5) +
  theme_classic() +
  ggtitle("French2 measured Q")
p1

```

This is the RC I will use for predicted Q.

# Predicted Q FRCH PT2
Black points are observed Q

```{r, echo=FALSE, warning=FALSE}
French6comb.2019$pred.french2.Q <- coef(French6.lm.2019)[2] * French6comb.2019$AbsPTDepth+ coef(French6.lm.2019)[1]

p2 <- ggplot(aes(x = DateTime, y = pred.french2.Q), data=French6comb.2019, by = "DateTime") +
  geom_line(color="#A6CEE3", size=1.25) +
  geom_point(data = French1comb.2019, aes(x = DateTime, y = Q_Ls, shape = Method), size = 3) +
  theme_classic() +
  ggtitle("French") +
  scale_shape_discrete(name = "Method", labels = c("Wading Rod", "Salt Dilution", "")) +
  xlab("") +
  ylab("Discharge (L/s)") +
  #ylim(50, 200) +
  scale_x_datetime(limits = as_datetime(c("2019-05-15", "2019-10-10")))
#scale_x_datetime(limits = as_datetime(c("2019-05-15", "2019-8-03")))
p2

```

Without a big range in observed Q this is the best we can do.

Most of the water level is above the water level for our Q measurements. Maybe it is more accurate to include the high points?

```{r, echo=FALSE, warning=FALSE}


French7comb.2019 <- full_join(frch.stream.two.2019, QSummary.FR.2019, by = "DateTime")  %>% filter(!AbsPTDepth %in% NA)
French7.lm.2019 <- lm(French7comb.2019$Q_Ls ~ French7comb.2019$AbsPTDepth)
summary(French7.lm.2019)

frch.formula <- y ~ x

p3 <- ggplot(aes(x = AbsPTDepth, y = Q_Ls), data = French7comb.2019) +
  geom_point(aes(color = Method), size = 3) +
  geom_smooth(method = "lm", se=FALSE) +
  stat_poly_eq(formula = frch.formula, 
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
               parse = TRUE) +
  theme_classic() +
  ggtitle("French2 measured Q")

p3
```

Lets plot and compare with previous prediction.

```{r, echo=FALSE, warning=FALSE}
French7comb.2019$pred.french2.Q <- coef(French7.lm.2019)[2] * French7comb.2019$AbsPTDepth+ coef(French7.lm.2019)[1]

p4 <- ggplot(aes(x = DateTime, y = pred.french2.Q), data=French7comb.2019, by = "DateTime") +
  geom_line(color="#A6CEE3", size=1.25) +
  geom_line(data = French6comb.2019, aes(DateTime, pred.french2.Q), color= "light green", size=1.25) +
  geom_point(data = French1comb.2019, aes(x = DateTime, y = Q_Ls, shape = Method), size=3) +
  theme_classic() +
  ggtitle("French") +
  scale_shape_discrete(name = "Method", labels = c("Wading Rod", "Salt Dilution", "")) +
  xlab("") +
  ylab("Discharge (L/s)") +
  #ylim(0, 1000) +
  scale_x_datetime(limits = as_datetime(c("2019-05-15", "2019-10-10")))

p4
```
Lets zoom in on the low Q

```{r}

p5 <- ggplot(aes(x = DateTime, y = pred.french2.Q), data=French7comb.2019) +
  geom_line(color="#A6CEE3", size=1.25) +
  geom_line(data = French6comb.2019, aes(DateTime, pred.french2.Q), color= "light green", size=1.25) +
  geom_point(data = French1comb.2019, aes(x = DateTime, y = Q_Ls, shape = Method), size=3) +
  theme_classic() +
  ggtitle("French") +
  scale_shape_discrete(name = "Method", labels = c("Wading Rod", "Salt Dilution", "")) +
  xlab("") +
  ylab("Discharge (L/s)") +
  ylim(60, 200) +
  scale_x_datetime(limits = as_datetime(c("2019-05-15", "2019-8-03")))

p5
```
```{r}
library(gridExtra)
grid.arrange(p1, p3, p4, p5)

```

It looks to me (Karen) that the prediction using the regression including the two high Q points fits better. I will use this to predict discharge.


### Compare FRCH PT1 and PT2
```{r, echo=FALSE, warning=FALSE}

frch.final.discharge.2019 <- full_join(French1comb.2019[,c(1,2,12)], French7comb.2019[,c(2,12)])
#frch.final.discharge.2019 %>% filter(DateTime > "2019-08-12" & DateTime < "2019-08-20") %>% View()

frch.final.discharge.2019$MeanDischarge <- rowMeans(frch.final.discharge.2019[,3:4], na.rm = TRUE)

frch.final.discharge.2019 %>% ggplot(aes(x = DateTime, y = pred.french1.Q)) +
  geom_line(color="#A6CEE3", size=1.25) +
  geom_line(aes(x = DateTime, y = pred.french2.Q),color="#1F78B4", size=1.25, alpha = 0.75)+
  geom_line(aes(x = DateTime, y = MeanDischarge),color="red", size=1.25, alpha = 0.75)+
  geom_point(aes(x = DateTime, y = Q_Ls), data = French1comb.2019, size=2) +
  theme_classic() +
  ggtitle("Frecnh1(light) French2(dark) & MeanDischarge (red) predicted and measured Q") +
  ylab("Predicted discharge L/s") +
  xlab("Time")

```

# Export PT data to csv to DoD_Discharge->Predicted_Discharge->2019
```{r, echo=FALSE, warning=FALSE}
frch.final.discharge.2019.final <- frch.final.discharge.2019[,-c(3,4)]
names(frch.final.discharge.2019.final) <- c("Site", "DateTime", "Q")
frch.final.discharge.2019.final$Site <- rep("FRCH", length(frch.final.discharge.2019.final$DateTime))

DateTimeFill <- data.frame(DateTime = seq(ymd_hm("	
2019-04-29 14:15", tz = "America/Anchorage"),ymd_hm("2019-10-10 9:15", tz = "America/Anchorage"), by = '15 mins'))
frch.final.discharge.2019 <- full_join(frch.final.discharge.2019, DateTimeFill)

frch.final.discharge.2019 <- frch.final.discharge.2019[order(frch.final.discharge.2019$DateTime),]
frch.final.discharge.2019 <- na_kalman(frch.final.discharge.2019, maxgap = 10)

frch.final.discharge.2019.final$Site <- rep("FRCH", length(frch.final.discharge.2019.final$DateTime))
write.csv(frch.final.discharge.2019.final, here("Predicted_Discharge/2019/FRCH/FRCH.Q.csv"), row.names = FALSE)

```

## Raw Poker PT1 2019
```{r, echo=FALSE, warning=FALSE}
#plot(POKE_RainGauge_2019$inst_rainfall_mm ~ POKE_RainGauge_2019$DateTime, type="h",
#     xlim = as.POSIXct(c("2019-05-10 14:45:00","2019-10-18 10:15:00"), #tz="America/Anchorage"),
#     ylim = c(20,0), 
#     axes=F, xlab="", ylab="")
#par(new = T)

poke.stream.one.2019.b <- poke.stream.one.2019

plot(poke.stream.one.2019$DateTime, poke.stream.one.2019$AbsPTDepth, type = 'l')

```

The beginning increase appears to be real with the precip on top. I need to remove some of the "vertical bars within the data frame and check take out date. I am also going to take out the beaver dam that is there from late august to middle of september  Let the cleaning commence!

```{r, echo=FALSE, warning=FALSE}
poke.stream.one.2019 <- poke.stream.one.2019[-c(15015:15439), ] # remove out of water points - PT removed on the 14th
poke.stream.one.2019[c(3359:3365, 5959:5967, 6517:6530, 7296:7300), 4] <- NA  # remove vertical bars...set to NA

poke.stream.one.2019 <- poke.stream.one.2019[-c(10406:11611), ] # remove beaver dam 



# Shift jump at start of August
poke.stream.one.2019 <- poke.stream.one.2019 %>% mutate(across(c(AbsPTDepth), ~ifelse(DateTime <= "2019-08-02 20:15:00", AbsPTDepth + 0.135,.)))

poke.stream.one.2019 <- na_kalman(poke.stream.one.2019, maxgap = 10)
#plot(POKE_RainGauge_2019$inst_rainfall_mm ~ POKE_RainGauge_2019$DateTime, type="h",
#     xlim = as.POSIXct(c("2019-05-10 14:45:00","2019-10-18 10:15:00"), #tz="America/Anchorage"),
#     ylim = c(20,0), 
#     axes=F, xlab="", ylab="")
#par(new = T)

poke.stream.one.2019 %>% #filter(DateTime > "2019-08-01" & DateTime < "2019-08-05") %>%
  ggplot(aes(DateTime, AbsPTDepth)) + geom_point()

```
1) Removed vertical bars early on in dataset
2) Removed beaver dam related data entirely
3) removed end of season out of water points

## Raw Poker PT2
```{r, echo=FALSE, warning=FALSE}
#plot(POKE_RainGauge_2019$inst_rainfall_mm ~ POKE_RainGauge_2019$DateTime, type="h",
#     xlim = as.POSIXct(c("2019-05-10 14:45:00","2019-10-18 10:15:00"), #tz="America/Anchorage"),
#     ylim = c(20,0), 
#     axes=F, xlab="", ylab="")
#par(new = T)
plot(poke.stream.two.2019$DateTime, poke.stream.two.2019$AbsPTDepth, type = 'l')
```

Same procedure as PT1....let the cleaning commence!

```{r, echo=FALSE, warning=FALSE}
poke.stream.two.2019 <- poke.stream.two.2019[-c(9738:11227, 14634:15058), ] # remove out of water points - PT removed on the 14th and the beaver dam
poke.stream.two.2019[c(4, 2978:2983, 5578:5587,6137:6150, 6913:6920), 4] <- NA  # remove vertical bars...set to NA

poke.stream.two.2019 <- na_kalman(poke.stream.two.2019, maxgap = 10)

#plot(POKE_RainGauge_2019$inst_rainfall_mm ~ POKE_RainGauge_2019$DateTime, type="h",
#     xlim = as.POSIXct(c("2019-05-10 14:45:00","2019-10-18 10:15:00"), #tz="America/Anchorage"),
#     ylim = c(20,0), 
#     axes=F, xlab="", ylab="")
#par(new = T)
plot(poke.stream.two.2019$DateTime, poke.stream.two.2019$AbsPTDepth)

```
1) Removed vertical bars early on in dataset
2) Removed beaver dam related data entirely
3) removed end of season out of water points

### export PT data to csv to DoD_Discharge->PT_data->2019
```{r, echo=FALSE, warning=FALSE}
poke.pt.2019 <- rbind(poke.stream.one.2019, poke.stream.two.2019)
poke.pt.2019.final <- poke.pt.2019[,c(1,4,5)]

write.csv(poke.pt.2019.final, here("PT_data/2019/POKE/poke.pt.2019.csv"), row.names = FALSE)

ggplot(poke.pt.2019.final, aes(x = DateTime, y = AbsPTDepth, color = Site)) +
  geom_point()



```


### Raw Rating Curve with Poker 1 Pressure Transducer

```{r, echo=FALSE, warning=FALSE}
QSummary.PO.2019 <- QSummary.2019 %>% filter(Site =="Poker") %>% drop_na(Q_Ls)
QSummary.PO.2019$Site <- "POKE"
poke.stream.one.2019$Site <- "POKE"

Poker1comb.2019 <- full_join(poke.stream.one.2019, QSummary.PO.2019)
Poker1.lm.2019 <- lm(Poker1comb.2019$Q_Ls ~ Poker1comb.2019$AbsPTDepth)
summary(Poker1.lm.2019) 

poke.formula <- y ~ x


ggplot(aes(x = AbsPTDepth, y = Q_Ls), data = Poker1comb.2019) +
  geom_point(aes(color = Method), size = 3) +
  geom_smooth(method = "lm", se=FALSE, formula = poke.formula) +
  stat_poly_eq(formula = poke.formula, 
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
               parse = TRUE) +
  xlim(0, 0.6) +
  theme_classic() +
  ggtitle("Poker1 all measured Q")

```

### Predicted Q POKE PT1
#### Black points are observed Q

```{r, echo=FALSE, warning=FALSE}
Poker1comb.2019$pred.poke1.Q <- coef(Poker1.lm.2019)[2] * Poker1comb.2019$AbsPTDepth+ coef(Poker1.lm.2019)[1]
ggplot(aes(x = DateTime, y = pred.poke1.Q), data=Poker1comb.2019) +
  geom_line(color="#A6CEE3", size=1.25) +
  geom_point(aes(x = DateTime, y = Q_Ls, shape = Method), size=3) +
  theme_classic() +
  ggtitle("Poker") +
  scale_shape_discrete(name = "Method", labels = c("Wading Rod", "Salt Dilution", "")) +
  xlab("") +
  ylab("Discharge (L/s)") +
  ylim(0, 1500) +
  scale_x_datetime(limits = as_datetime(c("2019-05-15", "2019-10-10")))
```

Not the worst thing I've seen in the world 

### Raw Rating Curve with Poker 2 Pressure Transducer

```{r, echo=FALSE, warning=FALSE}
poke.stream.two.2019$Site <- "POKE"

Poker2comb.2019 <- full_join(poke.stream.two.2019, QSummary.PO.2019)
Poker2.lm.2019 <- lm(Poker2comb.2019$Q_Ls ~ Poker2comb.2019$AbsPTDepth)
summary(Poker2.lm.2019)

ggplot(aes(x= AbsPTDepth, y = Q_Ls), data = Poker2comb.2019) +
  geom_point(aes(color = Method), size = 3) +
  geom_smooth(method = "lm", se=FALSE) +
  stat_poly_eq(formula = poke.formula, 
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
               parse = TRUE) +
  xlim(0.3,0.6) +
  theme_classic() +
  ggtitle("Poker2 all measured Q") 

```
### Predicted Q POKE PT2
#### Black points are observed Q

```{r, echo=FALSE, warning=FALSE}
Poker2comb.2019$pred.poke2.Q <- coef(Poker2.lm.2019)[2] * Poker2comb.2019$AbsPTDepth+ coef(Poker2.lm.2019)[1]
ggplot(aes(x = DateTime, y = pred.poke2.Q), data=Poker2comb.2019) +
  geom_line(color="#A6CEE3", size=1.25) +
  geom_point(aes(x = DateTime, y = Q_Ls, shape = Method), size=3) +
  theme_classic() +
  ggtitle("Poker2 predicted all measured Q") +
  xlab("Date") +
  ylab("Predicted Discharge") +
  ylim(0, 2000)

```

### Average POKE Q ###
```{r, echo=FALSE, warning=FALSE}
poke.final.discharge.2019 <- left_join(Poker1comb.2019, Poker2comb.2019, by = c("DateTime"))
poke.final.discharge.2019$MeanDischarge <- rowMeans(poke.final.discharge.2019[,c(13,25)], na.rm = TRUE)
poke.final.discharge.2019 <- poke.final.discharge.2019[,-c(3:12, 14:24)] # cleaning empty columns
names(poke.final.discharge.2019) <- c("Site", "DateTime", "PT1", "PT2", "MeanDischarge")
poke.final.discharge.2019$DateTime <- as.POSIXct(paste(poke.final.discharge.2019$DateTime), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
poke.final.discharge.2019$DateTime <- lubridate::round_date(poke.final.discharge.2019$DateTime, "15 minutes")

poke.final.discharge.2019 <- poke.final.discharge.2019


ggplot(aes(x = DateTime, y = pred.poke1.Q), data = Poker1comb.2019) +
  geom_line(aes(x = DateTime, y = pred.poke1.Q), data = Poker1comb.2019, color="#A6CEE3", size=1.25) +
  geom_line(aes(x = DateTime, y = pred.poke2.Q), data = Poker2comb.2019,color="#1F78B4", size=1.25, alpha = 0.75) +
  geom_line(aes(x = DateTime, y = MeanDischarge), data = poke.final.discharge.2019, color = "red", size = 1.25, alpha = 0.25) +
  geom_point(aes(x = DateTime, y = Q_Ls), size=2) +
  theme_classic() +
  ylim(0, 3000) +
  ggtitle("Poker1(light) Poker2(dark) & MeanDischarge (red) predicted all measured Q") +
  ylab("Predicted discharge L/s") +
  xlab("Time")

```

### export Q to csv to DoD_Discharge->Predicted_Discharge->2019
```{r, echo=FALSE, warning=FALSE}
poke.final.discharge.2019.final <- poke.final.discharge.2019[,c(2,5)]
names(poke.final.discharge.2019.final) <- c("DateTime", "Q")


# Fill missing data
DateTimeFill <- data.frame(DateTime = seq(ymd_hm("	
2019-05-10 14:45", tz = "America/Anchorage"),ymd_hm("2019-10-14 00:00", tz = "America/Anchorage"), by = '15 mins'))
poke.final.discharge.2019.final <- full_join(poke.final.discharge.2019.final, DateTimeFill)
poke.final.discharge.2019.final <- poke.final.discharge.2019.final[order(poke.final.discharge.2019.final$DateTime),]
poke.final.discharge.2019.final <- na_kalman(poke.final.discharge.2019.final, maxgap = 10)

poke.final.discharge.2019.final$Site <- "POKE"

ggplot(poke.final.discharge.2019.final, aes(x = DateTime, y = Q)) +
  geom_point()

write.csv(poke.final.discharge.2019.final, here("Predicted_Discharge/2019/POKE/POKE.Q.csv"), row.names = FALSE)
```

## Raw Vault PT1
```{r, echo=FALSE, warning=FALSE}
#plot(VAUL_RainGauge_2019$inst_rainfall_mm ~ VAUL_RainGauge_2019$DateTime, type="h",
#     xlim = as.POSIXct(c("2019-06-07 17:45:00","2019-10-18 10:15:00"), tz="America/Anchorage"),
#     ylim = c(20,0), 
#     axes=F, xlab="", ylab="")
#par(new = T)
plot(vaul.stream.one.2019$DateTime, vaul.stream.one.2019$AbsPTDepth)

```

Out of water at the end of the year? Let the cleaning commence!

```{r, echo=FALSE, warning=FALSE}
vaul.stream.one.2019 <- vaul.stream.one.2019 %>% subset(vaul.stream.one.2019$DateTime > "2019-06-07" & 
vaul.stream.one.2019$DateTime < "2019-10-11 14:00") # removed on 10/18


#plot(VAUL_RainGauge_2019$inst_rainfall_mm ~ VAUL_RainGauge_2019$DateTime, #type="h",
#     xlim = as.POSIXct(c("2019-06-07 17:45:00","2019-10-18 10:15:00"), #tz="America/Anchorage"),
#     ylim = c(20,0), 
#     axes=F, xlab="", ylab="")
#par(new = T)
plot(vaul.stream.one.2019$DateTime, vaul.stream.one.2019$AbsPTDepth, type = 'l')

# 
```
1) Removed end of record as there were erroneous points that might have been from ice on and then also out of water points 

### export PT data to csv to DoD_Discharge->PT_data->2019
```{r, echo=FALSE, warning=FALSE}
write.csv(vaul.stream.one.2019, here("PT_data/2019/VAUL/vaul.pt.2019.csv"), row.names = FALSE)
```



### Raw Rating Curve with VAUL PT1

```{r, echo=FALSE, warning=FALSE}
QSummary.VA.2019 <- QSummary.2019 %>% filter(Site =="Vault") %>% drop_na(Q_Ls)
vaul.stream.one.2019$Site <- "VAUL"
QSummary.VA.2019$Site <- "VAUL"

Vaultcomb.2019 <- full_join(vaul.stream.one.2019, QSummary.VA.2019)

Vault.lm.2019<- lm(Vaultcomb.2019$Q_Ls ~ 0 + Vaultcomb.2019$AbsPTDepth)
summary(Vault.lm.2019)

vaul.formula <- y ~ x

ggplot(aes(x = AbsPTDepth, y = Q_Ls), data = Vaultcomb.2019) +
  geom_point(aes(color = Method), size = 3) +
  geom_smooth(method = "lm", se=FALSE) +
  stat_poly_eq(formula = vaul.formula, 
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
               parse = TRUE) +
  xlim(0.4, 0.65) +
  theme_classic() +
  ggtitle("Vault all measured Q")  # I think this worked

```

Lets remove the highest Q and two lowest PT depth YSI points

```{r, echo=FALSE, warning=FALSE}
QSummary.VA.2019.2 <- QSummary.2019 %>% filter(Site =="Vault") %>% 
  #filter(Method != "YSI" | Q_Ls < 100,
  #       #Date != "2019-08-22"
  #       ) %>% 
  drop_na(Q_Ls)

QSummary.VA.2019.2$Site <- "VAUL"

Vaultcomb.2019.2 <- full_join(vaul.stream.one.2019, QSummary.VA.2019.2)



vaul.formula <- y ~ x

ggplot(aes(x = AbsPTDepth, y = Q_Ls), data = Vaultcomb.2019.2) +
  geom_point(aes(color = Method), size = 3) +
  geom_smooth(method = "lm", se=FALSE, formula = vaul.formula) +
  stat_poly_eq(formula = vaul.formula, 
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")),
               parse = TRUE) +
  xlim(0.4, 0.65) +
  theme_classic() +
  ggtitle("Vault measured Q")

```
 
 ### Predicted Q VAULPT1
#### Black points are observed Q

```{r, echo=FALSE, warning=FALSE}
Vault.lm.2019.2 <- lm(Vaultcomb.2019.2$Q_Ls ~ Vaultcomb.2019.2$AbsPTDepth + I(Vaultcomb.2019.2$AbsPTDepth^2))
summary(Vault.lm.2019.2)

Vaultcomb.2019.2$pred.vault.Q <- coef(Vault.lm.2019.2)[1] + coef(Vault.lm.2019.2)[2] * Vaultcomb.2019.2$AbsPTDepth + coef(Vault.lm.2019.2)[3] * I(Vaultcomb.2019.2$AbsPTDepth^2)
ggplot(aes(x = DateTime, y = pred.vault.Q), data = Vaultcomb.2019.2) +
  geom_line(color="#A6CEE3", size=1.25) +
  geom_point(data = Vaultcomb.2019, aes(x = DateTime, y = Q_Ls, shape = Method), size=3) +
  theme_classic() +
  ggtitle("Vault") +
  scale_shape_discrete(name = "Method", labels = c("Wading Rod", "Salt Dilution", "")) +
  xlab("") +
  ylab("Discharge (L/s)") +
  scale_x_datetime(limits = as_datetime(c("2019-05-15", "2019-10-10")))

```


### export PT data to csv to DoD_Discharge->Predicted_Discharge->2019
```{r, echo=FALSE, warning=FALSE}
vaul.final.discharge.2019.final <- Vaultcomb.2019.2[,-c(2:4,6:12)]
names(vaul.final.discharge.2019.final) <- c("Site", "DateTime", "Q")
vaul.final.discharge.2019.final$Site <- rep("VAUL", length(vaul.final.discharge.2019.final$DateTime))

DateTimeFill <- data.frame(DateTime = seq(ymd_hm("	
2019-06-07 17:45", tz = "America/Anchorage"),ymd_hm("2019-10-11 13:45", tz = "America/Anchorage"), by = '15 mins'))
vaul.final.discharge.2019.final <- full_join(vaul.final.discharge.2019.final, DateTimeFill)
vaul.final.discharge.2019.final <- vaul.final.discharge.2019.final[order(vaul.final.discharge.2019.final$DateTime),]
vaul.final.discharge.2019.final <- na_kalman(vaul.final.discharge.2019.final, maxgap = 10)

write.csv(vaul.final.discharge.2019.final, here("Predicted_Discharge/2019/VAUL/VAUL.Q.csv"), row.names = FALSE)

ggplot(vaul.final.discharge.2019.final, aes(x = DateTime, y = Q)) +
  geom_point()


```


## Raw Stuart PT1
```{r, echo=FALSE, warning=FALSE}
#plot(FRCH_RainGauge_2019$inst_rainfall_mm ~ FRCH_RainGauge_2019$Datetime, #type="h",
#     xlim = as.POSIXct(c("2019-05-21 14:45:00","2019-08-23 10:15:00"), #tz="America/Anchorage"),
#     ylim = c(20,0), 
#     axes=F, xlab="", ylab="")
#par(new = T)
plot(strt.stream.one.2019$DateTime, strt.stream.one.2019$AbsPTDepth, type = 'p')

```

Stuart PT1 only has record until 8/23... Looks pretty clean though

## Raw Stuart PT2
```{r, echo=FALSE, warning=FALSE}
#plot(FRCH_RainGauge_2019$inst_rainfall_mm ~ FRCH_RainGauge_2019$Datetime, #type="h",
#     xlim = as.POSIXct(c("2019-05-21 14:45:00","2019-10-16 10:15:00"), #tz="America/Anchorage"),
#     ylim = c(20,0), 
#     axes=F, xlab="", ylab="")
#par(new = T)
plot(strt.stream.two.2019$DateTime, strt.stream.two.2019$AbsPTDepth, type = 'p')

```

Just looks like I need to clip out the end of the season points there...Let the cleaning commence!

### STRT PT2 2.0 ###
```{r, echo=FALSE, warning=FALSE}
strt.stream.two.2019 <- strt.stream.two.2019 %>% subset(strt.stream.two.2019$DateTime > "2019-05-21" & strt.stream.two.2019$DateTime < "2019-10-13") # removed on 10/16 but erroneous values starting after the 14th....maybe ice...maybe beaver dam?

#plot(FRCH_RainGauge_2019$inst_rainfall_mm ~ FRCH_RainGauge_2019$Datetime, #type="h",
#     xlim = as.POSIXct(c("2019-05-21 14:45:00","2019-10-16 10:15:00"), #tz="America/Anchorage"),
#     ylim = c(20,0), 
#     axes=F, xlab="", ylab="")
#par(new = T)
plot(strt.stream.two.2019$DateTime, strt.stream.two.2019$AbsPTDepth, type = 'l')

# 
```
1) removed out of water points at the end of the season

### export PT data to csv to DoD_Discharge->PT_data->2019
```{r, echo=FALSE, warning=FALSE}
strt.pt.final <- rbind(strt.stream.one.2019, strt.stream.two.2019)
write.csv(strt.pt.final, here("PT_data/2019/STRT/strt.pt.2019.csv"), row.names = FALSE)
```

### Raw Rating Curve with STRT PT1

```{r, echo=FALSE, warning=FALSE}
QSummary.ST.2019 <- QSummary.2019 %>% filter(Site =="Stuart") %>% drop_na(Q_Ls)
QSummary.ST.2019$Site<- "STRT"
strt.stream.one.2019$Site<- "STRT"

Stuart1comb.2019 <- full_join(strt.stream.one.2019, QSummary.ST.2019)
Stuart1.lm.2019 <- lm(Stuart1comb.2019$Q_Ls ~ Stuart1comb.2019$AbsPTDepth)
summary(Stuart1.lm.2019) 


strt.formula <- y ~ x


ggplot(aes(x = AbsPTDepth, y = Q_Ls), data = Stuart1comb.2019) +
  geom_point(aes(color = Method), size = 3) +
  geom_smooth(method = "lm", se=FALSE) +
  stat_poly_eq(formula = strt.formula, 
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
               parse = TRUE) +
  theme_classic() +
  ggtitle("Stuart1 all measured Q")

```

I think the first time I did this RC we took out the two large Flowmeter calculations but then that gives us a negative relationship which makes the predicted Q really bad 

### Raw Rating Curve with STRT PT2

```{r, echo=FALSE, warning=FALSE}
strt.stream.two.2019$Site<- "STRT"

Stuart2comb.2019 <- full_join(strt.stream.two.2019, QSummary.ST.2019)
Stuart2.lm.2019 <- lm(Stuart2comb.2019$Q_Ls ~ Stuart2comb.2019$AbsPTDepth)
summary(Stuart2.lm.2019) 


strt.formula <- y ~ x


ggplot(aes(x = AbsPTDepth, y = Q_Ls), data = Stuart2comb.2019) +
  geom_point(aes(color = Method), size = 3) +
  geom_smooth(method = "lm", se=FALSE) +
  stat_poly_eq(formula = strt.formula, 
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
               parse = TRUE) +
  theme_classic() +
  ggtitle("Stuart2 all measured Q")

```

I am going to remove the high YSI pointt

### Rating Curve with STRT PT2 2.0

```{r, echo=FALSE, warning=FALSE}

QSummary.ST.2019.1 <- QSummary.ST.2019[-10, ]

Stuart3comb.2019 <- full_join(strt.stream.two.2019, QSummary.ST.2019.1)
Stuart3.lm.2019 <- lm(Stuart3comb.2019$Q_Ls ~ Stuart3comb.2019$AbsPTDepth)
summary(Stuart3.lm.2019) 


strt.formula <- y ~ x


ggplot(aes(x = AbsPTDepth, y = Q_Ls), data = Stuart3comb.2019) +
  geom_point(aes(color = Method), size = 3) +
  geom_smooth(method = "lm", se=FALSE) +
  stat_poly_eq(formula = strt.formula, 
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
               parse = TRUE) +
  theme_classic() +
  ggtitle("Stuart2 all measured Q")

```

Ill remove the high flowmeter 

### Rating Curve with STRT PT2 2.0

```{r, echo=FALSE, warning=FALSE}

QSummary.ST.2019.2 <- QSummary.ST.2019[-c(10,11), ]

Stuart4comb.2019 <- full_join(strt.stream.two.2019, QSummary.ST.2019.2)
Stuart4.lm.2019 <- lm(Stuart4comb.2019$Q_Ls ~ Stuart4comb.2019$AbsPTDepth)
summary(Stuart4.lm.2019) 


strt.formula <- y ~ x


ggplot(aes(x = AbsPTDepth, y = Q_Ls), data = Stuart4comb.2019) +
  geom_point(aes(color = Method), size = 3) +
  geom_smooth(method = "lm", se=FALSE) +
  stat_poly_eq(formula = strt.formula, 
               aes(label = paste(..eq.label.., ..rr.label.., sep = "~~~")), 
               parse = TRUE) +
  theme_classic() +
  ggtitle("Stuart2 all measured Q")

```

1)Removed top flowmeter and YSI point

### Predicted Q STRT PT1
#### Black points are observed Q

```{r, echo=FALSE, warning=FALSE}
Stuart1comb.2019$pred.stuart1.Q <- coef(Stuart1.lm.2019)[2] * Stuart1comb.2019$AbsPTDepth+ coef(Stuart1.lm.2019)[1]
ggplot(aes(x = DateTime, y = pred.stuart1.Q), data=Stuart1comb.2019) +
  geom_line(color="#A6CEE3", size=1.25) +
  geom_point(aes(x = DateTime, y = Q_Ls, shape = Method), size=3) +
  theme_classic() +
  ggtitle("Stuart") +
  scale_shape_discrete(name = "Method", labels = c("Wading Rod", "Salt Dilution", "")) +
  xlab("") +
  ylab("Discharge (L/s)") +
  ylim(0, 10000) +
  scale_x_datetime(limits = as_datetime(c("2019-05-15", "2019-10-10")))

```

### Predicted Q STRT PT2
#### Black points are observed Q

```{r, echo=FALSE, warning=FALSE}
Stuart4comb.2019$pred.stuart2.Q <- coef(Stuart4.lm.2019)[2] * Stuart4comb.2019$AbsPTDepth+ coef(Stuart4.lm.2019)[1]
ggplot(aes(x = DateTime, y = pred.stuart2.Q), data=Stuart4comb.2019) +
  geom_line(color="#A6CEE3", size=1.25) +
  geom_point(aes(x = DateTime, y = Q_Ls, shape = Method), size=3) +
  theme_classic() +
  ggtitle("Stuart") +
  scale_shape_discrete(name = "Method", labels = c("Wading Rod", "Salt Dilution", "")) +
  xlab("") +
  ylab("Discharge (L/s)") +
  ylim(0, 8000) +
  scale_x_datetime(limits = as_datetime(c("2019-05-15", "2019-10-10")))


```

### Average STRT Q ###

```{r, echo=FALSE, warning=FALSE}
strt.final.discharge.2019 <- left_join(Stuart1comb.2019, Stuart4comb.2019, by = c("DateTime"))
strt.final.discharge.2019$MeanDischarge <- rowMeans(strt.final.discharge.2019[,c(13,25)], na.rm = TRUE)
strt.final.discharge.2019 <- strt.final.discharge.2019[,-c(3:12, 14:24)] # cleaning empty columns
strt.final.discharge.2019 <- na.omit(strt.final.discharge.2019) # Remove data points that after removal
names(strt.final.discharge.2019) <- c("Site", "DateTime", "PT1", "PT2", "MeanDischarge")

strt.final.discharge.2019$DateTime <- as.POSIXct(paste(strt.final.discharge.2019$DateTime), format = "%Y-%m-%d %H:%M", tz = "America/Anchorage")
strt.final.discharge.2019$DateTime <- lubridate::round_date(strt.final.discharge.2019$DateTime, "15 minutes")


ggplot(aes(x = DateTime, y = pred.stuart2.Q), data = Stuart2comb.2019) +
  geom_line(aes(x = DateTime, y = pred.stuart1.Q), data = Stuart1comb.2019, color="#A6CEE3", size=1.25) +
  geom_line(aes(x = DateTime, y = pred.stuart2.Q), data = Stuart4comb.2019,color="red", size=1.25, alpha = 0.75) +
  geom_line(aes(x = DateTime, y = MeanDischarge), data = strt.final.discharge.2019, color = "#1F78B4", size = 1.25, alpha = 0.25) +
  geom_point(aes(x = DateTime, y = Q_Ls), size=2) +
  theme_classic() +
  ylim(0, 10000) +
  ggtitle("Stuart1(light) Stuart2(dark) & MeanDischarge (red) predicted all measured Q") +
  ylab("Predicted discharge L/s") +
  xlab("Time")


```

### export PT data to csv to DoD_Discharge->Predicted_Discharge->2019
```{r, echo=FALSE, warning=FALSE}
Stuart4comb.2019_final <- Stuart4comb.2019[,-c(2:4,6:12)] %>% filter(DateTime > "2019-05-10")
names(Stuart4comb.2019_final) <- c("Site", "DateTime", "Q")
Stuart4comb.2019_final$Site <- rep("STRT", length(Stuart4comb.2019_final$DateTime))

DateTimeFill <- data.frame(DateTime = seq(ymd_hm("	
2019-05-21 14:45", tz = "America/Anchorage"),ymd_hm("2019-10-12 23:45", tz = "America/Anchorage"), by = '15 mins'))
Stuart4comb.2019_final <- full_join(Stuart4comb.2019_final, DateTimeFill)
Stuart4comb.2019_final <- Stuart4comb.2019_final[order(Stuart4comb.2019_final$DateTime),]
Stuart4comb.2019_final <- na_kalman(Stuart4comb.2019_final, maxgap = 10)

write.csv(Stuart4comb.2019_final, here("Predicted_Discharge/2019/STRT/STRT.Q.csv"), row.names = FALSE)


ggplot(Stuart4comb.2019_final, aes(x = DateTime, y = Q)) +
  geom_point()


```

### export PT data to csv to DoD_Discharge->Predicted_Discharge->2019
```{r, echo=FALSE, warning=FALSE}
Q_2019 <- rbind(frch.final.discharge.2019.final, vaul.final.discharge.2019.final,
                poke.final.discharge.2019.final, Stuart4comb.2019_final,
                Moose2comb.2019_final)

# Round all sites to 15 minute intervals
Q_2019$DateTime <- lubridate::round_date(Q_2019$DateTime, "15 minutes")
Q_2019 <- Q_2019 %>% group_by(Site, DateTime) %>% summarise(Q = mean(Q))

# Fill gaps in data
DateTimeFill <- data.frame(DateTime = seq(ymd_hm("2019-04-29 14:15", tz = "America/Anchorage"),ymd_hm("2019-10-22 09:15", tz = "America/Anchorage"), by = '15 mins'))
DateTimeFill_all <- data.frame(Site = c(rep("FRCH", length(DateTimeFill$DateTime)),rep("MOOS", length(DateTimeFill$DateTime)),rep("POKE", length(DateTimeFill$DateTime)),rep("STRT", length(DateTimeFill$DateTime)),rep("VAUL", length(DateTimeFill$DateTime))), DateTime = rep(DateTimeFill$DateTime, 5))
Q_2019 <- full_join(Q_2019, DateTimeFill_all)
Q_2019 <- Q_2019[order(Q_2019$DateTime),]

# Fill in gaps up to 15 x 10 minutes
Q_2019 <- Q_2019 %>% group_by(Site) %>% summarise(Q = na_kalman(Q, maxgap = 10),
                                                  DateTime = DateTime) %>% filter(DateTime < "2019-10-23")


write.csv(Q_2019, here("Predicted_Discharge/2019/Q_2019.csv"), row.names = FALSE)

Q_2019$Day = format(as.POSIXct(Q_2019$DateTime, format = "%Y-%m-%d %H:%M:%S"), format = "%Y-%m-%d")
Q_2019$Day = as.POSIXct(Q_2019$Day, "%Y-%m-%d", tz = "America/Anchorage")

Q.daily.2019 <- Q_2019 %>% group_by(Site, Day) %>% summarise(Q = mean(Q))

write.csv(Q.daily.2019, here("Predicted_Discharge/2019/Q.daily.2019.csv"), row.names = FALSE)

Q_2019 %>% ggplot(aes(DateTime, Q, color = Site)) + geom_point(size = 0.25)

# Check time step intervals
Q_2019_check <- Q_2019 %>% group_by(Site) %>% summarise(diff = DateTime - lag(DateTime),
                                                      DateTime = DateTime)
unique(Q_2019_check$diff)

Q_2019_check %>% ggplot(aes(DateTime, diff, color = Site)) + geom_point()# + ylim(0,60)

# Check length of consecutive NA's
Q_2019_check_NA <- Q_2019 %>% mutate(Yes_NA = ifelse(Q %in% NA, "Y", "N"))

Q_2019_check_NA %>% 
  ggplot(aes(DateTime, Yes_NA)) + geom_point(size = 0.5) + facet_wrap(~Site)
```
